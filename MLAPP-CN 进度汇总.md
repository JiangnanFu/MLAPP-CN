
# MLAPP 读书笔记 - 00 前言

> A Chinese Notes of MLAPP，MLAPP 中文笔记项目 
https://zhuanlan.zhihu.com/python-kivy

记笔记的人：[cycleuser](https://www.zhihu.com/people/cycleuser/activities)

2018年05月06日13:15:36

## 简介
电子形式的数据规模增长，带来了数据分析自动化方法的需求的增长。机器学习的目的是开发能从数据中自动识别模式的方法，然后用发现的模式去对未来数据进行预测等等。所以机器学习和统计与数据挖掘领域都很相关，但重点和术语方面有所不同。本书就是对这一领域进行详细介绍，包含了一些应用样例，这些样例的领域包括分子生物学、文本处理、计算机视觉和机器人。

## 目标读者

这本书的目标读者是高年级研究生或者计算机科学、统计学、电子工程、经济等其他有充足相关数学知识的本科生。要求读者熟悉多元积分、概率论、线性代数以及计算机编程。初步了解统计学会很有帮助，不过不太熟悉也不用担心阅读本书会有困难。


## 概率角度

本书选择从这个角度来展开，因为使用概率理论是让机器能够从数据中进行学习的最佳方法，概率论在几个世纪以来都是统计学和工程领域的重要支柱。只要是有不确定性存在的问题，就可以使用概率论。在机器学习当中，不确定性多种多样：什么是对给定数据的最佳预测或者最佳决策？下一步进行哪种测量？等等。
对概率论的系统应用还适合所有推断问题，包括推断统计模型的参数，也称为“贝叶斯方法”。然而这个名词可能会引起非常强烈的反应，可能是正面也可能是负面，取决于询问对象，因此本书采用的是一个更中性的词汇“概率方法”。此外，本书中还会用到很多其他的方法，比如最大似然估计等等，这些都不是贝叶斯方法，但毫无疑问属于概率方法。

本书并不仅仅是一个罗列不同启发式方法的菜谱式书籍，而是强调了机器学习中的基于模型为原则的角度。对于任意的给定模型，都可以用一系列不同算法。反过来说，任意的算法也都往往可以用于多种不同模型。这样实现了一种模块化，将模型和算法相互区分，对教学和工程来说都是好选择。

本书会经常用到图像化的语言来对模型进行简明直观的表达。除了有助于理解之外，图结构还有利于开发高效的算法。不过这本书的重点并不是图结构，而是一般意义上的概率建模。

## 实践角度

本书中所提到的方法几乎都包含于一个叫做 PMTK 的 MATLAB 软件包里面，这个 PMTK 的意思就是概率建模工具箱(Probabilistic modeling toolkit)的英文缩写。PMTK 软件可以从 https://github.com/probml/pmtk3 下载，原来书中的链接 pmtk3.googlecode.com 提示失效了。pmtk 后面的这个3 是指版本号，本书用的是 pmtk3，更多相关资源可以访问 https://github.com/probml，其中由代码、文档、图件等等。
关于 MATLAB 的介绍这里就不说了，原书也建议了大家使用开源的 MATLAB 替代品 Octave，并说本书部分代码适用于 Octave。

本书中的很多图片都是使用 PMTK 生成的，这些相关的代码也都在 PMTK 网站上可以找到。这部分内容大家自己在 PMTK 的网站上看吧，我就不做翻译和说明了。

## 致谢

这部分就不翻译了。


# MLAPP 读书笔记 - 01 概论

> A Chinese Notes of MLAPP，MLAPP 中文笔记项目 
https://zhuanlan.zhihu.com/python-kivy

记笔记的人：[cycleuser](https://www.zhihu.com/people/cycleuser/activities)

2018年05月06日14:04:48

## 1.1 机器学习：概念和目的

> “我们被信息淹没，对知识感到饥饿。” John Naisbitt

人类进入大数据时代了。(译者注：现在有一种乱象，就是什么都说大数据啊人工智能啊，这些头猪已经就跟云计算一样四处飞啊，懂和不懂的都跟着吹捧。)

这么多数据就需要自动化方法来进行数据分析，因此需要机器学习。机器学习也就可以定义成一系列能够自动检测数据模式的方法集合，这些方法可以将发现的模式用于对未来数据的预测，或者对其他具有不确定性过程的选取提供参考(例如如何收集更多的数据等)。

本书的观点是解决这些问题的最佳方法就是使用概率论这一工具。概率论可以被用于任何涉及到不确定性的问题。在机器学习里，不确定性来源很多，这一点前言里面都说了，这里重复了，就不赘述了。

本书会介绍一系列概率模型，适合不同的数据和用途。此外还会介绍一系列的学习算法来使用这些模型。本书目标不仅仅是提供个菜谱式的参考，而是就着不同领域的用途，通过概率模型来给出一个独特角度。

需要注意的是，有时候虽然你有个看上去特别大规模的数据集，但是有效的数据点的个数可能并没那么大，甚至还可能很小。实际上大范围的数据就有个众所周知的特点叫长尾(Long Tail)，就是说有少数样本是非常常用的，而大多数是很少见的情景。例如，每天有 20% 的谷歌搜索都是之前没被看到过的。本书中所讨论的核心统计问题是从相对比较小规模的样本来进行泛化，在大数据领域也还是很相关的。



### 1.1.1 机器学习的类别

机器学习一般分成两种主要类型。

第一种就是预测类或者说监督学习，目标是通过学习算法得到一个从输入特征 x 到输出 y 的映射关系(mapping)，给定一个带有标签的输入输出集合对$D = \{(x_i,y_i)\}^N_{i=1}$。这样的集合 D 就叫训练集，N 就是训练集的样本数。
简单来说，每个训练样本的输入特征$x_i$ 是一个值为数值的 D 维向量，可能就是一个人的身高体重等等。这样的指标叫做特征(features)、属性(attributes)、或者 协变量(covariates)。不过这个$x_i$ 也可以是一个复杂结构对象，比如一个突破、一句话、一封邮件、一个时间序列、一个分子形状、一个图结构等等。

与此相似，输出(output)或称之为 响应变量(response variable)原则上也可以是任意形式的。不过大多数方法都是假设$y_i$ 是某个优先集合中的分类变量或者名义变量。比如可以使性别为雌性雄性，可以使实数值的标量(比如收入水平)。当 y 是分类变量的时候，问题就是一个分类问题或者模式识别问题，如果 y 是实数值的变量，则称为回归问题。还有一种变体，叫做有序回归，这是当 y 是某种自然排序标准的时候，比如从 A 到 F 分级。

第二种就是描述性或者叫无监督学习。这里的给定训练集中只有输入值，$D = \{(x_i)\}^N_{i=1}$，目标是要从数据中找到感兴趣的模式。这种方法也被叫做知识发现(knowledge discovery)。这类问题就没有上一种那么详细的定义，因为不知道要找的是啥样子的哪种类型的模式，也没有什么明显的误差矩阵之类的能用。而上一种监督学习里面我们可以把预测值和真实值进行对比。

实际上还有第三种机器学习，叫做强化学习(reinforcement learning)，这个当时用的还不那么多。这种方法用于给定奖励或者惩罚信号下的行为响应。例如小孩学走路等等。强化学习超出了本书的讨论范围，不过相关的理论在本书的 5.7也有涉及，但仅仅是基础内容。

## 1.2 监督学习

先开始讨论的是监督学习，这个在实践中用的最广泛。

### 1.2.1 分类问题

分类问题的核心目标就是对输入特征 x 和输出值 y 之间建立映射。其中的 y 属于一个有限集合，这个有限集合的元素个数为C。如果 C =2，那么这个问题就称之为二分类问题，也就可以假设 y 属于集合{0,1}；如果 C > 2，那么就称为多类别分类。如果分类标签不是互斥的，比如一个人可以即被形容为 瘦，同时也被形容为 高，那么称这类问题为多标签分类问题。不过最好把这种问题看做是对多个相关的二元类别标签进行预测的问题，所以也可以称之为多输出模型。除非特地说明，本文说的分类都值得是多类别分类，有单一的输出。

可以用函数估计来将正规表达这种问题。假设 y=f(x) 中的 x 和 y 分别是输入和输出值，而 f 是未知函数，那么目标就是通过给定的做好了分类的训练集来估计这个函数 f，然后使用估计得到的 f 来对新的数据集进行预测。预测的时候要用新的输入特征，也就是之前没看到的，这个过程也叫泛化，根据新特征的函数值就作出预测了。



#### 1.2.1.1 分类问题样本

本节简单又无聊，略


#### 1.2.1.2 概率预测

要处理不确定的情况，就要用到概率了。如果对概率论的基本概念不熟悉了，可以等着本书第二章那里有回顾。
给定输入向量 x 和训练集 D，我们将在可能的分类标签上的概率分布表示为$p(y|x,D)$。还记得 y 所属集合的元素个数 C 么？一般来说刚刚这个概率分布表示了一个长度为 C 的向量。如果只有两个分类，自然是所有分类的概率加一起等于1，$p(y=1|x,D)+p(y=0|x,D) =1$，那么只用其中一个概率$p(y=1|x,D)$就足够了。这里用$p(y|x,D)$来表示，|右边有 x 和 D，意思是这个概率是在测试样本中输入值 x 和训练集 D 上的条件概率分布。当选用不同的模型的时候，还可以加一个 M 在|右边，表示所选模型，也就是$p(y|x,D,M)$。如果行文背景中已经对模型有充分讲述了，就可以把 M 去掉，只写作$p(y|x,D)$了。

给定某个可能的概率化的输出，就可以计算出这个猜测是真实标签的概率了：

$\hat y =\hat f (x)=argmax ^C_{c=1} p(y=c|x,D)$ (1.1)

上面这个形式对应的就是最可能的分类标签，也被叫做概率分布$p(y|x,D)$的众数(mode)，也成为最大后验估计(MAP estimate， maximum a posteriori)。更正规详细的介绍在本书的 5.7。


如果一个$p(\hat y|x,D)$ 远小于1，也就是说这个答案不让人很有信心，这时候与其返回一个不太可信的结果就不如直接返回不确定了。在医疗和金融等对风险敏感的领域尤其如此。这一部分还列举了 IBM 的 Watson 和 Google 的 SmartASS 系统等等，在此忽略。



#### 1.2.1.3 现实世界中的应用

分类可能是机器学习最广泛的用途了，用于很多有意思又难以人力解决的现实问题。

##### 文档分类和垃圾邮件过滤

此处查看原书图 1.2


文档分类的目标是对一个文档，比如网页或者电子邮件信息，分到 C 种类别当中的某一种，也就是要计算 p(y=c|x,D)，其中的输入特征 x 是文本的某种信息。
垃圾邮件过滤是这种用途的一个特例，其中分类只有两种，要么是垃圾邮件，y=1，要么不是，则 y=0.

大多数分类器都假设输入特征向量 x 有固定尺寸。可变长度文档的特征向量格式可以使用词汇袋(bag of words)来表示。细节可以参考本书的 3.4.4.1，不过基本思想还是恩简单的，就是如果单词 j 出现在了文档 i 里面，则$x_{ij}=1$。如果把这种变换应用到数据集中的所有文档，就得到了一个由文档和词汇组成的二元共生矩阵，入图1.2所示。


这样就从一个文档分类问题简化到一个寻找模式中的细微变化的问题了。比如，可能很多邮件含有一些特定关键词，可以借助这些来分类。在练习8.1和8.2里面，你就要自己动手来使用不同分类技巧来进行垃圾邮件识别。



##### 鸢尾花分类

此处查看原书图 1.3

图1.3是另外一个例子，来自统计学家 Ronald Fisher。这个案例的目的是让机器学习对是三种鸢尾花进行分类，分别是 setosa、versicolor 和 virginica。很幸运，不用直接处理图像，有生物学家已经将有用特征进行了统计，这些特征包括：萼片长度、宽度，花瓣长度、宽度。
从照片等复杂对象到数据这个过程叫做特征提取(feature extraction)，这个过程非常重要，又特别困难。译者注：特征提取还往往可能被人忽略，如果没有进行充分的特征提取，是根本不可能充分对分类对象进行分类的。本书后面的章节会讲到从数据中提取好的特征的一些方法。

此处查看原书图 1.4

如图1.4所示，对鸢尾花数据集进行散点图投图，很明显可以检查花瓣长宽来讲 setosas(红色圆圈)和其他两种区分开。然而另外两种 versicolor 和 virginica 的区分就稍微难一点了，需要至少使用两组特征。在进行机器学习之前，可以将数据先投图看看，这样可以进行一些探索性的数据分析，是个很好的办法。


##### 图片分类和手写识别

此处查看原书图 1.5

接下来这个问题就更难了，要直接对图片进行分类，这些图片都是没有预处理的数据。可能需要先整体分类一下，比如是室内的还是室外场景，是横着还是竖着拍摄的，是否有小狗等等，这就叫做图形分类。

有一个特例就是判断手写的字母数字，例如对于邮编之类的，就可以进行这种手写识别。这个用途也有个标准数据集，叫做 MNIST，是 Modified National Institute of Standards 的缩写，这个数据集里面的图片都做了预处理，保证了大多数数值或者字幕都在图片中心位置。这个数据集有6000个训练样本图片和 10000 个测试样本图片，内容都是由不同的人写的数字0到9。每个图片都是 28*28 像素大小，灰度值都是从0到255的。图1.5(a)是一些样本。

很多通用分类方法会忽略输入特征的结构，例如空间布局等等。因此，这些方法可以用于处理图1.5(b) 所示的数据，这份数据是同一份数据对所有特征进行了随机排列。这个过程在练习1.1当中。这种灵活性既是好事，也是噩梦，是好事因为这些方法可以适用于通用目的，是噩梦因为这些方法忽略了很明显的有用信息。本书后面会讨论利用输入特征结构信息的方法。


##### 人脸检测和识别

此处查看原书图 1.6

这个问题就比上一个更难了，要从一个图片中找到某些对象，这也叫做对象检测或者对象定位。一个例子就是人脸检测。解决这个问题的一种方法是把图片切分成叠覆在不同位置、大小和方向的小块，然后对这些个小块来检测是否含有人脸形状的结构。这种方法也叫做滑动窗口检测(sliding windows detector)。这个系统会返回像人脸概率最高的区域的位置。如图1.6所示。这种方法目前应用于数码相机里面，可以用于控制相机去对角到人脸位置。译者注：比如索尼微单就有人脸识别和眼控对角，都是基于这种思路。另外一种用途是在谷歌街景之类的系统中把人脸模糊掉。

找到了面孔之后，就可以继续进行人脸识别了，就是对该面孔所有者的身份进行识别。这个过程中用到的分类标签可能很多很多。另外这个过程用到的这些特征都和人脸检测问题中有所不同，例如在人脸识别的过程中，面孔的细微差别，例如发行等等，对于身份确定都是很重要的；而对于人脸检测来说，这类细节都是无关紧要的，而关注的核心是人脸与非人脸之间的差别。




### 1.2.2 回归

回归和分类其实挺相似的，核心区别在于分类的响应变量 y，也就是分类标签，是离散的，是一个有限集合中的元素；而回归中的响应变量 y 是连续的。
如图1.7所示，有一个单实数值的输入特征$x_i \in R$，然后也有一个单实数值的响应变量$y_i\in R$。我们可以考虑对这个样本数据使用两种模型进行拟合，一个如图1.7左图所示，用直线，另外一个如右图所示，用二次曲线拟合。其实这时候就能引出很多扩展问题了，比如如果输入特征是高维度的怎么办、异常值怎么处理、非光滑的响应变量怎么办等等。这些内容都在本书的后文中。

此处查看原书图 1.7

现实世界中的回归问题有很多，比如：
* 根据给定的市场状况和其他方面的信息预测明天的股票市场价格。
* 预测在 YouTube 上观看某个特定视频的观众年龄。
* 预测一个机器人手臂在三维空间中的位置，对其一系列不同的马达发送控制信号控制扭矩。
* 根据不同的临床检测结果来预测人体中前列腺特异抗原(prostate specific antigen, PSA)的规模。


## 1.3 无监督学习

接下来就讲下无监督学习。这种情况下只给了输出数据，没有任何输入值。目标就是要从数据中发现感兴趣的结构，所以有时候也叫做知识发现(knowledge discovery)。和监督学习的不同在于，我们没有被告知对于每个输入的期望输出是什么。将这个任务正规表达(formalize)，要进行密度估计(density estimation)，要建立$p(x_i|\theta )$的模型。

这样和监督学习的情况有两个主要的区别。
首先是概率的表达形式不一样，写成的是$p(x_i|\theta )$而不是$p( y_i|x_i, \theta )$，这是因为监督学习是条件密度估计，而无监督学习是非条件密度估计。
其次，无监督学习中的特征$x_i$  是一个特征向量，所以需要建立的是多元概率模型。而监督学习中的$y_i$通常是单值的，是用来去预测的。这就意味着对于大多数的监督学习算法来说，都使用的是单变量概率模型，带有与输入相关的参数(input-dependent parameters)，单变量概率模型那问题就比多变量的简单多了。在本书第19章会讲到多输出分类，其中的监督学习也涉及了多元概率模型。


无监督学习就跟人学习过程类似。应用领域更广，不需要人为对数据进行标签分类，成本低，信息密度大。分类的数据不仅很昂贵，而且包含的信息相对来说也少了些，对于复杂模型的参数估计来说就可能不够可靠了。多伦多大学的 Geoffrey Hinton 是机器学习领域的著名教授，他之前说：
当我们学着观看世界的时候，是没有人告诉我们什么是正确答案的，我们就是用眼睛去看而已。有时候可能你妈妈会告诉你那个是小狗，不过这只是非常少的信息。这样的过程中，你能得到几个 bit 的信息就挺幸运了，甚至哪怕每秒钟只有一个 bit 的信息都很不错了。你的大脑视觉系统有$10^14$ 数量级的神经元链接在一起，而你的生存时间只有$10^9$ 秒。所以每秒只有 1bit 信息获取的学习过程是没啥用的。你需要更多信息，比如每秒$10^5$ bit 的信息。这么多信息只能从观察到的输入本身里面获得。---Geoffrey Hinton,1996,Quoted in Gorder 2006。


下面是无监督学习的一些例子。

### 1.3.1 聚类分析

此处查看原书图 1.8

聚类分析，简单说就是把数据分成不同的组。如图1.8所示，其中把二位数据投成了散点图，表示的是210个人的身高体重，好像应该明显分成几个群或者子组，不过也不知道该分多少组。设 K 表示了可分的组的数目。
首先要对在分组数上的分布 p(K|D)进行估计，这就能知道数据中是否具有子群。简单来说，通常用p(K|D)的众数(mode)来进行近似，得到的是$K\overset{\triangle}{=} arg max_K p(K|D)$。在监督学习的情况下，我们会被告知有男女两类人，但在无监督学习里面，我们可以随意选择自己喜欢的分组数。选一个具有“合适复杂度(right complexity)”的模型的过程就叫做模型选择。后文也会详细介绍。
接下来的目标就是估计每个点属于哪个组了。假设有$z_i \in \{1，... ，K\}$，表示了每个点 i 所归属的组的序号。这样的 z 就是潜在变量(hidden/latent variable)，因为不能从训练集中直接观察到。只要计算$z_i\overset{\triangle}{=} arg max_K p(z_i=k|x_i,D)$就行了。如图1.8(b) 所示，其中设置了 K=2，两组颜色不同一眼就能看出来。

在这本书里面，重点关注的是基于模型的聚类，也就是先对数据拟合一个概率模型，而不是直接运行某些特定算法。这样可以客观地对比不同模型，可以对比似然性等等，然后还可以结合使用成为更大规模系统等等。

下面是一些聚类分析在现实世界中的实际应用范例：
* 天文学里面，基于对天文观测的聚类分析，自动分类系统(Cheeseman 等，1988)帮助发现了一种新的恒星。
* 电子商务里面，基于购买类型或者网页浏览习惯等等，使用聚类将用户分组，然后给他们发送定制广告(Berkhin 2006)。
* 生物学里面，对流式细胞术数据(flow-cytometry data)的聚类分组，可以将细胞分成不同子类(Lo 等，2009)。

### 1.3.2 发掘潜在变量

此处查看原书图 1.9


处理高维数据的时候，可能要把高维数据投影到更低维度的子空间内，这个字空间包含了数据的关键信息。这个过程就叫做降维。简单的样例如图1.9所示，其中的三维数据投影到了一个二维平面上。这个而为估计还是不错的，因为大多数点距离这个子空间距离都挺近。而如果继续降低维度投影到图1.9(a)中所示的那条红线上，就不太好了，这部分详细内容在本书第12章。

这个技巧背后的思路是虽然数据可能呈现出高维度的状态，但是其中与潜在变量对应的可能只有少数几个项目而已。例如，对人的面部图像进行建模的时候，可能就只有少数几个隐藏的潜在因子就能描述绝大部分的变化，比如光照、姿势、身份等等，如图1.10所示。


此处查看原书图 1.10

当作为对其他统计模型的输入的时候，这种低维度的表示通常能提高的预测准确性，因为这种降维过的数据聚焦在研究对象的“本质特征”上，滤除了次要信息。另外，低维度表示还可以用于快速邻域搜索，二维投影对于高维数据的可视化也很有帮助。

降维的最常用方法就是主成分分析，即 PCA，principal components analysis。这可以被看做是一种无监督的(多输出)线性回归，其中我们观测的是高维度响应变量 y，而并不是低维度的“诱因” z。这样一个模型就建立了，就是从 z 到 y 的对应关系。我们还必须要逆转这个对应关系，从观测到的高维响应变量 y 中去推出潜在的低维度 z，这部分在本书的12.1。

降维，以及主成分分析，已经被用于很多领域了。一些样例如下所示：
* 生物学里面用 PCA 来解析基因片段数据，说明每个测试结果通常是多个基因通过所属的不同生物学路径协同行为的结果。
* 自然语言处理中，用一种叫做潜在语义分析的 PCA 衍生方法来进行文档恢复(本书27.2.2)。
* 在信号处理中，比如声学信号或者神经信号等等，常常使用 ICA(独立成分分析，主成分分析的一种变体)来区分不同的信号源(本书12.6)。
* 计算机图形学中，常会将动作捕捉数据投影到低维度空间，然后用来建立动画。参考本书的15.5。


### 1.3.3 发掘图结构量

此处查看原书图 1.11


有时候对一系列的相关数据进行测试，需要找出某个变量和哪个变量最相关。这就可以用一个图 G 来表示，图中的节点则为各个变量，而线段表示变量的依赖关系，这些内容在本书第10章讲到图模型的时候会详细说。可以从数据中使用学习算法得到这个图模型$\hat G = \arg\maxp(G|D)$。

这种稀疏图学习和应用无监督学习方法一样，总体上也有两种应用：发掘新知识，或者得到更好的联合概率密度估计。每个给出的样例如下：
* 很多这种稀疏图学习算法的动机来自于系统生物学社区。例如，假如我们测试了一个细胞里蛋白质的磷酸关系状态(Sachs 等等，2005)。图1.11展示的就是这样得到的一个图结构，详细方法在本书26.7.2中有讲述。
*某些情况下，对于解析图结构本身我们没多大兴趣，而只是想用它来对相关性进行建模然后来进行预测。例如金融证券组合管理，其中大规模的不同证券股票之间的相关性是极其重要的。



此处查看原书图 1.12


### 1.3.4 矩阵补全

有时候我们会遇到数据缺失的情况，也就是有的变量的值我们不知道。例如，我们可能组织了一个问卷调查，然后有的人可能没回答一些问题。或者可能我们有不同的传感器，而某些可能不工作了。对应的结果就是矩阵中有“孔洞”，通常用 NaN 来表示，NaN 的意思是 Not A Number，即值非数值。对遗失值进行插补(imputation)就是要用合适的值来填充这些空白位置。这个过程也叫做矩阵补全。下面的是几个具体例子。


#### 1.3.4.1 图像修复

遗失值插补的一个例子就是图片修复。目标是对图片中的空白地方使用合适的结构形态之类的内容进行填补。如图1.12所示，其中对一个图片进行了降噪，然后插入像素填补了空白位置的图像内容。具体方法是对图像中清楚的部分建立一个联合概率模型，然后推测给定变量(像素位置)的未知变量(像素)。这个过程有点像购物篮分析(market basket analysis)，除了数据是实数值和具有空间结构，所以用到的概率模型也有所不同。更多细节参考本书的19.6.2.7和13.8.4。




#### 1.3.4.2 协同筛选


此处查看原书图 1.13


另外一个样例就是协同筛选(collaborative filtering)。比如可以基于人们对已经看过电影的评分来预测接下来他们想要看的电影。关键思路在于这个预测并不是基于电影或者用户的特征(虽然也可以用这些特征)，而基本主要是基于一个评分矩阵。更确切的来说，如图1.13所示，有一个矩阵 X，其中的两个方向分别是电影和用户，而矩阵的值就是对应用户对对应电影的评分，可以是从1到5的某个值。要注意这个矩阵 X 当中很多值都可能是空的或者未知的，因为大多数用户也未必对大多数电影进行过打分。所以观察到的总会只是一个很小的子集，而我们要预测的是另外一个不同的子集。具体来说，如果给定某个用户 u，可能要预测他没有评分的电影中他最可能想要去看的。

为了获取这个领域的信息，DVD 租赁公司 Netflix 建立了一个竞赛，从2006年开始，奖金是一百万美元。他们提供了一个很大的评分矩阵，评分从1到5，有大约一万八千部电影，参与评分的有五十万左右的用户。整个矩阵的规模大约有$9*10^9$条数据，而其中只有大约1%的数据是有确定值的，所以这个矩阵是极其稀疏的。从中选取一个自己用来作为训练集，另外的一部分用于测试。如图1.13所示。这个竞赛的目标是能比 Netflix 本身的系统更加精确。在2009年9月21号，这个奖办不给了一队研究者，“BellKor's Pragmatic Chaos”。本书的27.6.2详细讲述了他们用的方法。





#### 1.3.4.3 购物篮分析


购物篮分析是商业数据挖掘里面的一个很受关注的项目。这种数据包含一个二值矩阵，往往规模很大又是稀疏的，其中每一列表征的是一个商品，而每行表示一笔交易。如果在第 i 次交易中商品 j 被购买了，就设置$x_{ij}=1$，否则为0。很多商品可能会被一起购买，比如面包和黄油等等，所以在这些 bit 数据中会有相关性。给定一个新的观察到的部分 bit 向量，表征了消费者购买项目的一个子集，目标就是去预测其他 bit 的可能值，表示消费者是否会购买其他项目。和协同筛选不同的是，这里通常假设没有缺失数据。因为每个消费者过去的购买行为都是已知的。


除了购买模式之外，这个问题也适用于很多其他领域。例如，类似的技术可以用于复杂软件系统中的文件相关性的建模分析。这时候任务目的就是根据给定的已被修改的文件自己来预测其他文件是否需要被上传来确保数据连续性(Hu 等2010)。

这个问题通常要用到频繁集挖掘算法(frequent itemset mining)，这一方法建立关联规则(Hastie 等，2009)。另外也可以用一种概率方法，对这个 bit 向量拟合一个联合密度模型$p(x_1,...,x_D)$(Hu 等2010)。相比关联规则，这种方法通常能够提供更精确的预测，不过解释起来就不如关联规则的方法好解释了。这是数据挖掘和机器学习的一个显著区别：在数据挖掘里面，更注重对是得到可解释的模型，而在机器学习里面，更注重的是得到精确模型。



此处查看原书图 1.14



## 1.4 机器学习中的一些基本概念

在本节会简要介绍机器学习里面的一些关键思想。在本书后面的内容中，会对这部分概念进行扩展，不过我们还是现在这里简单介绍一下，让大家了解一下接下来要接触的内容。


### 1.4.1 参数化模型和非参数化模型

在本书里面我们主要关注的是概率模型，形式是$p(y|X)$或者$p(x)$，这还要取决于我们使用的是监督学习还是无监督学习算法。有很多方法来定义这些模型，不过最重要的区别是看模型是否有固定数目的参数，或者参数的数量是否随着训练集规模的增长而增长。前一种就是参数化模型(parametric models)，后一种则是非参数化模型(non-parametric models)。参数化模型的优点是用起来更快速，而对数据分布的自然特征进行更强假设的时候就不如非参数化模型了。非参数化模型更加灵活，但对于大规模数据集来说在计算上比较困难。接下来的章节中对这两种模型都会有所讲解。对于监督学习来说，我们关注的是简易性，不过很多讨论内容也适用于无监督学习。

### 1.4.2 K 最邻近算法，一个简单的非参数化模型分类器


此处查看原书图 1.15

这个方法就是“查看”训练集中与输入值 x 最邻近的 K 个点，然后计算样本中每一类有多少个成员包含于这个集合中，然后返回经验分数作为估计值，如图1.14所示。更正规的表示法如下所示：

$p(y=c|x,D,K) = \frac{1}{K} \sum_{i\in N_{K(x,D)}}\prod (y_i=c)$ (1.2)


其中的$N_{K(x,D)}$是在 D 中和点 x 最近的 K 个点的索引，而，$\prod (e)$则是指示函数，其中的 e 表示判断条件，如果 e 为真则$\prod (e) =1$，否则$\prod (e)=0$。


$$
\prod (e) = \begin{cases} 1 & \text{if e is true}  \\
0 & \text{if e is false}
\end{cases}
$$(1.3)

这个方法属于一种基于记忆的学习(memory-based learning)，也是基于实例的学习(instance-based learning)。具体的概率推导过程在本书的14.7.3。



此处查看原书图 1.16

最常用的距离矩阵就是欧氏距离，不过这也限制了适用的范围，因为要求数据必须是实数值的。当然也可以用其他的距离矩阵。

图1.15是上述方法的一个实例，其中输入是二维的，有三个类，设置了 K=10。图1.15(a)当中是对训练数据的投影，图1.15(b)则是对$p(y=1|x,D)$的投图，图1.15(c)则是对$p(y=2|x,D)$的投图。不用对$p(y=3|x,D)$再去投图，因为概率相加等于1，所以有其他两个就能确定$p(y=3|x,D)$了。图1.15(d)是对最大后验估计(MAP estimate)的$\hat y(x)= arg max_c p(y=c|x,D)$ 投图。

K =1 的 KNN 分类器就会生成一个沃罗诺伊镶嵌(Voronoi tessellation，Voronoi diagram)，也叫狄利克雷镶嵌(Dirichlet tessellation)或泰森多边形(Thiessen polygon)，如图1.14(b)所示。这个过程实际上是把整个的区域$V(x_i)$分配给每个点$x_i$，在$V(x_i)$中的所有点到$x_i$的距离比其他所有点更近。在每个细胞格内，预测的标签就是训练集中对应点的标签。

### 1.4.3 维度诅咒

在得到一个比较好的距离矩阵并且有充分标签的训练集的情况下，KNN 分类器简单又好用。如果 N 趋向于无穷大，KNN 分类器的性能差不多是最佳性能的一半了(Cover and Hart 1967)。

不过当面对高维度输入的时候，KNN 分类器就不太好用了。这种高维度下的悲惨的性能表现是由于维度诅咒(curse of dimensionality)引起的。

要解释这个问题，需要引用一些例子(Hastie 等 2009 p22)。设想要对一个训练集使用 KNN 分类器，这个训练集的输入值均匀分布(uniformly distributed)在一个 D 维度单位立方体，日常所说的立方体就是3维的，这里的是 D 维的。摄像我们对测试点 x 周围的类标签的密度进行估计，方法是在 x 周围“生长”一个超立方体，直到包含了某个的数据点比例 f。这样这个超立方体的边长期望值就是$e_{D(F)} = f^{1/D}$。如果 D=10，而我们希望基于数据集中的10%来进行估计，那么得到了$e_{10(0.1)} = 0.8$也就是说在每个维度要在 x 周围延长原本的超立方体的80%。如果只用数据的1%，那么$e_{10(0.01)} = 0.63$，如图1.16所示。整个数据范围在每个维度上才只有1，所以这样依赖这种方法得到的结果就已经不在原来位置了，根本配不上 KNN 这个名字中的后两个字母 NN(nearest neighbor，最邻近)。查找远距离邻居成了麻烦，因为这不能很好预测给定点位的输入输出函数的行为。

### 1.4.4 分类和回归的参数模型

要解决维度诅咒这个难题，主要方法就是对于数据的自然特征进行一些假设，比如对于监督学习就是$p(y|x)$，对于无监督学习就是$p(x)$。这些假设也就是所谓的归纳偏见(inductive bias)，经常是存在于参数模型当中。参数模型是有着固定参数数目的统计模型。下面会介绍两个广泛应用的例子，本书后文中会深入讲解包括这两个在内的更多模型。




### 1.4.5 线性回归

最广泛使用的回归模型就是线性回归(linear regression)。即设响应变量为输入变量的线性函数。写出来如下所示：

$y(x)=w^Tx + \epsilon =\sum^D_{j=1}w_jx_j + \epsilon$(1.4)

上式中的$w^Tx$表示的是输入向量 x 和模型的权重向量(weight vector)w(统计学中对回归权重更常用的记号是$\beta$)的内积(inner product)或者数积(scalar product)。而$\epsilon$则是线性预测和真实值之间的残差(residual error)。


此处查看原书图 1.17

通常我们会假设残差$\epsilon$遵循高斯分布，即正态分布。记作$\epsilon \sim  N(\mu,\sigma ^2)$，其中$\mu$是均值，$\sigma$是方差，更多细节第二章会讲。对这个分布投图，就会得到钟形曲线(bell curve)，如图1.17所示。


要在线性回归和高斯分布之间建立更确切的联系，可以用下面这种形式重写模型：

$p(y|x,\theta)= N(y|\mu(x),\sigma^2(x))$(1.5)

很明显，这个模型这样就是一个条件概率密度了。在最简单的情况下，可以假设$\mu$是 x 的线性函数，所以$\mu =w^Tx$，而设噪音为固定的，即$\sigma^2(x) = \sigma^2$。这样$\theta = (w,\sigma^2)$就是模型参数了。

假如输入特征x是1维的，就可以用下面的形式表示响应变量：
$\mu (x)=w_0 + w_1x =w^TX$(1.6)
上式中的$w_0$就是偏项(bias term),$w_1$是斜率(slope)，此处的向量 X 定义为$X=(1,x)$。这里在输入向量上加一个预设常数1是一个常用技巧，这样就可以把截距项(intercept term)和模型中其他项目结合起来。如果$w_1$符号为正，就意味着输出随着输入的增大而增大。这如图1.17(b)所示；图1.17(a)所示的是响应变量均值和 x 之间关系的投图。

对非线性关系模型，可以把线性回归中的 x 替换成某种对输入的非线性函数$\phi(x)$，也就是如下面所示的形式：

$p(y|x,\theta) = N(y|w^T\phi(x),\sigma^2 )$ (1.7)



此处查看原书图 1.18


这个过程即基函数扩展(basis function expansion)。例如图1.18所示，其中的$\phi(x)=[1,x,x^2,...,x^d]$，图1.18(a)中 d=14，图1.18(b)中 d=20，这两个都是多项式回归(polynomial regression)。
本书的后面章节会提到其他的基函数。实际上很多流行的机器学习算法都可以看作是从数据估计基函数的不同方法而已，比如支持向量机(support vector machines)、神经网络(neural networks)、分类和回归树等等。这部分内容在本书14和16章。


### 1.4.6 逻辑回归


此处查看原书图 1.19



对于分类问题，尤其是二分类问题，可以对线性回归做两个修改。首先是对 y 不再使用高斯分布，而是换用伯努利分布，这在$y \in \{0,1\}$ 二分类问题的情况下更近似。如下所示：

$p(y|x,w)=Ber(y|\mu(x))$(1.8)

其中的$\mu(x) = \mathrm{E}[y|x]=p(y=1|x)$。接下来计算输入变量的一个线性组合，和之前的不同在于要通过一个函数来处理一下，以保证$0\leq \mu(x) \leq 1$：

$\mu(x)=sigm(w^Tx)$(1.9)

上面的$sigm(\eta)$是指 S 形函数(sigmoid function)， 也叫做逻辑函数(logistic function 或 logit function)。这个函数的定义如下所示：

$sigm(\eta) .= \frac{1}{1+exp(-\eta)} =\frac{e^\eta }{e^\eta +1}$(1.10)

Sigmoid 的意思就是 s 形，如图1.19(a)所示。这个函数也叫做压缩函数(squashing function)，因为此函数会把线条约束在0到1的闭区间内。这种约束很有必要，因为输出值要被表达成概率的形式，根据定义就能知道概率就是在这个0到1的闭区间内的。

把上面两个步骤结合起来就得到了下面的式子：

$p(y|x,w)=Ber(y|sigm(w^Tx))$(1.11)

这个就叫做逻辑回归，虽然看上去有点像线性回归，但实际上逻辑回归是一种分类，而并不是回归。


图1.19(b)展示了一个简单的逻辑回归样例，其中投影了下面的函数：

$p(y_i=1|x_i,w) = sigm(w_0+w_1x_i)$(1.12)

图1.19(b)中的$x_i$是学生 i 的 SAT(理解为美国高考)的分数，而$y_i$是判定他们是否通过一门课。黑色实心点是训练集，红色圆点是$p(y=1|x_i,\hat w)$，这里的$\hat w$就是从训练集估计出来的参数，具体计算过程在本书的8.3.4。

如果我们在概率为0.5的位置分解，就引入了决策规则(decision rule)，形式如下所示：
$\hat y(x)=1 \iff p(y=1|X) > 0.5$(1.13)

如图1.19(b)中，$sigm(w_0+w_ix)=0.5$的时候，$x\approx 545 = x*$。所以可以在这个位置画一条竖线，作为所谓的决策边界(decision boundary)。这条边界左侧设为0，右侧设为1。

这里要注意到，决策规则即便在训练集上都有一个非零的错误比例(non-zero error rate)。这是因为数据本身并不是线性可分的(linearly separable)，也就是说我们并不能画一条线区分0和1.使用基函数扩展，可以创建非线性决策边界的模型，就跟非线性回归类似。更多样例都在本书后文中。



### 1.4.7 过拟合

当拟合高灵活度模型的时候，要非常小心过拟合(overfit)，也就是要避免去对输入的所有微小变动都进行建模，因为这些很可能是噪音而不是真正的信号。如图1.18(b)所示，其中用高次多项式拟合得到的曲线七扭八歪。真实的函数是不太可能有这么严重的振荡的。因此用这样的模型对未来输出就可能无法得到准确预测。

再举一个例子，比如 KNN 分类器，K 值的选择会对模型行为有很大影响。如果 K=1，那自然是在训练集上不会有误差，因为这就相当于只是返回了训练集各点本身的标签而已，但得到的与侧面就会很纠结了，如图1.20(a)所示.这样此方法对于预测未来数据就不一定很适合。在图1.20(b)当中设置了 K=5，这时候预测面就更光滑多了，因为在从一个更广泛的邻域来进行均值取值。随着 K 的增长，预测面会越来越光滑，知道 K 达到了临界值，也即是 K=N，这时候就是在预测整个数据集上的主要分类标签了。后文会详细讲解如何选择“正确”的 K 值。


此处查看原书图 1.20

### 1.4.8 模型选择

我们可能有很多可选的模型，复杂度各自不同，比如线性回归、逻辑回归，不同的多项式次数，或者 KNN 分类器使用不同 K 值，那么该怎么选择呢？一个很自然的方法是计算各个方法在训练样本上的误分类率(misclassification rate)。

这个误分类率(misclassification rate)的定义如下：

$err(f,D)=\frac{1}{N}\sum^N_{i=1}\prod(f(x_i)\neq y_i)$(1.14)

上式中的 f(x) 就是咱们的分类器了。如图1.21(a)中的是这个错误率和 KNN 分类器的 K 值之间关系的曲线。很明显随着 K 的增长训练集上的错误率会增加，因为这个过程增加了光滑程度。如上文所述，我们可以使用 K-1来让整个训练集上的错误率最低，这样就只是存储训练集数据而已。

然而我们还关心泛化误差(generalization error)，也就是未来数据的平均分类误差率的期望值，更多细节参考本书6.3。这个指标可以通过对大规模相互独立的测试数据集的误分类率进行计算而近似得到，而不是用在模型训练过程中的。在图1.21(a)当中用红色时薪曲线投了测试误差和 K 之间的曲线。这个曲线是 U 形的，对于复杂模型(小 K 值)来说，这个方法就过拟合了，对于简单模型(大 K 值)来说，这个方法就欠拟合了。因此很明显选择测试误差最小的 K 值，在图1.21(a)当中从10到100都可以。

很不幸，在训练模型的时候我们又不能用测试数据集，所以也不能用测试数据集来挑选正确的模型复杂度。不过我们可以把训练集分成两部分，一部分用来训练模型，另一部分用作验证集(validation set)来挑选模型复杂度。这样我们在训练集上拟合所有不同模型，然后在验证集上面评估不同模型的性能，从中择优。选好了最佳模型之后，再用这个模型对全部数据进行拟合。如果我们有一个单独的测试集，可以在这个测试集上面进行评估，来估计所选方法的准确性，更多相关细节在本书6.5.3。

通常做法是从数据集中选择80%抽样作为训练集，另外的20%作为验证集。不过如果训练集规模很小，这样做就有麻烦了，因为训练集的数据可能不太充足，不够用于训练模型，甚至不能对未来的情况进行可靠估计了。

一种简单又很流行的解决方案就是使用交叉验证(cross validation，CV)。这个想法很简单：把训练集分成 K 份，对每个$k\in \{1,...,K\}$都训练除了第 k 份之外的所有数据，然后在第 k 份上进行验证，就这样轮流进行，如图1.21(b)所示。然后对所有份上的误差率计算均值，用这个作为测试误差的近似值。这里要注意每个点只被预测过一次，而在训练过程中则被用到了 K-1 次。这种方法就叫做 K 折交叉验证(K-fold CV)，通常设置 K=5，称为5折交叉验证。如果设置 K=N，那么这样就成了留一法交叉验证(leave-one out cross validation，LOOCV)，因为对于每一份 i 都训练了除了 i 样本之外的所有其他数据，而在 i 上进行测试。练习1.3就让你用5折交叉验证估计测试误差和 K 的关系。然后和图1.21(a)当中的先验误差(empirical error)进行比较。

上面这些挑选 KNN 分类器的 K 值问题其实是一种更广泛问题的特例，这类问题都是模型选择(model selection)，其中我们的任务就是在不同灵活度的模型支架做出选择。交叉验证被广泛用于这类问题，当然本书后文还会介绍一些其他方法。

此处查看原书图 1.21


### 1.4.9 没有免费的午餐


所有的模型都是错的，不过有的模型还是有用的。———— George Box(Box and Draper 1987，p424)

机器学习多数关注的是推导出不同的模型，用不同的算法对这些模型进行拟合。我们可以用交叉验证之类的方法来先去选择一个对于所用问题最适合的方法。然而，并没有通用的最佳模型，这也被称为“没有免费的午餐理论(no free lunch theorem)”(Wolpert 1996)。这一现象是因为在某个领域比较合适的一些假设，用到其他情况就可能不太靠谱了。

因此，我们需要开发很多不同类别的模型，来覆盖现实世界中各种不同的数据。对于每个模型，都有很多不同的算法能用来训练该模型，还要在速度、准确性、复杂度之间进行权衡妥协。接下来的各个章节里面我们要学习的就是数据、模型、算法的结合。



## 练习 1



### 练习 1.1 对打散的MNIST数据使用 KNN 分类器

运行本书配套程序 pmtk3 中的 mnist1NNdemo，在前1000个测试案例上验证 K=1 的KNN 分类器的误分类率为3.8%。如果你运行到全部10,000个测试样本上，误差率应该是3.09%。
然后修改一下代码，对特征(训练和测试矩阵的列)进行随机置换，参考 shuffledDigitsDemo，然后再运行同一个分类器，验证一下误分类率没变。


### 练习 1.2 估计 KNN 分类器

使用https://github.com/mariusmuja/flann 这里的代码，原文中的链接http://people.cs.ubc.ca/\sim mariusm/index.php/FLANN/FLANN 已经失效了，结合 mnist1NNdemo 来对 MNIST 数据进行分类。看看能加速多少，然后准确度是否有下降？

### 练习 1.3 对 KNN 分类器进行交叉验证

使用本书配套程序 pmtk3 中的 knnClassifyDemo 来投图测试集上误分类率的交叉验证估计。和图1.21(a)进行对比，讨论测试误差率的相似和不同。








# MLAPP 读书笔记 - 02 概率

> A Chinese Notes of MLAPP，MLAPP 中文笔记项目 
https://zhuanlan.zhihu.com/python-kivy

记笔记的人：[cycleuser](https://www.zhihu.com/people/cycleuser/activities)

2018年05月07日11:07:07

## 2.1 概率论简介


>概率论就是把常识降维表达成计算而已。---皮埃尔 拉普拉斯(Pierre Laplace)1812

前面的章节里，可以看出概率论在机器学习里面扮演了很重要的角色。所以本章就详细讲一下概率论。不过本章内容不可能面面俱到而且也不会过分强调细节，所以你最好还是找一本参考书来看看啥的。本章会涉及到后文要用到的很多关键概念和思路。

在讲解具体内容之前，先停下来想一下，什么是概率？我们都很熟悉这种说法：一枚硬币人头朝上的概率是0.5.但这句话到底是什么意思？实际上对概率有两种不同解读。

第一种是频率论阐述(frequentist interpretation)，这种观点认为概率表现长时间下事件的频率。例如上一句中所说，只要足够多次地抛硬币，人头朝上的次数就是一半。

另一种是对概率的贝叶斯阐述(Bayesian interpretation)。这种观点是概率是用来衡量某种事物的不确定性(uncertainty)，与信息更相关，而不是实验的重复(Jaynes 2003)。按照这种观点，上面说硬币的那句话的意思就是我们相信下次抛硬币两面朝上的概率各半。

贝叶斯解释的阐述的一个很大的好处是可以用于对具有不确定性的时间进行建模，而不必要进行长期频率测试。比如估算到 2020年的时候极地冰盖的融化量。这事情可能发生也可能不发生，但不能重复啊。我们也本应对某事的不确定性进行定量衡量；基于我们队这件事发生概率的认知，就可以采取近似行动，这部分参考本书5.7 讲解了在不确定情况下最优选择的相关讲解。在机器学习方面一个例子就是电子邮件判断是否为垃圾邮件。再比如就是雷达上发现一个小点，我们可能要计算该位置对应物体的概率分布，推断是鸟、飞机还是导弹。所有这类场景中，重复实验的思路都是不可行的，但贝叶斯阐述则是可用的，而且也符合直觉。因此本书对概率的解读就采用了贝叶斯阐述。好在概率论的基础内容都是相似的，也不受到所选阐述方式的影响。

此处查看原书图 2.1



## 2.2 概率论简单回顾

这部分就是简单回顾一下概率论的基础内容，读者如果对概率论生疏了可以看看，如果还很熟悉这些基本内容 就没必要看了，略过即可。


### 2.2.1 离散随机变量

表达式p(A)是指 A 事件发生(为真)的概率。A 可以是逻辑判断表达式，比如：“明天会下雨”。根据概率定义就可以知道$0\leq p(A) \leq 1$，如果p(A)=0则意味着绝对不会发生，如果p(A)=1则意味着必然发生。用$p(\bar A)$表示事件 A 不发生的概率；很显然，$p(\bar A) = 1- p(A)$。当事件 A 为真的时候通常还简写做  A=1，反之写为 A=0。这就跟布尔运算那个类似了。


对这个二值事件的记号进行扩展，可以定义一个离散随机变量(discrete random variable)X，这个随机变量可以从任意的一个有限元素集合或者无限但可列的集合 *X* 中取值。将 X = x 的概率记作$p(X=x)$，或者缩写成$p(x)$。这里的$p()$也叫做概率质量函数(probability mass function，缩写为 pmf)。跟上面的一样，也要满足$0\leq p(x) \leq 1$ 和$\sum_{x\in X}p(x)=1$。如图2.1所示的就是两个密度函数，定义在有限状态空间$x=\{1,2,3,4,5\}$。左边的是一个均匀分布，$p(x)=1/5$，右面的则是一个退化分布(degenerate distribution)，$p(x)=\prod (x=1)$，其中的$\prod()$是二值指标函数(binary indicator function)。这个分布表示的是 X 就总是1，也就是说是固定值。


### 2.2.2 基本规则

这部分讲的是概率论基本规则。

#### 2.2.2.1 两个事件的结合概率

给定两个事件，A 和 B，可以用如下方式来定义结合概率：

$p(A ∨ B) = p(A) + p(B) − p(A ∧ B)$ (2.1)
$p(A ∨ B) = p(A) + p(B)  \text{若两个事件互斥(mutually exclusive)}$ (2.2)

译者注：其实2.2毫无必要，因为两个事件互斥的时候也就是2.1里面的最后一项$p(A ∧ B) =0$所以根本没必要单独定义。 




#### 2.2.2.2 联合概率

两个事件 A 和 B 的联合概率定义如下所示：

$p(A,B) = p(A ∧ B) = p(A|B)p(B)$ (2.3)

这也叫做乘法规则(product rule)。对两个事件的联合概率分布$p(A,B)$，可以以如下方式定义边缘分布(marginal distribution)：

$p(A)=\sum_b p(A,B) =\sum_b p(A|B=b)p(B=b)$(2.4)

上式中对所有可能的状态 B 来进行求和。对$p(B)$的定义与之相似。也有时候也叫做加法规则(sum rule)或者全概率规则(rule of total probability)

乘法规则可以多次使用，就得到了链式规则(chain rule)：

$p(X_{1:D})=p(X_1)p(X_2|X_1)p(X_3|X_2,X_1)p(X_4|X_1,X_2,X_3) ... p(X_D|X_{1:D-1})$(2.5)

上面的1:D表示的是有序集合{1,2,...,D}。


#### 2.2.2.3 条件概率

若事件 B 为真，在此条件下事件 A 的条件概率如下所示：

$p(A|B) = p(A,B)/p(B)  if p(B)>0$ (2.6)

### 2.2.3 贝叶斯规则

结合条件概率的定义以及乘法规则和加法规则，就能推出贝叶斯规则(Bayes rule)，也称为贝叶斯定理(Bayes Theorem)：


$p(X=x|Y=y) = \frac{p(X=x,Y=y) }{p(Y=y) } = \frac{p(X=x)p(Y=y|X=x)}{\sum_{\dot x}p(X=\dot x)p(Y=y|X=\dot x) }$ (2.7)


#### 2.2.3.1 样例：医疗诊断

假如一位四十岁的女性，决定通过乳腺 X光检测(mammogram)做乳腺癌检测。如果结果是阳性，那么有多大概率患上？很明显这依赖于检测本身的可靠性。假设这个检测的敏感度(sensitivity)是80%，也就是如果一个人患上了，那么被检测出来是阳性的概率为0.8.即：

$p(x=1|y=1)=0.8$(2.8)

其中的 x=1意思就是检测结果阳性，而 y=1的意思是确实患病。
据此很多人就认为患病概率也就是80%。这是错误的！
这个计算方法忽略了患病的先验概率(prior probability)，即：
$p(y=1)=0.004$(2.9)

把这个先验概率忽略掉，就是基本比率谬误(base rate fallacy)。此外还要考虑的就是测试本身的假阳性(false positive)或者假警报(false alarm)的概率：

$p(x=1|y=0)$(2.10)

上面三个项目都结合起来，应用贝叶斯规则，可以计算正确概率了：

$\begin{aligned}
p(y=1|x=1) & =\frac{p(x=1|y=1)p(y=1)}{p(x=1|y=1)p(y=1)+p(x=1|y=0)p(y=0)}\\
& =\frac{0.8 \times 0.004}{0.8 \times 0.004 +0.1 \times 0.996}\\
& =0.031   
\end{aligned}
$(2.11、2.12)


上式中$p(y=0)=1-p(y=1)=0.996$。也就是说即便检测结果是阳性，患病概率也只有3%而已。

#### 2.2.3.2 样例：生成分类器

对上面医疗诊断的例子进行泛化，就可以对任意类型的特征向量 x 来进行分类了，如下所示：

$p(y=c|x,\theta)=\frac{p(y=c|\theta)p(x|y=c,\theta)}{\sum_{\dot c}p(y=\dot c|\theta)p(x|y=\dot  c,\theta)}$(2.13)


+这就是生成分类器(Generative classiﬁers)，使用类条件概率密度$p(x|y=c)$和类先验概率密度$p(y=c)$来确定如何生成数据。更多细节在本书第3、4章。另一种方法是直接拟合类后验概率密度$p(y=c|x)$，这就叫辨别式分类器(discriminative classifier)。这两种方法的优劣在本书8.6有详细讲解。

### 2.2.4 独立分布和有条件独立分布

此处查看原书图 2.2

X 和 Y 为无条件独立(unconditional independent)或者边缘独立(marginally independent)，记作$X \bot Y$，如果用两个边缘的积来表示，则如图2.2所示：

$X \bot Y \iff p(X,Y)=p(X)p(Y)$(2.14)

总的来说，如果联合分布可以写成边缘的积的形式，就可以说一系列变量之间相互独立(mutually independent)。

不过很可惜，这种无条件独立的情况是很少见的，大多数情况下变量之间都互相关联。好在一般这种影响都可以通过其他变量来传导的，而不是直接的关联。如果X 和 Y 对于给定的 Z 来说有条件独立，则意味着能够将条件联合分布写成条件边缘的积的形式，就说 ：

$X \bot Y |Z \iff p(X,Y|Z)=p(X|Z)p(Y|Z)$(2.15)

在本书第10章会谈到图模型，到时候会把这个假设写成图 X-Z-Y 的形式，更直观表现了 X 和 Y 之间的独立性由 Z 传导。例如，确定当天是否下雨(事件 Z)，则明天是否下雨(事件 X)和当天土地是否湿润(事件 Y)之间独立。
直观来说，这是因为 Z 可以同时导致 X 和 Y，所以如果知道了 Z，就不需要知道 Y 就可以预测 X，反之亦然。第10章会详细介绍这部分内容。

条件独立分布的另外一个特点是：

#### 定理 2.2.1 
$X\bot Y| Z$则意味着存在着函数 g 和 h ，对全部的x,y,z，在p(z)>0的情况下满足下列关系：

$p(x,y|z)=g(x,z)h(y,z)$(2.16)

练习2.8有详细证明过程。

条件概率假设让我们可以从小处着手构建大兴的概率模型。本书中有很多这样的样例，尤其是本书的3.5当中就提到了朴素贝叶斯分类器(naive Bayes classifiers)，在本书17.2还有马尔科夫模型(Markov models)，在本书第10章有图模型(graphical models)，所有这些模型都充分利用了条件概率的性质。


### 2.2.5 连续随机变量

签名谈到的都是具有不确定性的离散量。接下来就要将概率论扩展应用到具有不确定性的连续量。

设 X 是一个不确定的连续量。X 在某个空间$a\leq X\leq b$的概率可以用如下方式计算。
先定义如下事件：
$$
\begin{aligned}
A & =(X\le a)\\
B & =(X\le B)\\
W & =(a\le X\le b)
\end{aligned}
$$

很明显有
$B=A\bigvee W$，由于 A 和 W 是相互独立的，所以可以用加法规则：
$p(B)=p(A)+p(W)$(2.17)
显然有：
$p(w)=p(B)-p(A)$(2.18)

此处查看原书图 2.3


定义一个函数$F(q) \overset{\triangle}{=} p(X\le q)$，这就是 X 的累积分布函数(cumulative distribution function，缩写为 cdf)。很明显这个 cdf 是一个单调递增函数(monotonically increasing function)。如图2.3(a)所示。来利用这个记号则有：

$p(a<X\le b) =F(b)-F(a)$(2.19)

接下来假设这个函数 F(x)可导，则定义函数$f(x)=\frac{d}{dx}F(x)$，这个函数就叫概率密度函数(probability density function，缩写为 pdf)。参考图2.3(b)。有了 pdf，就可以计算一个有限区间上的连续变量的概率了：

$P(a<X\le b)= \int_a^b f(x)dx$(2.20)


随着这个区间逐渐缩小，直到趋向于无穷小，就可以得到下面的形式：

$P(x<X\le x+dx)\approx  p(x)dx$(2.21)

我们要满足$p(x)\ge 0$，但对于任意的 x，$p(x)\ge 1$也有可能，只要密度函数最终积分应该等于1就行了。举个例子，下面的正态分布Unif(a,b)：

$Unif(x|a,b)= \frac{1}{b-a}\prod(a\le x\le b)$(2.22)

如果设置$a=0,b=\frac1 2$，则有了对于在$x\in [0,\frac 12]$之间取值的任意 x 都有$p(x)=2$，


### 2.2.6 分位数

由于累积分布函数(cdf) F 是一个单调递增函数，那就有个反函数，记作$F^-$。如果 F 是 X 的累积分布函数(cdf)，那么$F^{-1}(\alpha)$就是满足概率$P(X\le x_\alpha )=\alpha$的值；这也叫做 F 的$\alpha$分位数(quantile)。$F^{-1}(0.5)$就是整个分布的中位数(median)，左右两侧的概率各自一半。而$F^{-1}(0.25)$和$F^{-1}(0.75)$则是另外两个分位数。

利用这个累积分布函数(cdf)的反函数还可以计算尾部概率(tail area probability)。例如，如果有高斯分布$N(0,1)$，$\phi$ 是这个高斯分布的累积分布函数(cdf)，这样在$\phi^{-1}(\alpha/2)$ 左边的点就包含了$\alpha /2$概率密度，如图2.3(b)所示。与之对称，在$\phi^{-1}(1-\alpha/2)$ 右边的点也包含了$\alpha /2$概率密度。所以呢，在$(\phi^{-1}(\alpha/2),\phi^{-1}(1-\alpha/2))$ 就包含了$1-\alpha$的概率密度。如果设置$\alpha =0.05$，那么中间这个区间就占了全部概率的95%了。

$(\phi^{-1}(0.025),\phi^{-1}(0.975))=(-1.96，1.96)$(2.23) 

如果这个正态分布是$N(\mu,\sigma^2)$，那么其95%的区间就位于$(\mu-1.96\sigma，\mu+1.96\sigma)$。有时候就简写一下成了$\mu\pm 2\sigma$。


### 2.2.7 均值(Mean)和方差(variance)

对正态分布来说，大家最常见常用的属性估计就是均值(mean)，或者称之为期望值(expected value)，记作$\mu$。对于离散 rv (译者注：这个 rv 很突兀，之前没出现，也没解释是啥,推测是 random variables)的情况，可以定义成$\mathrm{E}[X] \overset{\triangle}{=} \sum_{x\in X}xp(x)$；对于连续 rv 的情况，可以定义为$\\mathrm{E}[X] \overset{\triangle}{=} \int_{X}xp(x)dx$。如果这个积分是无穷的，则均值不能定义，更多例子后文会有。

然后就是方差(variance)了，这个表征的是分布的“散开程度(spread)”，记作$\sigma^2$。定义如下：

$$
\begin{aligned}
var[X] * & =\mathrm{E}[(X-\mu)^2]=\int(x-\mu)^2p(x)dx      &\text{           (2.24)}\\
& =  \int x^2p(x)dx  +\mu^2 \int p(x)dx-2\mu\int xp(x)dx=\mathrm{E}[X^2]-\mu^2         &    \text{           (2.25)}\\
\end{aligned}
$$

从上面的式子就可以推导出：
$\mathrm{E}[X^2]= \mu^2+\sigma^2$(2.26)
然后就可以定义标准差(standard deviation)了：
$std[X]\overset{\triangle}{=} \sqrt {var[X]}$(2.27)
标准差和 X 单位一样哈。


## 2.3 常见的离散分布 

本节介绍的是一些常用的定义在离散状态空间的参数分布，都是有限或者无限可列的。

### 2.3.1 二项分布和伯努利分布

设咱们抛硬币 n 次，设$X\in \{0,...,n\}$ 是人头朝上的次数。如果头朝上的概率是$\theta$，这就可以说 X 是一个二项分布(binomial distribution)，记作$X\sim Bin(n,\theta)$。则 pmf(probability mass function的缩写,概率质量函数)可以写作：
$Bin(k|n,\theta)\overset{\triangle}{=} \binom{n}{k} \theta ^k  (1- \theta)^{n-k}$(2.28)
上式中的
$ \binom{n}{k} \overset{\triangle}{=} \frac{n!}{(n-k)!k!}$(2.29)
是组合数，相当于国内早期教材里面的$C_n^k$，从 n 中取 k 个样的组合数，也是二项式系数(binomial coefficient)。如图2.4所示就是一些二项分布。

此处查看原书图 2.4



这个分布的均值和方差如下所示：
$mean=\theta, var =n\theta(1-\theta)$(2.30)

换个思路，如果只抛硬币一次，那么$X\in \{0,1 \}$就是一个二值化的随机变量，成功或者人头朝上的概率就是$\theta$。这时候就说 X 服从伯努利分布(Bernoulli distribution)，记作$X \sim  Ber(\theta)$，其中的概率质量函数 pmf 定义为：
 
$Ber(x|\theta)=\theta^{\prod (x=1)}(1-\theta)^{\prod (x=0)}$(2.31)

也可以写成：
$$
Ber(x|\theta)=\begin{cases} \theta &\text{ if x =1} \\
1-\theta &\text{ if x =0} \end{cases}
$$ (2.32)

很明显，伯努利分布只是二项分布中 n=1 的特例。


### 2.3.2 多项式(multinomial)分布和多重伯努利(multinoulli)分布

二项分布可以用于抛硬币这种情况的建模。要对有 K 个可能结果的事件进行建模，就要用到多项分布(multinomial distribution)。这个定义如下：设$x=(x_1,...,x_K)$ 是一个随即向量，其中的$x_j$是第 j 面出现的次数个数。这样 x 的概率质量函数 pmf 就如下所示：

$Mu(x|n,\theta)*- \binom {n}{x_1,..,x_K}\prod^K_{j=1}\theta^{x_j}_j$(2.33)

其中的$\theta_j$是第 j 面出现的概率，另外那个组合数的计算如下所示：
$\binom {n}{x_1,...,x_K} \overset{\triangle}{=} \frac{n!}{x_1!x_2!...x_K!}$(2.34)

这样得到的也就是多项式系数(multinomial coefficient)，将一个规模为$n=\sum^K_{k=1}$的集合划分成规模从$x_1$到$x_K$个子集的方案数。 

接下来设 n=1。这就好比是讲一个 K 面的骰子只投掷一次，所以 x 就是由 0 和 1 组成的向量。其中只有一个元素会是1.具体来说就是如果 k 面朝上，就说第 k 位为1。这样就可以把 x 看做一个用标量分类的有 K 个状态的随机变量，这样 x 就是自己的虚拟编码(dummy encoding)，即：$x=[\prod(x=1),...,\prod(x=K)]$。例如，如果 K=3，那么状态1、2、3对应的虚拟编码分别是(1,0,0),(0,1,0),(0,0,1)。这样的编码也称作单位有效编码(one-hot encoding)，因为只有一个位置是1.这样对应的概率质量函数 pmf 就是：

$Mu(x|1,\theta)=\prod^K_{j=1 }\theta_j ^{\prod(x_j=1)}$(2.35)

可以参考图2.1的(b-c)作为一个例子。这是类别分布(categorical distribution)或者离散分布(discrete distribution)的典型案例。Gustavo Lacerda 建议大家称之为多重伯努利分布(multinoulli distribution)，这样与二项分布/伯努利分布的区别关系相仿。本书就采用了这个术语，使用下列记号表示这种情况：

$Cat(x|\theta)\overset{\triangle}{=} Mu(x|1,\theta)$(2.36)

 换句话说，如果$x\sim Cat(\theta)$，则$p(x=j|theta)=\theta_j$。参考表2.1。




#### 2.3.2.1 应用：DNA 序列模体

此处查看原书图 2.5


生物序列分析(biosequence analysis)是一个典型应用案例，设有一系列对齐的 DNA 序列，如图2.5(a)所示，其中有10行(序列)，15列(沿着基因组的位置)。如图可见其中几个位置是进化的保留位，是基因编码区域的位置，所以对应的列都是“纯的”，例如第7列就都是 G。

如图2.5(b)所示，对这种数据的可视化方法是使用序列标识图(sequence logo)。具体方法是把字幕ACGT 投到对应位置上，字体大小与其实验概率(empirical probability)成正比，最大概率的字幕放在最顶部。

对计数向量归一化，得到在位置$t,\hat \theta_t$的经验概率分布，可以参考本书的公式3.48：
$N_t=(\sum^N_{i=1}\prod(X_{it}=1),\sum^N_{i=1}\prod(X_{it}=2),\sum^N_{i=1}\prod(X_{it}=3),\sum^N_{i=1}\prod(X_{it}=4))$(2.37)
$\hat\theta_t =N_t/N$(2.38)

这个分布就被称作一个模体(motif)。可以计算每个位置上最大概率出现的字母，得到的就是共有序列(consensus sequence)。


### 2.3.3 泊松分布(Poisson Distribution)



如果一个离散随机变量$X\in \{0,1,2,...\}$服从泊松分布，即$X\sim  Poi(\lambda)$，其参数$\lambda >0$，其概率质量函数 pmf 为：

$Poi(x|\lambda )=e^{-\lambda}\frac{\lambda ^x}{x!}$(2.39) 

第一项是标准化常数(normalization constant)，使用来保证概率密度函数的总和积分到一起是1.
泊松分布经常用于对罕见事件的统计，比如放射性衰变和交通事故等等。参考图2.6是一些投图样本。



此处查看原书图 2.6

### 2.3.4 经验分布(empirical distribution)

某个数据集，$D =\{x_1,...,x_N \}$，就可以定义一个经验分布，也可以叫做经验测度(empirical measure)，形式如下所示：

$p_{emp}(A)\overset\triangle{=}\frac 1 N \sum^N_{i=1}\delta _{x_i}(A)$(2.40)

其中的$\delta_x(A)$是狄拉克测度(Dirac measure)，定义为：
$$
\delta_x(A)= \begin{cases} 0 \text{    if }x \notin A \\
1\text{    if }x \in A 
\end{cases}
$$(2.41)

一般来说可以给每个样本关联一个权重(weight)
$p(x)=\sum^N_{i=1}w_i\delta_{x_i}(x)$(2.42)

其中要满足$0\le w_i \le 1$以及$\sum^N_{i=1}w_i=1$。可以想象成一个直方图(histogram)，其中每个点$x_i$位置都有各自的峰(spike)，而$w_i$决定了峰值i 的高低。这个分布中，所有不在数据集中的点就都设为0了。

## 2.4 一些常见的连续分布

接下来介绍一些常用的单变量一维连续概率分布。

### 2.4.1 高斯(正态)分布

不管是统计学还是机器学习里面，最广泛使用的都是高斯分布了，也叫做正态分布。其概率密度函数 pdf 为：
$N(x|\mu,\sigma^2) \overset{\triangle}{=} \frac {1}{\sqrt{2\pi \sigma^2}} e^ {-\frac{1}{2 \sigma^2}(x-\mu)^2}$(2.43)

上式中的$\mu=\mathrm{E}[X]$是均值(mean)也是众数(mode),$\sigma^2=var[X]$ 是方差(variance)。$\sqrt{2\pi \sigma^2}$是归一化常数(normalization constant)，用于确保整个密度函数的积分是1，具体可以参考练习2.11。

可以写成$X \sim  N(\mu,\sigma^2)$来表示$p(X=x)=N(x|\mu,\sigma^2)$。$X \sim  N(0,1)$就是标准正态分布(standard normal distribution)。图2.3(b)是这样一个标准正态分布的概率密度函数图像，也被称作钟形曲线。

所谓高斯分布的精确率(precision)就是方差的倒数$\lambda =1/\sigma^2$。精确率高的意思也就是方差低，而整个分布很窄，对称分布在均值为中心的区域。

要注意这是一个概率密度函数(pdf)，所以完全可以$p(x)>1$。比如在中心位置，$x=\mu$,这样就有$N(\mu\mu,\sigma^2)=(\sigma\sqrt{2\pi})^{-1 }e^0$,所以如果$\sigma< 1/\sqrt{2\pi}$,这样就有$p(x)>1$.

高斯分布的累积分布函数(cdf)为:

$\phi(x;\mu , \sigma^2)\overset{\triangle}{=} \int^x_{-\infty}N(z|\mu,\sigma^2)dz$(2.44)


图2.3(a) 所示为当$\mu=0,\sigma^2=1$时候的 cdf 函数曲线.这个函数的积分没有闭合形式表达式,不过在多数软件包里面都内置了.另外还能以误差函数(error function,缩写为 erf)的形式来计算:


$\phi(x;\mu , \sigma^)\overset{\triangle}{=} \frac 1 2[1+erf(z/\sqrt2)]$(2.45)

其中的$z=(x-\mu)/\sigma$,误差函数为:
$erf(x)\overset{\triangle}{=} \frac{2}{\sqrt\pi}\int^x_0e^{-t^2}dt$(2.46)

高斯分布是统计学里面用的最广的分布,有几个原因.首先是这两个参数很好解释,分别对应着分布中的两个基础特征,均值和方差.其次中心极限定理( central limit theorem, 参考本书2.6.3)也表明独立随机变量的和旧近似为高斯分布,所以高斯分布很适合用来对残差或者噪音建模.然后高斯分布有最小假设数(least number of assumptions),最大熵(maximum entropy),适合用于有特定均值和方差情境下建立约束,如本书9.2.6所述,这就使得高斯分布是很多情况下很不错的默认选择.另外,高斯分布的数学形式也很简单,容易实现,效率也很高.高斯分布更广泛应用参考 Jaynes 2003 第七章.

### 2.4.2 退化概率分布函数(Degenerate pdf)


如果让方差趋近于零,即$\sigma^2 \rightarrow 0$,那么高斯分布就变成高度为无穷大而峰值宽度无穷小的形状了,中心当然还是在$\mu$位置:
$\lim_{\sigma^2\rightarrow 0} N(x| \mu,\sigma^2) =\delta (x-\mu)$(2.47)

这个新的分布函数$\delta$就叫做狄拉克函数(Dirac delta function).其定义为:
$$
\delta(x)=\begin{cases}\infty \text{   if   } x=0\\ 
0 \text{   if   } x\ne 0
\end{cases}
$$(2.48)

这样进行积分也有
$\int_{-\infty} ^\infty \delta(x)dx=1$(2.49)

这个狄拉克函数的有个特点就是筛选特性(sifting property),从一系列求和或者积分当中筛选了单一项目:

$\int_{-\infty} ^\infty f(x) \delta(x-\mu )dx=f(\mu )$(2.50)

只有当$x-\mu =0$的时候这个积分才是非零的.

高斯分布有个问题就是对异常值很敏感,因为从分布中心往外的对数概率衰减速度和距离成平方关系(since the logprobability only decays quadratically with distance from the center).
有一个更健壮的分布,就是所谓的 T 分布或者也叫学生分布(student distribution),其概率密度函数如下所示:

$T(x|\mu,\sigma^2,v)\propto [1+\frac 1v (\frac{x-\mu}{\sigma})^2 ]^ {-(\frac {v+1}{2})}$(2.51)

上式中的$\mu$是均值,$\sigma^2>0$是范围参数(scale parameter),$v>0$称为自由度( degrees of freedom). 如图2.7就是该函数的曲线.为了后文用起来方便,这里特地说一下几个属性:
$mean=\mu, mode=\mu,var=\frac{v\sigma^2}{v-2}$(2.52)

这个模型中,当自由度大于2$v>2$的时候方差才有意义,自由度大于1$v>1$均值才有意义.

此处查看原书图 2.7

此处查看原书图 2.8

T 分布的稳定性如图2.8所示,左侧用的是没有异常值的高斯分布和T 分布,右侧是加入了异常值的.很明显这个异常值对于高斯分布来说干扰很大,而 T 分布则几乎看不出来有影响.因为 T 分布比高斯分布更重尾(heavier tails), 至少对于小自由度 v 的时候是这样,如图2.7所示.

如果自由度 v=1,则 T 分布就成了柯西分布(Cauchy distribution)或者洛伦兹分布(Lorentz distribution) .要注意这时候重尾(heavy tails)会导致定义均值(mean)的积分不收敛.

要确保有限范围的方差(ﬁnite variance), 就需要自由度 v>2.一般常用的是自由度v=4,在一系列问题中的性能表现也都不错(Lange 等1989).如果自由度远超过5,即$v\gg 5$,T 分布就很快近似到高斯分布了,也就失去了健壮性(robustness)了.

此处查看原书图 2.9

### 2.4.3 拉普拉斯分布(Laplace distribution)

另外一个常用的重尾分布就是拉普拉斯分布,也被称为双面指数分布(double sided exponential distribution),概率密度函数如下所示:

$Lap(x|\mu,b)\overset\triangle{=}\frac1{2b}\exp(-\frac{|x-\mu|}{b})$(2.53)

上式中的$\mu$是位置参数(location parameter), b>0 是缩放参数(scale parameter),如图2.7所示就是其曲线.这个分布的各个属性如下所示:

$mean=\mu, mode=\mu,var=2b^2$(2.54)
这个分布的健壮性(robustness)如图2.8中所示,另外从图中也可以发现拉普拉斯分布比高斯分布在0点有更多概率.这个特性在本书13.3的时候还要用到,很适合用于在模型中增强稀疏性(encourage sparsity).

### 2.4.4$\gamma$分布



这个分布很灵活,适合正实数值的rv, x>0. 用两个参数定义,分别是形状参数(shape) a>0  和频率参数(rate) b>0:

$Ga(T|shape=a, rate=b)\overset{\triangle}{=}  \frac{b^a}{\Gamma(a) }T^{a-1}e^{-Tb}$(2.55)

上式中的$\Gamma(a)$是一个$\gamma$函数:
$\Gamma(x) \int_0^{\infty} u^{x-1}e^{-u}du$(2.56)


参考图2.9就是一些样例图像.这个分布的各个属性如下所示:

$mean=\frac{a}{b}, mode=\frac{a-1}{b},var=\frac{a}{b^2}$(2.54)

有一些分布实际上就是$\gamma$分布的特例, 比如下面这几个:


* 指数分布(Exponential distribution)定义是$Expon(x|\lambda)\overset{\triangle}{=} Ga(x|1,\lambda)$,其中的$\lambda$是频率参数(rate).这个分布描述的是泊松过程(Poisson process) 中事件之间的时间间隔.例如,一个过程可能有很多一系列事件按照某个固定的平均频率$\lambda$连续独立发生.
* 厄兰分布(Erlang Distribution)就是一个形状参数 a 是整数的$\gamma$分布,一般会设置 a=2,产生的是一个单参数厄兰分布,$Erlang(x|\lambda) = Ga(x|2, \lambda),$,$\lambda$也是频率参数.
* 卡方分布(Chi-squared distribution)定义为$\chi ^2 (x|ν) \overset\triangle{=}Ga(x|\fracν2,\frac12 )$.这个分布是高斯分布随机变量的平方和的分布.更确切地说,如果有一个高斯分布$Z_i \sim  N(0, 1),$,那么其平方和$S=\sum_{i=1}^vZ_i^2$则服从卡方分布$S \sim  \chi_v^2$.

另一个有用的结果是:如果一个随机变量服从$\gamma$分布:$X \sim  Ga(a,b)$ 那么这个随机变量的导数就服从一个逆$\gamma$分布(inverse gamma),即$\frac 1X \sim  IG(a,b)$,这个在练习2.10里面有详细描述.逆$\gamma$分布(inverse gamma)定义如下:


$IG(x|shape =a,scale =b)\overset{\triangle}{=} \frac{b^a}{\Gamma (a)}x^{-(a+1)} e^{-\frac b x}$(2.58)

这个逆$\gamma$分布的三个属性 如下所示:

$ mean= \frac{b}{a-1},mode=\frac{b}{a+1},var=\frac{b^2}{(a-1)^2(a-2)}$(2.59)

这个均值只在 a>1 的情况下才存在,而方差仅在 a>2 的时候存在.


### 2.4.5$\beta$分布

此处查看原书图 2.10


$\beta$分布支持区间[0,1],定义如下:


$Beta(x|a,b)=\frac{1}{B(a,b)}x^{a-1 }(1-x)^{b-1}$(2.60)

上式中的$B(a,b)$是一个$\beta$函数,定义如下:

$B(a,b)\overset\triangle{=}\frac{\Gamma (a)\Gamma (b)}{\Gamma (a+b)}$(2.61)

这个分布的函数图像可以参考图2.10.需要 a 和 b 都大于零来确保整个分布可以积分,这是为了保证$B(a,b)$存在.如果 a=b=1, 得到的就是均匀分布(uniform distirbution),如图2.10中红色虚线所示.如果 a 和 b 都小于1,那么得到的就是一个双峰分布(bimodal distribution),两个峰值在0和1位置上,如图2.10中的蓝色实线所示.如果 a 和 b 都大于1了,得到的就是单峰分布(unimodal distribution) 了,如图2.10中的另外两条虚线所示.这部分内容在练习2.16里会用到.这个分布的属性如下:

$ mean= \frac{a}{a+b},mode=\frac{a-1}{a+b-2},var=\frac{ab}{(a+b)^2(a+b+1)}$(2.52)



### 2.4.6 柏拉图分布(Pareto distribution)

这个分布是用来对有长尾(long tails)或称为重尾(heavy tails)特点的变量进行建模的.例如,英语中最常出现的词汇是冠词 the, 出现概率可能是第二位最常出现词汇 of 的两倍还多, 而 of 也是第四位的出现次数的两倍,等等.如果把每个词汇词频和排名进行投图,得到的就是一个幂律(power law),也称为齐夫定律(Zipf's law).财富的分配也有这种特点,尤其是在美帝这种腐朽的资本主义国度.

柏拉图分布的概率密度函数(pdf)如下所示:
$Pareto(x|k,m)=km^kx^{-(k+1)}\prod(x\geq m)$(2.63)

通过定义可知, x 必须必某一个常数 m 大,但又不用大特别多,而其中的 k 就是控制这个的,避免 x 太大.随着$k \rightarrow \infty$,这个分布就接近于狄拉克分布$\delta(x-m)$了.参考图2.11(啊) 就是一些此类分布函数的图像,如果用对数坐标来进行投图,就会形成一条直线,如图2.11(b) 所示那样.这个直线的方程形式就是$\log p(x)=a\log x+c$,其中的 a 和 c 是某个常数.这也叫幂律(power law).这个分布的属性如下所示:

$mean=\frac{km}k-1{} \text{   if }k>1,mode=m, var =\frac{m^2k}{(k-1)^2(k-2)} \text{   if }k>2$(2.64)



此处查看原书图 2.11


## 2.5 联合概率分布

签名的都是单变量的概率分布,接下来要看看更难的,就是联合概率分布( joint probability distributions),其中要涉及到多个相关联的随机变量,实际上这也是本书的核心内容.

联合概率分布的形式是$p(x_1,...,x_D)$,这些随机变量属于一个规模为 D>1 的集合,对这些随机变量间 的(随机stochastic)关系进行建模,就要用联合概率分布.如果所有变量都是离散的,那就可以吧联合分布表示成一个大的多维数组,每个维度对应一个变量.若设每个变量的状态数目总共是 K, 那么这样要建模的话,需要定义的参数个数就达到了$O(K^D)$了.


### 2.5.1 协方差和相关系数

协方差(covariance)是用来衡量两组变量之间(线性)相关的程度的,定义如下:

$cov[X,Y]\overset{\triangle}{=} \mathrm{E}[(X-\mathrm{E}[X])(Y-\mathrm{E}[Y])] =\mathrm{E}[XY]-\mathrm{E}[X]\mathrm{E}[Y]$(2.65)

此处查看原书图 2.12

如果 x 是一个 d 维度的随即向量,那么它的协方差矩阵(covariance matrix) 的定义如下所示,这是一个对称正定矩阵(symmetric positive definite matrix):

$$\begin{aligned}
cov[x]*&= \mathrm{E}[(x-\mathrm{E}[x])(x-\mathrm{E}[x])^T] \text{    (2.66)}\\
&=  \begin{pmatrix}
        var[X_1] & cov[X_1,X_2] &...& cov[X_1,X_d]  \\
        cov[X_2,X_1]  & var[X_2]  &...&cov[X_2,X_d]  \\
        ...&...&...&...\\
       cov[X_d,X_1]  & cov[X_d,X_2] z &...&var[X_d] \\
        \end{pmatrix} \text{     (2.67)}\\
\end{aligned}
$$

协方差可以从0到$\infty$之间取值.有时候为了使用方便,可以只用其中的上半部分.

两个变量X 和 Y 之间的皮尔逊相关系数(correlation coefficient)定义如下:

$corr[X,Y]\overset{\triangle}{=} \frac{cov[X,Y]}{\sqrt{var[X]var[Y]}}$(2.68)

而相关矩阵(correlation matrix)则为:
$$
R= \begin{pmatrix}
        cov[X_1,X_1] & cov[X_1,X_2] &...& cov[X_1,X_d]  \\
        ...&...&...&...\\
       cov[X_d,X_1]  & cov[X_d,X_2] &...&var[X_d] \\
        \end{pmatrix} 
$$(2.69)

从练习4.3可知相关系数是在[-1,1]这个区间内的,因此在一个相关矩阵中,每一个对角线项值都是1,其他的值都是在[-1,1]这个区间内.

另外还能发现的就是当且仅当有参数 a 和 b 满足$Y = aX + b$的时候,才有$corr [X, Y ] = 1$,也就是说 X 和 Y 之间存在线性关系,参考练习4.3.

根据直觉可能有人会觉得相关系数和回归线的斜率有关,比如说像$Y = aX + b$这个表达式当中的系数 a 一样.然而并非如此,如公式7.99中所示,实际上回归系数的公式是$a = cov [X, Y ] /var [X]$.可以将相关系数看做对线性程度的衡量,参考图2.12.

回想本书的2.2.4,如果 X 和 Y 相互独立,则有$p(X, Y ) = p(X)p(Y )$,这样二者的协方差$cov[X,Y]=0$,相关系数$ corr[X,Y]=0$, 很好理解,相互独立就是不相关了.但反过来可不成立,不相关并不能意味着相互独立.例如设$X \sim  U(-1,1), Y=X^2$. 很明显吧,这两个是相关的对不对,甚至 Y 就是 X 所唯一决定的,然而如练习4.1所示,这两个变量的相关系数算出来等于零啊,即$corr[X,Y]=0$.图2.12有更多直观的例子,都是两个变量 X 和 Y 显著具有明显的相关性,而计算出来的相关系数却都是0.实际上更通用的用来衡量两组随机变量之间是否独立的工具是互信息量(mutual information),这部分在本书2.8.3当中有设计.如果两个变量真正不相关,这个才会等于0.

此处查看原书图 2.13


### 2.5.2 多元高斯分布

多元高斯分布(multivariate Gaussian)或者所谓多元正态分布(multivariate normal,缩写为MVN),是针对连续随机变量的联合概率分布里面用的最广的.在第四章会对其进行详细说明,这里只说一些简单定义并且给个函数图像瞅瞅.

在 D 维度上的多元正态分布(MVN)的定义如下所示:
$N(x|\mu,\Sigma)\overset{\triangle}{=} \frac{1}{(2\pi )^{\frac D2} |\Sigma|^{\frac12}}\exp [-\frac12 (x-\mu)^T\Sigma^{-1}(x-\mu) ]$(2.70)

上式中$\mu = E [x] \in R^D$是均值向量,而$\Sigma= cov [x]$ 一个$ D\times D$的协方差矩阵.有时候我们会用到一个名词叫做精度矩阵(precision/concentration matrix),这个就是协方差矩阵的逆矩阵而已,也就是$\Lambda =\Sigma^{-1 }$.前面那一团做分母的$(2\pi )^{\frac D2}|\Sigma|^{\frac12}$也还是归一化常数,为了保证这个概率密度函数的积分等于1,更多参考练习4.5

图2.13展示了一些多元正态分布的密度图像,其中有三个是三个不同协方差矩阵的下的二维投影,另外一个是立体的曲面图像.一个完整的协方差矩阵有$D(D + 1)/2$个参数,除以2是因为矩阵$\Sigma$是对称的.对角协方差矩阵的方向有 D 个参数,非对角线位置的元素的值都是0. 球面(spherical)或者各向同性(isotropic)协方差矩阵$\Sigma = \delta^2 I_D$有一个自由参数.

### 2.5.3 多元学生 T 分布

相比多元正态分布 MVN, 多元学生T 分布更加健壮,其概率密度函数为:
$$
\begin{aligned}
\Gamma (x|\mu,\Sigma,v)&=\frac{\Gamma (v/2+D/2)}{\Gamma (v/2+D/2)}  \frac{|\Sigma|^{-1/2}}{v^{D/2}\pi^{D/2}}\times [1+\frac1v(x-\mu )^T\Sigma^{-1}(x-\mu)]^{-(\frac{v+D}{2})}
&\text{   (2.71)}\\
&=\frac{\Gamma (v/2+D/2)}{\Gamma (v/2+D/2)} |\pi V|^{-1/2}\times [1+(x-\mu)^T\Sigma^{-1}(x-\mu)]^{-(\frac{v+D}{2})}
 &\text{   (2.72)}\\
\end{aligned}
$$

其中的$\Sigma$叫做范围矩阵(scale matrix),而并不是真正的协方差矩阵,$V=v\Sigma$.这个分布比高斯分布有更重的尾部(fatter tails).参数$v$越小,越重尾;而当$v\rightarrow \infty$则这个分布趋向为高斯分布.这个分布的属性如下所示:

$mean=\mu, mode=\mu,  Cov=\frac{v}{v-2}\Sigma$(2.73)

### 2.5.4 狄利克雷分布

$\beta$分布扩展到多元就成了狄利克雷分布(Dirichlet distribution),支持概率单纯形(probability simplex),定义如下:

$S_K={x:0 \le x_k \le 1, \sum ^K_{k=1}x_k=1}$(2.74)

其概率密度函数 pdf 如下所示:

$Dir(x|\alpha)\overset{\triangle}{=} \frac{1}{B(\alpha)} \prod^K_{k=1} x_k^{\alpha_k -1}\prod(x\in S_K)$(2.75)



此处查看原书图 2.14


此处查看原书图 2.15

上式中的$B(\alpha_1,...,\alpha_K)$是将$\beta$函数在 K 个变量上的自然推广(natural generalization),定义如下:

$B(\alpha)\overset{\triangle}{=} \frac{\prod^K_{k=1}\Gamma (\alpha_k)}{\Gamma (\alpha_0)}$(2.76)
其中的$\alpha_0\overset{\triangle}{=} \sum^K_{k=1}\alpha_k$.

图2.14展示的是当 K=3的时候的一些狄利克雷函数图像,图2.15是一些概率向量样本.很明显其中$\alpha_0\overset{\triangle}{=} \sum^K_{k=1}\alpha_k$控制了分布强度,也就是峰值位置.例如Dir(1, 1, 1)是一个均匀分布,Dir(2, 2, 2) 是以为(1/3, 1/3, 1/3)中心的宽分布(broad distribution),而Dir(20, 20, 20) 是以为(1/3, 1/3, 1/3)中心的窄分布(narrow distribution).如果对于所有的 k  都有$\alpha_k <1$,那么峰值在单纯形的角落.

这个分布的属性如下:
$ \mathrm{E}[x_k]=\frac{\alpha_k}{\alpha_0},mod\mathrm{E}[x_k]=\frac{\alpha_k-1}{\alpha_0-K},var[x_k]=\frac{\alpha_k(\alpha_0-\alpha_k)}{\alpha_0^2(\alpha_0+1)}$(2.77)

上式中的$\alpha_0 = \sum_k \alpha_k$.通常我们用对称的狄利克雷分布,$\alpha_k=\alpha/K$. 这样则有方差$var[x_k]=\frac{K-1}{K^2(\alpha+1)}$. 这样增大$\alpha$就能降低方差,提高了模型精度.


## 2.6 随机变量变换

如果有一个随机变量$x \sim p()$,还有个函数$y=f(x)$,那么 y 的分布是什么?这就是本节要讨论的内容.


### 2.6.1 线性变换

设$f()$是一个线性函数:
$y=f(x)=Ax+b$(2.78)

这样就可以推导 y 的均值和协方差了.首先算均值如下:
$\mathrm{E}[y]=\mathrm{E}[Ax+b]=A\mu+b$(2.79)

上市中的$\mu=\mathrm{E}[x]$.这就叫线性期望(linearity of expectation).如果$f()$ 是一个标量值函数(scalar-valued function)$f(x)=a^Tx+b$,那么对应结果就是:

$\mathrm{E}[a^Tx+b]=a^T\mu+b$(2.80)

对于协方差,得到的就是:

$cov[y]=cov[Ax+b]=A\Sigma A^T$(2.81)

其中的$\Sigma =cov[x]$, 这个证明过程留作联系.如果$f()$ 是一个标量值函数(scalar-valued function),这个结果就成了:
$var[y]=var[a^Tx+b]=a\Sigma a^T$(2.82)

 这些结果后面的章节都会多次用到.不过这里要注意,只有x 服从高斯分布的时候,才能单凭借着均值和协方差来定义 y 的分布.通常我们必须使用一些技巧来对 y 的完整分布进行推导,而不能只靠两个属性就确定.
 
 

### 2.6.2 通用变换

如果 X 是一个离散随机变量,$f(x)=y$, 推导 y 的概率质量函数 pmf,只要对所有x 的概率值了加到一起就可以了, 如下所示:
$p_y(y)=\sum_{x:f(x)=y}p_x(x)$(2.83)

例如,若X是偶数则$f(X)=1$,奇数则$f(X)=0$,$p_x(X)$是在集合$\{1, . . . , 10\}$上的均匀分布(uniform),这样$p_y (1) = x\in \{2,4,6,8,10\},  p_x (x) = 0.5,  p_y (0) = 0.5$.注意这个例子中的函数 f 是多对一的函数.
如果 X 是连续的随机变量,就可以利用公式2.83,因为$p_x (x)$是一个密度,而不是概率质量函数了,也就不能把密度累加起来了. 这种情况下用的就是累积分布函数 cdf 了,协作下面的形式:

$P_y(y)\overset\triangle{=}P(Y\le y)=P(f(X)\le y)=P(X\in\{x|f(x)\le y\})$(2.84)

对累积分布函数 cdf 进行微分,就能得到概率密度函数 pdf 了:

$P_y(y)\overset\triangle{=}P(Y\le y)=P(X\le f^{-1}(y))=P_x(f^{-1}(y))$(2.85)

求导就得到了:

$p_y(y)\overset{\triangle}{=} \frac{d}{dy}P_y(y)=\frac{d}{dy}P_x(f^{-1}(y)=\frac{dx}{dy}\frac{d}{dx}P-X(x)=\frac{dx}{dy}px(x)$(2.86)

显然$x=f^{-1}(y)$ ,可以把$dx$看作是对 x 空间的一种体测量;类似的把$dy$当作对 y 空间体积的测量.这样$\frac{dx}{dy}$就测量了体积变化.由于符号无关紧要,所以可以取绝对值来得到通用表达式:

$p_y(y)=p_x(x)|\frac{dx}{dy}|$(2.87)

这也叫变量转换公式(change of variables formula).按照下面的思路来理解可能更容易.落在区间$(x, x+\delta x)$的观测被变换到区间$(y, y+\delta y)$ , 其中$p_x (x)\delta x \approx p_y (y)\delta  y$.因此$p_y(y)\ approx p_x(x)|\frac{\delta x}{\delta y}|$.例如,假如有个随机变量$X \sim  U(-1,1) , Y=X^2$.那么则有$p_y(y)=\frac12y^{-\frac12}$. 具体看练习2.10.


#### 2.6.2.1 变量的多重变化(Multivariate change of variables)

前面的结果可以推到多元分布上.设$f$是一个函数,从$R^n$映射到$R^n$, 设$y=f(x)$. 那么就有这个函数的雅可比矩阵 J(Jacobian matrix):


$$
J_{x\rightarrow y } * = \frac{\partial(y_1,...,y_n)}{\partial(x_1,...,x_n)}\overset\triangle{=}
\begin{pmatrix}
        \frac{\partial y_1}{\partial x_1} & ...& \frac{\partial y_1}{\partial x_n}  \\
        ...&...&...\\
       \frac{\partial y_n}{\partial x_1}   &...&\frac{\partial y_n}{\partial x_n} \\
        \end{pmatrix} 
$$(2.88)

矩阵 J 的行列式|det J|表示的是在运行函数 f 的时候一个单位的超立方体的体积变化.
如果 f 是一个可逆映射(invertible mapping),就可以用逆映射$y\rightarrow x$的雅可比矩阵(Jacobian matrix) 来定义变换后随机变量的概率密度函数(pdf)

$p_y(y)=p_x(x)|det(\frac{\partial x}{\partial y})|=p_x(x)|detJ_{y\rightarrow x}$(2.89)
在练习4.5,你就要用到上面这个公式来推导一个多元正态分布的归一化常数(normalization constant).

举个简单例子,假如要把一个概率密度函数从笛卡尔坐标系(Cartesian coordinates)的$x=(x_1,x_2)$ 转换到一个极坐标系(polar coordinates)$y=(r,\theta )$, 其中有对应关系:$x_1=r \cos \theta,x_3=r \sin \theta$.这样则有雅可比矩阵如下:

$$
J_{y\rightarrow x }=
\begin{pmatrix}
        \frac{\partial x_1}{\partial r}  &\frac{\partial x_1}{\partial \theta}  \\
       \frac{\partial x_2}{\partial r} &\frac{\partial x_2}{\partial \theta} \\
        \end{pmatrix} =
\begin{pmatrix}
        \cos \theta   & -r \sin \theta \\
        \sin \theta   &   r\cos \theta\\
        \end{pmatrix} 
$$(2.90)

矩阵 J 的行列式为:

$|det J|=|r\cos^2\theta+r\sin^2\theta|=|r|$(2.91)

因此:

$p_y(y)=p_x(x)|det J|$(2.92)

$p_{r,\theta}(r,\theta)=p_{x_1,x_2}(x_1,x_2)r=p_{x_1,x_2}(r\cos\theta,r\sin\theta)r$(2.93)


以几何角度来看,可以参考图2.16,其中的阴影部分面积可以用如下公式计算:


$P(r \le R \le  r + dr, \theta  \le  \Theta  \le  \theta  + d\theta ) = p_{r,\theta}  (r, \theta )drd\theta$(2.94)


在这个限制范围内,这也就等于阴影中心部分的密度$p(r,\theta)$乘以阴影部分的面积,$rdrd\theta$.因此则有:

$p_{r,\theta}  (r, \theta )drd\theta= p_{x_1,x_2}(r\cos\theta,r\sin\theta)rdrd\theta$$(2.95)

此处查看原书图 2.16

此处查看原书图 2.17


### 2.6.3 中心极限定理(Central limit theorem)


现在设想有 N 个随机变量,概率密度函数(pdf)为p(x_i),且不一定是正态分布,每个的均值和方差都分别是$\mu,\sigma^2$.然后假设每个随机变量都市独立同分布的(independent and identically distributed,缩写成iid).设$S_N =\sum^N_{i=1 }X_i$是所有随机变量的和.这是一个很简单的变换,但应用很广.随着 N 的增大,这个和的分布会接近:


$p(S_N=s)=\frac{1}{\sqrt{2\pi N\sigma^2}}\exp(-\frac{(s-N\mu)^2}{2N\sigma^2})$(2.96)

所以这个量的分布就是:

$ Z_N \overset{\triangle}{=} \frac{S_N-N_{\mu}}{\sigma\sqrt N} = \frac{\bar X-\mu}{\sigma/\sqrt N}$(2.97)

这个分布就会收敛到标准正态分布了,其中样本均值为:$\bar X=\frac 1 N \sum^N_{i=1}x_i$.这就叫做中心极限定理,更多内容参考(Jaynes 2003, p222) 或者 (Rice 1995, p169).

图2.17即是一例,其中计算$\beta$分布变量均值,右图可见很快收敛到正态分布了.


## 2.7 蒙特卡罗近似方法(Monte Carlo approximation)

要计算一个随机变量的函数的分布,靠公式变换 通常还挺难的.有另外一个办法,简单又好用.首先就是从分布中生成 S 个样本,就把它们标为$x_1,...,x_S$.生成样本有很多方法,对于高维度分布来说最流行的方法就是马尔科夫链蒙特卡罗方法(Markov chain Monte Carlo,缩写为 MCMC),这部分内容在本书24章再行讲解.
还说这个例子,对分布函数$f(X)$使用经验分布(empirical distribution)$\{f(x_s )\}^S_{s=1}$来进行近似.这就叫蒙特卡洛近似(Monte Carlo approximation), 之所以用这个名字是因为欧洲的知名赌城.这种方法首先是在统计物理性里面应用发展起来的,确切来说还是在原子弹研究过程中,不过现在已经广泛应用在统计和机器学习领域里面了.

此处查看原书图 2.18


应用蒙特卡罗方法,可以对任意的随机变量的函数进行近似估计.先简单取一些样本,然后计算这些样本的函数的算术平均值(arithmetic mean).这个过程如下所示:

$\mathrm{E}[f(X)]=\int f(xp(x)dx\approx \frac1S\sum^S_{s=1}f(x_s)$(2.98)

上式中$x_s \sim  p(X)$.这就叫做蒙特卡罗积分(Monte Carlo integration),相比数值积分(numerical integration)的一个优势就是在蒙特卡罗积分中只在具有不可忽略概率的地方进行评估计算,而数值积分会对固定网格范围内的所有点的函数进行评估计算.

通过调整函数$f()$,就能对很多有用的变量进行估计,比如:
*$\bar x =\frac 1S \sum^S_{s=1}x_s\rightarrow \mathrm{E}[X]$
*$\frac 1 S\sum^S_{s=1}(x_s-\bar x)^2\rightarrow var[X]$
*$\frac 1 S \# \{x_s \le c\}\rightarrow P(X\le c)$
* 中位数(median)$\{x_1,...,x_S\}\rightarrow median(X)$

下面是一些例子,后面一些章节有更详细介绍.

### 2.7.1 样例:更改变量,使用 MC (蒙特卡罗)方法

在2.6.2，我们讨论了如何分析计算随机变量函数的分布$y = f(x)$.更简单的方法是使用蒙特卡罗方法估计.例如,若$x \sim  Unif(−1, 1) ,  y = x^2$.就可以这样估计$p(y)$:从$p(x)$ 中去多次取样,取平方,计算得到的经验分布.如图2.18所示.后文中还要广泛应用这个方法.参考图5.2.

此处查看原书图 2.19



### 2.7.2 样例:估计圆周率$\pi$,使用蒙特卡罗积分

蒙特卡罗方法还可以有很多种用法,不仅仅是统计学领域.例如我们可以用这个方法来估计圆周率$\pi$.我们知道圆的面积公式可以利用圆周率和圆的半径 r 来计算,就是$\pi r^2$,另外这个面积也等于下面这个定积分(deﬁnite integral):
$I=\int _{-r}^r\int _{-r}^r\prod(x^2+y^2\le r^2)dxdy$(2.99)

因此有$\pi =I/(r^2)$.然后就可以用蒙特卡罗积分来对此进行近似了.设$fx,y) =\prod(x^2+y^2\le r^2)$是一个指示器函数(indicator function),只要点在圆内,则函数值为1,反之为0,然后设$p(x),p(y)$都是在闭区间[-r,r]上的均匀分布(uniform distribution),所以有$p(x)=p(y)=\frac{1}{2r}$ 这样则有:

$$
\begin{aligned}
I &= (2r)(2r)\int\int f(x,y)p(x)p(y)dxdy&\text{ (2.100)}\\
&= 4r^2 \int\int f(x,y)p(x)p(y)dxdy&\text{ (2.101)}\\
&=4r^2\frac1S\sum^S_{s=1}f(x_s,y_s) &\text{ (2.102)}\\
\end{aligned}
$$

当标准差为0.09的时候,计算得到的圆周率为$\hat \pi =3.1416$,参考本书2.7.3就知道什么是标准差了.接受/拒绝的点如图2.19中所示.

此处查看原书图 2.20

### 2.7.3 蒙特卡罗方法的精确率

随着取样规模的增加,蒙特卡罗方法的精度就会提高,如图2.20所示,在图上部是从一个高斯分布中取样的直方图,底下的两个图使用了核密度估计(kernel density estimate, 参考本书14.7.2)得到的光化曲线.这种光滑分布函数在密集网格点上进行评估和投图.这里要注意一点,光滑操作只是为了投图看而已,蒙特卡罗方法估计的过程根本用不着光滑.
如果我们知道了均值的确切形式,即$\mu =E]f(X)]$,然后蒙特卡罗方法近似得到的是$\hat\mu$,那么对于独立取样则有:
$(\hat\mu -\mu )\rightarrow N(0,\frac{\sigma^2 }{S})$(2.103) 

其中:
$\sigma^2=var[f(X)]=\mathrm{E}[f(X)^2]-\mathrm{E}[f(X)]^2$(2.104) 

这是由中心极限定理决定的.当然了,上式中的$\sigma^2$是位置的,但也可以用蒙特卡罗方法来估计出来:
$\hat\sigma^2= \frac1S \sum^S_{s=1}(f(x_s)-\hat\mu)^2$(2.105) 

然后则有:
$P\{\mu-1.96\frac{\hat \sigma}{\sqrt S}\le \hat\mu \le \mu +1.96\frac{\hat \sigma}{\sqrt S}\}\approx 0.95$(2.106) 

上式中的$\frac {\hat \sigma}{\sqrt S}$就叫做数值标准差或者经验标准差(numerical or empirical standard error), 这个量是对我们对$\mu$估计精度的估计.具体信息查看本书6.2有更多讲解.

如果我们希望得到的答案$\pm \epsilon$范围内的概率至少为95%,那就要保证取样数目 S 满足条件$1.96\sqrt{\hat\sigma^2/S}\le \epsilon$, 这里的1.96可以粗略用2替代,这样就得到了$S\geq \frac{4 \hat\sigma^2}{\epsilon^2}$.


## 2.8 信息理论

信息理论(information theory)关注的是以紧凑形式进行数据呈现(这种紧凑形式也被称为数据压缩(data compression)或者源编码(source coding)),以及以能健壮应对错误的方式进行传输和存储(这个过程也叫做纠错(error correction) 或者信道编码(channel coding)).第一眼看上去好像这和概率论以及机器学习没什么关系,不过实际是有联系的.首先,对数据进行紧凑表达需要给高概率的字符串赋予短编码字,而将长编码字留给低概率字符串.就好比自然语言中,特别常用的词汇都往往比少见的词汇短很多,比如冠词 a/the 明显比闪锌矿 sphalerite 短很多.另外,在噪音频道上进行信息解码也需要对人发送的不同信息建立一个良好的概率模型.这就都需要一个能够预测数据可能性的模型,这也是机器学习里面的一个核心问题,关于信息理论和机器学习之间关系的更多内容请参考(MacKay 2003).

显然这里不可能说太多太深关于信息理论的内容,有兴趣的话去看(Cover and Thomas 2006).这里也就是介绍本书中要用到的一些基础概念了.

### 2.8.1 信息熵

随机变量 X 服从分布 p, 这个随机变量的熵(entropy)则表示为$H(X)$或者$H(p)$,这是对随机变量不确定性的一个衡量.对于一个有 K 个状态的离散随机变量来说,其信息熵定义如下:

$H(X)\overset\triangle{=}-\sum^K_{k=1}p(X=k)\log_2p(X=k)$(2.107)

通常都用2作为对数底数,这样单位就是 bit (这个是 binary digits 的缩写).如果用自然底数 e, 单位就叫做 nats 了.
举个例子,$X\in \{1,...,5\}$,柱状分布(histogram distribution), 概率$p=[0.25,0.25,0.2,0.15,0.15]$,利用上面的公式计算得到$H =2.2855$.
熵最大的离散分布就是均匀分布,可以参考本书9.2.6.因为对于一个 K 元(K-ary)随机变量,如果$p(x = k) = 1/K$,则信息熵最大,这时候的熵为$H(X)=\log_2K$. 熵最小的分布就是所有概率质量都在单一状态的$\delta$分布,这时候熵为0,因为只有一个状态有概率,没有任何不确定性.

在图2.5当中对 DNA 序列进行了投图,每一列的高度定义为$2-H$,其中的 H 就是这个分布的熵,2是最大可能熵(maximum possible entropy).因此高度为0的就表示均匀分布,而高度为2就对应着确定性分布(deterministic distribution).

此处查看原书图 2.21

对于二值化随机变量的特例,$X\in\{0,1\}$,则有$p(X=1)=\theta, p(X=0)=1-\theta$,这样熵为:

$$\begin{aligned}
H(X)&= -[p(X=1)\log_2p(X=1)+p(X=0)\log_2p(X=0)] &\text{(2.108)}\\
&=-[\theta\log_2\theta+(1-\theta)\log_2(1-\theta)]&\text{(2.109)}
\end{aligned}
$$

这也叫做二值熵函数(binary entropy function),也写作$H(\theta)$,如图2.21所示,课件当$\theta=0.5$的时候熵值最大为1,这时候是均匀分布了.


### 2.8.2 KL 散度

KL 散度(Kullback-Leibler divergence),也称相对熵(relative entropy),可以用来衡量p和q两个概率分布的差异性(dissimilarity).定义如下:

$KL(p||q)\overset\triangle{=}\sum^K_{k=1}p_k\log\frac{p_k}{q_k}$(2.110)

上式中的求和也可以用概率密度函数的积分来替代.就可以写成:

$KL(p||q)=\sum_kp_k\log p_k - \sum_kp_k\log q_k =-H(p)+H(p,q)$(2.111)

上式中的$H(p,q)$就叫做交叉熵(cross entropy):

$H(p,q)\overset\triangle{=}-\sum_kp_k\log q_k$(2.112)

参考 (Cover and Thomas 2006) 可以证明,当使用模型 q 来定义编码本(codebook)的时候,来自分布 p 的待编码数据的平均比特数(average number of bits)就是交叉熵.正规熵(regular entropy)$H(p)=H(p,p)$,参考本书2.8.1的定义,也就是使用真实模型时候的比特数期望值,因此 KL 散度也就是不同概率分布之间的不同的量度.换个说法, KL 散度就是要对数据编码所需要的额外比特(extra bits)的平均数,因为这时候用分布 q 来对数据进行编码,而不是使用分布 p.

既然是额外的比特数,这种表述就很明显说明这个 KL 散度应该是非负的,即$KL(p||q)\ge 0$,等于0则意味着两个分布相等,即$p=q$.接下来对此进行一下证明.

#### 定理2.8.1 信息不等式(Information inequality) 

$KL(p||q)\ge 0$ 当且仅当$p=q$的时候, KL 散度为0.

#### 证明

要证明这个定理,需要用到詹森不等式(Jensen’s inequality).这个不等式是说,对于任意的凸函数(convex function) f,有以下关系:

$f(\sum^n_{i=1}\lambda_i (x_i)) \le \sum^n_{i=1}\lambda_i f(x_i)$(2.113)

其中$\lambda_i \ge 0,\sum^n_{i=1}\lambda_i=1$. 由于凸函数的定义,对于 n=2的时候很显然,对于 n>2 的情况也可以归纳证明(proved by induction).

对定理的证明参考了(Cover and Thomas 2006, p28).设$A=\{x:p(x)>0\}$是$ p(x)$ 的支撑集合(support, 译者注:纯白或许就当做定义域理解好了).则有:


$$
\begin{aligned}
-KL(p||q)& = -\sum_{x\in A}p(x)\log \frac{p(x)}{q(x)}  = \sum_{x\in A}p(x)\log \frac{q(x)}{p(x)} &\text{(2.114)}\\
& \le \sum_{x\in A}p(x)\frac{q(x)}{p(x)} = \log \sum_{x\in A}q(x) &\text{(2.115)}\\
& \le \log \sum_{x\in \chi}q(x) =\log1 =0&\text{(2.116)}\\
\end{aligned}
$$
当 上面第一个不等式是应用了詹森不等式.因为$\log(x)$是个严格凸函数,所以在等式2.115里面,当且仅当对于某些 c 使$p(x)=cq(x)$成立的时候,等量关系成立.等式2.116中的等量关系当且仅当$\sum_{x \in A }q(x)=\sum_{x\in \chi }q(x)=1$的时候成立,这时候 c=1. 所以对于所有的 x 来说,当且仅当$p(x)=q(x),KL(p||q)=0$.

证明完毕.


这个结果的一个重要推论就是*足有最大熵的离散分布就是均匀分布*.更确切地说,$H(X)\le \log|\chi |$,$|\chi |$是 X 的状态数,当且仅当$p(x)$是均匀分布的时候等号成立.设$u(x)=1/|\chi |$,则有:
$$
\begin{aligned}
0&\le KL(p||u)= \sum_xp(x)\log\frac{p(x)}{u(x)}&\text{(2.116)}\\
&=\sum_xp(x)\log p(x)-\sum_xp(x)\log u(x)=-H(X)+\log|\chi| &\text{(2.118)}\\
\end{aligned}
$$

上面这个就是公式化的拉普拉斯不充分理由原则(Laplace’s principle of insufficient reason),说的是在没理由优先选择某个分布的时候,优先选择均匀分布(uniform distribution).关于如何建立满足特定约束条件(certain constraints) 的分布可以阅读本书9.2.6,其他方面尽可能最小化(as least-commital as possible).(正态分布满足一阶和二阶矩约束条件,但其他方面有最大熵.)




### 2.8.3 信息量(Mutual information)

设有两个随机变量 X 和 Y. 如果我们想知道一个变量告诉我们关于另一个变量的多少信息。就可以计算相关系数(correlation coefficient)了,可是相关系数只适用于实数值的随机变量.另外相关系数对不相关程度的衡量作用也很有限,如图2.12所示.所以更常用的方法是对比联合分布(joint distribution)$p(X, Y)$和因式分布(factored distribution)$p(X)p(Y)$的相关性.这就叫互信息量(mutual information) 或者简写做 MI, 定义如下:
$I(X;Y)\overset\triangle{=}KL(p(X,Y)||p(X)p(Y))=\sum_x\sum_yp(x,y)\log\frac{p(x,y)}{p(x)p(y)}$(2.119)

$I(X;Y)\ge0$的等号当且仅当$p(X,Y)=p(X)p(Y)$的时候成立.也就是如果两个变量相互独立,则互信息量 MI 为0. 为了深入理解 MI 这个量的含义,咱们用联合和条件熵的方式来重新表述一下.参考练习2.12可以得到上面的表达式等价于下列形式:

$I(X;Y)=H(X)-H(X|Y)=H(Y)-H(Y|X)$(2.120)

上式中的$H(Y|X)$就是条件熵(conditional entropy) 定义为$H(Y|X)=\sum_xp(x)H(Y|X=x)$.这样就可以把 X 和 Y 之间的互信息量 MI 理解成在观测了 Y 之后对 X 的不确定性的降低,或者反过来就是观测了 X 后对 Y 不确定性的降低.本书后面一些内容中还会用到这个概念.参考2.13和2.14来阅读互信息量 MI 和相关系数之间的联系.

另外一个和互信息量 MI 有很密切联系的量是点互信息量(pointwise mutual information,缩写为 PMI), 对于两个事件(而不是随机变量) x 和 y,其点互信息量 PMI 定义如下:

$PMI(x,y)\overset{\triangle}{=} \log\frac{p(x,y)}{p(x)p(y)}= \log\frac{p(x|y)}{p(x)}= \log\frac{p(y|x)}{p(y)}$(2.121)

这个量衡量的是与偶发事件相比,这些事件之间的差异.很明显 X 和 Y 的互信息量 MI 就是点互信息量 PMI 的期望值.所以就可以把点互信息量 PMI 的表达式写为:

$PMI(x,y)= \log\frac{p(x|y)}{p(x)}= \log\frac{p(y|x)}{p(y)}$(2.122)

这个量是通过将先验(prior)的$p(x)$ 更新到后验(posterior)的$p(x|y)$得到的,也可以是将先验的$p(y)$ 更新到后验的$p(y|x)$得到.



#### 2.8.3.1 连续随机变量的互信息量

上一节中的互信息量 MI 定义是针对离散随机变量的.对于连续随机变量,可以先对其进行离散化(discretize)或者量子化(quantize),具体方法可以使将每个随机变量归类到一个区间里面,将变量的变化范围划分出来,然后计算每一段的小区间中的分布数量(Scott 1979).然后就可以利用上文的方法公式来计算互信息量 MI 了(代码参考PMTK3的 mutualInfoAllPairsMixed, 样例可以参考miMixedDemo).

此处查看原书图 2.22


然而很不幸,分成多少个小区间,以及小区间边界的位置,都可能对计算结果有很大影响.一种解决方法就是直接对互信息量 MI 进行估计,而不去先进行密度估计(Learned-Miller 2004)).另一种办法是尝试很多不同的小区间规模和位置,然后计算得到的最大互信息量 MI.经过适当的标准化之后,这个统计量就被称为最大信息系数(maximal information coefficient,缩写为 MIC)(Reshed et al. 2011).更确切来说定义如下所示:

$m(x,y)=\frac{\max_{G\in G(x,y)}I(X(G);Y(G))}{\log\min (x,y)}$(2.123)

上式中的$G(x, y)$是一个规模为$ x\times y$ 的二维网状集合,而$X(G),Y(G)$表示的是将变量在这个网格上进行离散化得到的结果.在区间位置(bin locations)上最大化的过程可以通过使用动态编程(dynamic programming)来有效进行(Reshed et al. 2011).这样定义了连续变量互信息量 MIC如下:

$MIC\overset{\triangle}{=} \max_{x,y:xy<B}m(x,y)$(2.124)

上式中的 B 是一个与取样规模相关的约束条件,用于约束能使用且能可靠估计分布的区间个数. ((Reshed et al. 2011) 建议的是$B = N^{0.6}$.显然 MIC 处于区间[0, 1]中,其中-表示两个变量没关系,而1表示二者有无噪音的相关性(noise-free relationship),这种相关性可以是任意形式的,不仅仅是线性相关.

图2.22给出的是一个实例.其中的数据集包含了357个变量,衡量一系列的社会/经济/健康/政治指标,由世界健康组织 WHO 手机.左边的途中看到了对于 65,566 个变量对的相关系数(CC)与互信息量(MIC)的关系图.有图则投了一些特定变量对的散点图,其中包括了:
* C 图中的是 CC 和 MIC 都低,相应的散点图很明显表明了这两组变量之间没有关系:因伤致死比例和人群中牙医密度.
* D 图和 H 图中是 CC 和 MIC 都高,呈现近乎线性的相关性.
* E/F/G 这三个图都是低 CC 高 MIC.这是因为这些变量之间的关系是非线性的,例如在 E 图和 F 图中,都是非函数对应关系,比如可能是一对多的对应关系.

总的来说, MIC 这个统计量是基于互信息量的,可以用于发现变量之间的有意义的关系,而这些关系可能是那些简单的统计量,比如相关系数之类无法反应的.由于这个优势, MIC 也被称作是21世纪的相关性衡量变量“a correlation for the 21st century” (Speed 2011).



# MLAPP 读书笔记 - 03 离散数据的生成模型(Generative models for discrete data)

> A Chinese Notes of MLAPP，MLAPP 中文笔记项目 
https://zhuanlan.zhihu.com/python-kivy

记笔记的人：[cycleuser](https://www.zhihu.com/people/cycleuser/activities)

2018年05月13日14:39:57


## 3.1 简介

在本书2.2.3.2中,提到了如何对一个特征向量 x 进行分类,使用了贝叶斯规则,构建了一个生成分类器(generative classiﬁer),形式如下所示:
$p(y=c|x,\theta)\propto p(x|y=c,\theta)p(y=c|\theta)$(3.1)
使用这样模型的管建就是要给类条件概率密度(class-conditional density)指定一个合适的形式$p(x|y=c,\theta)$,这定义了我们在每个类别中希望看到的数据种类.在本章中,观测数据是离散符号(discrete symbols).此外还要讨论如何推导这类模型的未知参数$\theta$.


## 3.2 贝叶斯概念学习(Bayesian concept learning)

想一下小朋友学习理解一个单词的意思,比如狗 dog 这个单词.可能家大人会指着一个这个名词指代概念的个体,然后告诉这东西是啥,比如说:"哎呀这是一只小狗啊"或者"小心有狗啊"之类的.不过他们往往都是给出正面例子,而不是给出反例,比如说:"看看这不是小狗啊".当然,在动态的学习过程中,反例是可能出现的,比如小朋友说:"哎呀这是小狗",然后家长更正说:"你个瓜娃这是小猫不是狗".不过心理学的研究表明,人类可以单纯从正面样例(positive examples)来学习概念(Xu and Tenenbaum 2007).

先把这种学习单词意思的学习过程就等价认为是概念学习(concept learning), 这样也就等价于二值化分类(binary classification).设如果 x 是概念 C 的一个具体实例,则$f(x)=1$,反之则$f(x)=0$.那么目标就是通过学习得到指示函数(indicator function)$f$,这个函数就是用来判断元素是否包含于集合 C 内的. 对$f$ 的定义可以允许存在不确定性,或者对 C 中的元素也可以有不确定性,这样就能用标准概率积分模拟模糊集合理论(fuzzy set theory).标准的二值化分类器方法需要正负两方面的样本.这次咱们要设计一个只需要正面样本的学习方法.

处于教学目的,这部分要参考 Josh Tenenbaum 1999年的博士论文中的内容. 这次样例是一个数字游戏,是概念学习的一个简单例子.这个游戏的内容如下,一个人甲选择一个简单算术概念组成的集合 C, 比如可以使素数或者是1到10之间的数字.然后给另一个人乙一个随机选择的正面样本系列$D = \{x_1 , ... , x_N \}$,D 是从 C 中选取的,然后问乙新的测试样本$\hat x$是否属于 C, 也就是甲让乙去对$\hat x$进行分类.

此处查看原书图 3.1


为了简单起见,就让所有数字都是1到100之间的整数.然后甲告诉乙16是这个概念的正面样本.那么有什么其他的数值你觉得也是正面样本呢?17?6?32?99?只有一个样本分明很难对不对,所以预测起来也不靠谱,太难了.肯定得想和16更相似的数.比如17有点像,因为距离近,6页有相似因为有一个同样的数字,32也相似,因为是偶数而且还是而被关系,不过99看着就不太像了.这样有的数字看上去比其他的看着更可能.这可以用一个概率分布$p(\hat x|D)$, 这个概率分布是数据集 D 当中任意$\hat x \in \{1,...,100\}$ 使得$\hat x \in C$的概率.这也叫做后验预测分布(posterior predictive distribution).图3.1展示的就是实验室中推出的一例预测分布.可以看到人们对于16相似的数的选择很相似,有某种程度的相似性.

然后甲告诉乙8,2,64也都是正面样本.这时候可能就会猜测隐藏概念是2的幂.这就是归纳法(induction) 的一个例子.基于这个假设,预测分布就很明确了,主要都集中在2的幂数上.

如果甲告诉乙数据集$D=\{16,23,19,20\}$就会得到不同的泛化梯度(generalization gradient),如图3.1底部所示.
在机器学习里面如何解释和模拟这种行为呢?
传统归纳方法是假设有一个概念假设空间(hypothesis space of concepts),$H$, 比如奇数/偶数/1-100之间的数/2的幂数/以 j 结尾的某个数等等.$H$的子集中与数据 D 一致的就被称为版本空间(version space).随着样本增多,版本空间缩小,对概念的确定性就随之增加(Mitchell 1997).
然而只有版本空间还不够.在看到了$D=\{16\}$之后,有很多都一直规则,怎么来结合起来去预测其他元素是否属于 C 即$\bar x\in C$呢?另外在看到$D=\{16,8,2,64\}$之后,为什么你就认为规则是2的幂数而不是所有偶数呢,或者也不是"除了32之外的所有2的幂数"呢?这几个都符合啊.接下来我们就用贝叶斯观点来对此进行解释.

### 3.2.1 似然率(likelihood)

在看到$D=\{16,8,2,64\}$之后,为什么选择假设$h_{two}\overset\triangle{=}$2的幂数,而不选择$h_{even}\overset\triangle{=}$偶数呢?这两个假设都符合啊.关键就在于我们本能想要去避免可疑的巧合(suspicious coincidences).如果概念真是偶数,我们看到的怎么就都碰巧是2的幂数呢?

要用正规语言来说的话,假设样本是从概念的扩展集(extension)中随机抽取出来的.(概念的扩展及就是所有属于该概念的元素组成的集合,比如$h_{even}$的扩展及就是{2,4,6,...,98,100},以9结尾的数字的扩展及就是{9,19,...,99}.)Tenenbaum 称此为强抽样假设(strong sampling assumption).有了这个假设之后,从h中可替换地独立抽取N个样本的概率就是:

$p(D|h)=[\frac{1}{size(h)}]^N=[\frac{1}{|h|}]^N$(3.2)

上面这个关键的等式体现了 Tenenbaum 所说的规模原则(size principle),也就意味着优先选择与数据样本一致且假设最少或者最简单的模型.这个原则也被通俗称为奥卡姆剃刀(Occam’s razor).
举个例子试试,设$D=\{16\}$,则$p(D|h_{two})= 1/6$,这是因为在100以内有六个2的幂数;而$p(D|h_{even})= 1/50$,这是因为1-100这个范围内有50个整数.所以$h=h_{two}$的可能性(likelihood)要比$h=h_{even}$高.有四个样本的时候,$h=h_{two}$的可能性是$(1/6)^4=7.7\times 10^{-4}$,而$h=h_{even}$的可能性是$(1/50)^4=1.6\times 10^{-7}$.这两者的概率比(likelihood ratio)高达5000:1了!自然好理解为啥人们都买$h=h_{two}$了.这也定量表明了之前的直觉(intuition),就是如果真的是$h=h_{even}$的话,那么$D=\{16,8,2,64\}$就太巧合了.



### 3.2.2 先验(Prior)

若$D=\{16,8,2,64\}$.那么$h_{32}=$"除了32之外的2的幂数"会比$h_{two}=$"2的幂数"有更高的概率,因为$h_{32}$不需要去解释为啥在样本集合中没有32.不过$h_{32}=$"除了32之外的2的幂数"这个假设看上去太"不自然(conceptually unnatural)".我们之所以有这种直觉,是因为对不自然的概念赋予了低的先验概率(low prior probability).当然了,不同的人可能有不同的先验判断.这种主观色彩(subjective)也是贝叶斯估计有很多争议的一个原因,例如对于数值的判断来说,一个小朋友和一个数学教授就可能会有不同的答案.实际上这两者可能不仅先验判断不同,甚至连假设空间都不同.不过我们还是假设他们的假设空间一直,然后设置小朋友对于某些复杂概念上的先验权重为0.这样在先验和假设空间上就没有特别突兀的差别了.

虽然先验的主观性很惹争议,但还是很有用的.告诉你一串数字,其中有1200, 1500, 900, 1400,说取样自某个数学运算规则下,那你可能会认为400有可能符合这个规则,而1183就比较扯了.可要是告诉你这些数值来自健康胆固醇标准(healthy cholesterol levels),那就可能你觉得400概率不大而1183反而挺有可能出现了.因此不难发现,先验是利用背景知识来解决问题的机制.要是没有先验,快速学习就不可能实现了,比如从小规模样本进行学习等等.

那么针对例子中这种情况,咱们该用哪种先验呢?为了演示,咱们用最简单的先验,设定30中简单数学运算概念服从均匀分布,比如偶数/技术/质数/结尾有9的数等等.还可以让技术和偶数这两个概率更大.包括进去两个很不自然的概念,比如2的幂数加上37/除了32之外其他的2的幂数,但这两个给他们很低的先验权重.参考图3.2(a)是这个先验的图像.稍后会考虑更复杂情况.



此处查看原书图 3.2


### 3.2.3 后验(Posterior)

后延就是可能性(似然率,likelihood)乘以先验,然后归一化.在本文就是:

$p(h|D)=\frac{p(D|h)p(h)}{\sum_{\hat h\in H}p(D, \hat h)}=\frac{p(h)I(D\in h)/|h|^N}{\sum_{\hat h\in H}p(\hat h)I(D\in h)/|h|^N}$(3.3)

当且仅当所有数据都包含于假设h的扩展中的时候,其中的$I(D\in h)=1$.图3.2所示为$D=\{16\}$时候的先验/似然率/后验的图像.很显然,后验是先验和似然率的结合.通常都假设先验是均匀分布,所以后验往往与似然率成正比.然而,一些"不自然"概念,比如底下那两个,2的幂数加37和除了32以外的2的幂数这些虽然似然率挺高的,但后验很低,因为对应的先验就很低.

图3.3所示为$D=\{16,8,2,64\}$后的先验/似然率/后验.这时候在2的幂数上的概率就比之前高的多了,所以这就决定了后验概率的特征.

实际上人类学习者会有一个领悟时刻(aha moment),确定真正的概念.(这里就体现了对不自然概念的低先验的用处,否则如果选了"除了32以外的其他2的幂数"就明显会过拟合了.)

通常来说,只要有足够数据了,后验概率密度$p(h|D)$就会在一个单独概念位置有最大峰值,也就成了最大后验(MAP),即:
$p(h|D)\rightarrow \delta_{\hat h^{MAP}}(h)$(3.4)
上式中$\hat h^{MAP}= \arg \max_h p(h|D)$是后验众数(posterior mode),其中的$\delta$是狄拉克测度(Dirac measure),定义如下:

$$
\delta_x(A)=\begin{cases}1 &\text{if}&x\in A\\
0 &\text{if}&x\notin A\end{cases}
$$(3.5)

最大后验(MAP)可以写作:
$\hat  h^{MAP} = \arg \max_h p(D|h)p(h)=\arg \max_h [\log p(D|h)+\log p(h)]$(3.6)

由于似然率项依赖于N的指数函数,而先验保持不变,所以随着数据越来越多,最大后验估计(MAP estimate)就收敛到最大似然估计(maximum likelihood estimate,MLE):

$\hat  h^{mle} \overset{\triangle}{=} \arg \max_h p(D|h) =\arg \max_h \log p(D|h)$(3.7)

也就是说,如果数据足够多了,就会发现数据特征盖过了先验.这种情况下最大后验估计(MAP)就朝着最大似然估计(MLE)收敛了.

如果假设空间里面包含了真实假设,那么最大后验估计/最大似然估计就都会收敛到这个假设.因此说贝叶斯推断(Bayesian inference)和最大似然估计是一致估计(consistent estimator),更多内容参考6.4.1.此事也说假设空间在限定范围内可识别(identiﬁable in the limit),意味着虽然受限于有限的数据也能够恢复出真实概念.如果假设类不足以全面表征真实情况(这也是常态),我们就只能收敛到尽可能接近真实概念的假设上.正规来说要用到亲密度(closeness)的概念,这超出了本章的范围了.

此处查看原书图 3.3
此处查看原书图 3.4


### 3.2.4 后验预测分布(Posterior predictive distribution)





后验其实是我们对外部世界的内在认知状态.怎么来测试我们所持信念呢?可以用他们来预测可观测的客观量(这也是科学方法的基础).比如上文所提到的后验预测分布可以写作:

$p(\hat x \in C|D )=\sum_h p(y=1|\hat x,h)p(h|D)$(3.8)

这正好就是每个独立假设给出的预测的加权平均值,也叫做贝叶斯模型平均值(Bayes model averaging,缩写为 BMA,Hoeting et al. 1999).如图3.4所示,底部的实心点只是的是每个假设的预测,右边竖着的曲线是每个假设的权重.把每一列和权重相乘加到一起,就得到最顶部的分布了.


如果我们的数据集比较小或者存在模棱两可的不确定情况下,后延$p(h|D)$就很模糊了,就导致了宽泛预测分布(broad predictive distribution).不过,只要学习者弄明白了(figured things out),后验概率分布就成了以最大后验估计(MAP)为中心的$\delta$分布了.这时候,对应的预测分布就是:
$p(\hat x\in C|D)=\sum_hp(\hat x|h)\delta_{\hat h}(h)=p(\hat x|\hat h)$(3.9)

这也叫做对预测密度的插值近似(plug-in approximation),特别简单所以用的很广泛.不过通常来说,这也代表了我们的不确定性,这种预测不会像使用贝叶斯模型均值(BMA)那样光滑.后文还会有更多相关例子.

虽然最大后验估计学习(MAP Learning)很简单,但不能解释从有不确定后验的相似度推理(similarity-based reasoning)到有确定后验的规则推理(rule-based reasoning)的这种渐进转变过程.比如,还说本章这个例子,先看到的是$D = \{16\}$,如果用上面的简单先验,最小一直假设就是"4的幂数",所以只有4和16会得到非零概率,被预测出来.这明显就是过拟合了.后面看到了$D=\{16,8,2,64\}$,最大后验估计学习得到的假设就是"2的幂数".所以随着观测数据增多,差值预测分布会更宽或者维持原来的状态,最开始很窄,但随着观测数据增多逐渐变宽.与之相反,贝叶斯方法当中,最开始是很宽的估计,然后随着数据量增多逐渐收窄,这就很好理解了.比如最开始刚看到$D = \{16\}$的时候,有很多假设,都有不可忽略的后验支撑,所以预测分布也很宽.不过随着数据增多,$D=\{16,8,2,64\}$,后验就集中在一个假设上了,预测分布也更窄了.因此差值近似和贝叶斯方法在小样本情况下是截然不同的,虽然二者随着数据规模扩大都会收敛到同样的答案.

### 3.2.5 更复杂的先验(A more complex prior)

为了对人类行为进行建模,Tenenbaum 在他的论文中用了一个更复杂的先验,这个先验是通过一个实验数据分析而推导得到的,这个实验测试了人们对数字相似性如何衡量,具体参考其博士论文的208页.结果就是得到了一个集合,跟前文的类似,也是数学概念组成的,相比之下多了一个就是在n到m中的所有间隔,$1\le n,m\le 100$.(注意这些假设并不是互斥的.)所以这个先验实际上是两个先验的混合,其中的一个是算数规则,另外一个是数字间隔:

$p(h)=\pi_0 p_{rules}(h)+( -\pi_0)p_{interval}()h$(3.10)

给定先验的两部分之后,这个模型中的唯一一个自由参数就是相对权重,$\pi_0$.只要$\pi_0 >0.5$,结果就对这个值不是很敏感,反映的是人们更倾向于选择算数规则假设.这个模型的预测分布如图3.5所示,使用了更大的假设空间.这个分布和图3.1中人类的预测分布具有惊人的相似,虽然这个模型除了假设空间的选择之外并没有使用人类案例的数据进行拟合.



此处查看原书图 3.5

## 3.3$\beta$二项模型(beta-binomial model)

上面一节中讨论的数字游戏所涉及的是在得到一系列离散观察之后,从一个有限假设空间中推断一个离散变量的分布.这样计算其实都挺简单,只需要用到加法/乘法/除法.可是在实际应用中,有很多连续的未知参数,所以假设空间实际上是$R^K$或者其子集,其中的K就是参数个数.这样在数学上就复杂了,因为要用积分来替代之前离散情况下的加法.不过基本思想还是一样的.

举个例子,观测了一个硬币抛起落下的若干次实验之后,推测一个硬币人头朝上的概率.这看上去很小儿科,但这个模型是很多方法的基础,比如朴素贝叶斯分类器/马尔科夫模型等等.从历史角度来说这个实验也是很重要的,因为这正是1763年贝叶斯(Bayes)原版论文中用到的例子,贝叶斯的分析后来被皮埃尔-西蒙 拉普拉斯(Pierre-Simon Laplace)推广,建立成为了现在我们所知的贝叶斯规则,更多历史细节参考(Stigler 1986).

我们还是按照之前的套路,确定似然率(Likelihood)和先验(prior),然后推导后验(posterior)和后验预测(posterior predictive).

### 3.3.1 似然率(Likelihood)

设 X 服从伯努利(Bernoulli)分布,即$X_i \sim  Ber(\theta)$,$X_i=1$表示人头,$X_i=0$表示背面,$\theta \in [0, 1]$是频率参数(人头出现的概率).如果实验事件是独立同分布的,那么似然率(likelihood)为:

$p(D|\theta) =\theta^{N_1}(1-\theta)^{N-0}$(3.11)


上式中的$N_1 =\sum^N_{i=1} I(x_i = 1)$对应人头,而$N_0 =\sum^N_{i=1} I(x_i = 0)$对应背面.这两个技术叫做数据的充分统计(sufficient statistics),关于D我们只需要知道这两个量,就能推导$\theta$.充分统计集合也可以设置为$N_1$和$N = N_0 + N_1$.

正规表达下,若$p(\theta|D) = p(\theta|s(data))$,则就可以称$s(D)$是对数据D的一个充分统计.如果使用均匀分布作为先验,也就等价说$p(D|\theta) \propto p(s(D)|\theta)$.如果我们有两个集合,有同样的充分统计,就会推出同样的参数值$\theta$.

接下来设想在固定的总实验次数$N = N_0 + N_1$的情况下,数据中包含了人头朝上的次数为$N_1$.这时候就有$N_1$服从二项分布,即$N_1 \sim  Bin(N, \theta)$,其中这个Bin的意思就是二项分布(binomial distribution),其概率质量函数(pmf)如下所示:

$Bin(k|n,\theta))\overset\triangle{=}(\begin{aligned}n\\k\end{aligned})\theta^k(1-\theta)^{n-k}$(3.12)

因为$(\begin{aligned}n\\k\end{aligned})$是独立于$\theta$的一个常数,所以二项取样模型的似然率和伯努利模型的似然率是一样的,所以我们对$\theta$的推断都是一样的,无论是观察一系列计数$D(N_1,N)$或者是有序的一系列测试$D = \{x_1 , ... , x_N \}$.

### 3.3.2 先验(prior)

需要一个定义在区间[0,1]上的先验.为了数学运算简便,可以让先验和似然率形式相同,也就是说对于参数为$\gamma _1,\gamma_2$的某个先验来说:
$p(\theta)\propto \theta^{\gamma_1}(1-\theta)^{\gamma_2}$(3.13)
这样的话,后验就很好估算了,只要合并指数就可以了:

$p(\theta) \propto p(D|\theta)p(\theta) = \theta^{ N_1} (1 − \theta) ^{N_0 }\theta ^{\gamma_1 }(1 − \theta) ^{\gamma_2 }= \theta ^{N_1 +\gamma_1} (1 − \theta) ^{N_0 +\gamma_2}$(3.14)


这样先验和所以先验都一样了,就说这个先验是所对应似然率的共轭先验(conjugate prior).共轭先验用处很广泛,因为计算起来简单,也好理解.

使用伯努利分布的情况下,共轭先验就是$\beta$分布,在本书2.4.5就有提到:
$Beta(\theta|a,b)\propto \theta^{a-1}(1-\theta)^{b-1}$(3.15)

这个先验的参数叫超参数(hyper-parameters).可以根据我们事先持有的信念进行编码来对此进行设置.例如,如果我们认为$\theta$的均值应该是0.7而标准差为0.2,就设定$ a = 2.975,d b = 1.275$(练习3.15).或者若认为$\theta$的均值应该是0.15而所属区间为开区间(0.05,0.30),就设定$ a = 4.5,d b = 25.5$(练习3.16).
如果关于参数$\theta$咱啥也不知道啊,只知道属于闭区间[0,1],就可以用均匀分布了,这也就是无信息先验(uninformative prior,更多细节参考本书5.4.2).均匀分布可以用一个$a=b=1$的$\beta$分布来表示.



此处查看原书图 3.6

### 3.3.3 后验(posterior)

把二项分布的似然率和$\beta$分布的先验乘到一起,就得到下面的后验了(参考公式3.14):

$p(\theta|D ) \propto Bin(N_1|\theta ,N_0+ N_1)Beta(\theta|a,b)Beta(\theta|N_1+a,N_0+b)$(3.16)

具体来说,这个后验是通过在经验计数(empirical counts)基础上加上了先验超参数(prior hyper-parameters)而得到的.因此将这些超参数称之为伪计数(pseudo counts).先验的强度,也是先验的有效取样规模(effective sample size)就是伪计数的和$a+b$;这个量起到的作用类似于数据集规模$N_1 + N_0 = N$.

图3.6(a)所示的例子中,弱先验Beta(2,2),似然率函数为单峰,对应一个大取样规模;从图中可见后验和似然率基本相符合:这是因为数据规模盖过了先验.图3.6(b)是使用了强先验Beta(5,2)来进行更新,也是一个单峰值似然率函数,可这时候很明显后验就是在先验和似然率函数之间的一个折中调和.

要注意的是按顺序对后验进行更新等价于单次批量更新.假设有两个数据集$D_a,D_b$,各自都有充分统计$N^a_1 , N^a_0$和$N^b_1 , N^b_0$.设$N_1= N^a_1+N^b_1,N_0= N^a_0+N^b_0$则是联合数据集的充分统计.在批量模式(batch mode)下则有:
$p(\theta|D_a,D_b)\propto Bin(N_1|\theta,N_1+N_0)Beta(\theta|a,b)\propto Beta(\theta|N_1+a,N_0+b)$(3,17)


在序列模式(sequential mode)则有:

$$
\begin{aligned}
p(\theta|D_a,D_b) &\propto p(D_b|\theta)p(\theta|D_a)&\text{(3.18)}\\
 &\propto Bin(N^b_1|\theta,N^b_1+N^b_0)Beta(\theta|N^a_1+a,N^a_0+b)&\text{(3.19)}\\
 &\propto Beta(\theta |N^aa_1+N^b_1+a,N^a_0+N^b_0+b) &\text{(3.20)}\\
\end{aligned}
$$

这个性质使得贝叶斯推断很适合在线学习(online learning),后面会有更详细说明.

#### 3.3.3.1 后验(posterior)的均值(mean)和众数(mode)

参考等式2.62,最大后验估计(MAP)为:
$\hat\theta_{MAP}=\frac{a+N_1-1}{a+b+N-2}$(3.21)

如果使用均匀分布先验,那么最大后验估计(MAP)就会降低成为最大似然估计(MLE),就正好是硬币人头朝上的经验分数(empirical):
$\hat\theta_{MLE}=\frac{N_1}{N}$(3.22)

这个结论很符合直观印象,不过也可以通过应用基本微积分使等式3.11中的似然函数最大而推导出,参考练习3.1.

后验均值如下所示:
$\bar\theta = \frac{a+N_1}{a+b+N}$(3.23)

这个区别后面有很大用处.后验均值是先验均值和最大似然估计的凸组合(convex combination),表示的就是在这两者之间进行折中,兼顾了先验的已有观点以及数据提供的信息.

设$\alpha_0 = a + b$是先验中的等效样本容量(equivalent sample size),控制的是先验强度,然后令先验均值(prior mean)为$m_1=a/\alpha_0$.然后后验均值可以表示为:
$\mathrm{E}[]=\frac{\alpha_0 m_1+N_1}{N+\alpha_0} = \frac{\alpha_0}{N+\alpha_0}m_1+\frac{N}{N+\alpha_0}\frac{N_1}{N}=\lambda m_1+(1-\lambda)\hat\theta_{MLE}$(3.24)

上式中的$\lambda=\frac{\alpha_0}{N+\alpha_0}$为先验和后验的等效样本容量的比值.所以先验越弱,$\lambda$越小,而后验均值就更接近最大似然估计(MLE).

#### 3.3.3.2 后验(posterior)的方差(variance)


均值和模都是点估计,还要知道可信程度.后验方差就是用来对此进行衡量的.$\Beta$后验的方差如下所示:

$var[\theta|D]=\frac{(a+N_1)(b+N_0)}{(a+N_1+b+N_0)^2(a+N_1+b+N_0+1)}$(3.25)

上面这个式子看着很麻烦,在$N \gg a,b$的情况下可以对其进行近似以简化,得到的为:
$var[\theta|D]\approx \frac{N_1 N_0}{NNN}=\frac{\bar\theta(1-\bar\theta)}{N}$(3.26)

其中的$\bar\theta$就是最大似然估计(MLE).然后能得到估计结果的"误差项(error bar)",也就是后验标准差:
$\sigma =\sqrt{var[\theta|D]}\approx \sqrt{ \frac{\bar\theta(1-\bar\theta)}{N}}$(3.27)

显然,不确定性以$1/\sqrt N$的速度降低.要注意这里的不确定性,也就是方差,在$\bar\theta=0.5$的时候最大,在$\bar\theta$接近0或者1的时候最小.这意味着确定硬币是否有偏差要比确定硬币结果是否合理公平更容易(This means it is easier to be sure that a coin is biased than to be sure that it is fair).

### 3.3.4 后验预测分布(Posterior predictive distribution)

截至目前,我们关注的都是对未知参数的推导.这一节咱们回头来看对未来可观测数据的预测.

设预测一个硬币落地成人头朝上在未来单次实验中的概率服从后验分布$Beta(a,b)$.则有:
$$
\begin{aligned}
p(\bar x=1|D )& =\int^1_0 p(x=1|\theta)p(\theta|D)d\theta &\text{(3.28)}\\
&=\int^1_0\theta Beta(\theta|a,b)d\theta=\mathrm{E}[\theta|D]=\frac{a}{a+b}&\text{(3.29)}\end{aligned}
$$


这样就能发现,在这个案例中,后验预测分布(posterior predictive distribution)的均值(mean)和后验均值参数插值(plugging in the posterior mean parameters)是等价的:$p(\bar x|D)=Ber(\bar x|\mathrm{E}[\theta|D])$.

#### 3.3.4.1 过拟合与黑天鹅悖论

若不使用插值进行最大似然估计(MLE),也就是说使用$p(\tilde x|D)\approx  Ber(\tilde x|\hat\theta_{MLE})$.很不幸,当样本规模小的时候这个近似表现很差.例如设一组实验$N=3$.那么最大似然估计(MLE)就是$\bar\theta =0/3=0$,这已经是最大程度利用了观测数据了.如果我们采信这个估计,就会认为硬币人头朝上是不可能事件了.这就叫做零计数问题(zero count problem)或者稀疏数据问题(sparse data problem),对小规模数据进行估计的时候会经常出现的.有人可能觉得在所谓大数据应用领域,就没必要太担心这种问题了,可是一定要注意,一旦我们对数据基于某些特定标准进行了人为划分,比如某个人从事某个活动的次数等等,样本规模就变小了很多了.这种问题就还会出现,比如在推荐个性化网页的时候就可能出现.所以即便是在所谓大数据时代,贝叶斯方法还是有用的 (Jordan 2011).

零计数问题很类似一个叫做黑天鹅悖论的哲学问题.古代西方人的观念是所有天鹅都是白色的,就把黑天鹅当作不存在的事物的一个比喻.而在17世纪欧洲探索者在澳大利亚发现了黑天鹅.所以科学哲学家卡尔 波普(Karl Popper)就提出了黑天鹅悖论这个名词,另外也有个畅销书用黑天鹅做标题(Taleb 2007).这个悖论用于归纳问题,如何从过去的特定观察去得出对未来的一般性结论.

使用贝叶斯方法来推导一个对这个问题的解决方案.使用均匀先验,所以a=b=1.这样对后验均值插值就得到了拉普拉斯继承规则(Laplace’s rule of succession):

$p(\tilde x =1|D)=\frac{N_1+1}{N_1+N_0+2}$(3.30)

上式中包含了一种实践中的常规做法,就是对经验计数(empirical counts)加1,归一化,然后插值,这也叫做加一光滑(add-one smoothing).要注意对最大后验估计(MAP)插值就不会有这种光滑效果,因为这时候模(mode)的形式$\hat\theta=\frac{N_1+a-1}{N+a+b-2}$,如果a=b=1就成了最大似然估计(MLE)了.


#### 3.3.4.2 预测未来多次实验

设有 M 次未来实验,要去预测其中的人头朝上的次数 x.这个概率则为:
$$
\begin{aligned}
p(x|D,M)&= \int_0^1 Bin(x|\theta,M)Beta(\theta|a,b)d\theta&\text{(3.31)}\\
&=\binom{M}{x}\frac{1}{B(a,b)}\int_0^1\theta^x(1-\theta)^{M-x}\theta^{a-1}(1-\theta)^{b-1}d\theta &\text{(3.32)}\\
\end{aligned}
$$
这个积分正好就是$Beta(a+x, M−x+b)$这个分布的归一化常数.因此:
$\int^1_0\theta^x(1-\theta)^{M-x}\theta^{a-1}(1-\theta)^{b-1}d\theta = B(x+a,M-x+b)$(3.33)
因此就能发现后验预测分布如下所示,是一个(复合)$\beta$-二项分布分布(beta-binomial distribution):
$Bb(x|a,b,M) * = {\begin{pmatrix}M\\x\end{pmatrix}} \frac{B(x+a,M-x+b)}{B(a,b)}$
(3.34)
这个分布的均值和方差如下所示:
$\mathrm{E}[x]=M\frac{a}{a+b},var[x]=\frac{Mab}{(a+b)^2}\frac{(a+b+M)}{a+b+1}$(3.35)
如果$M=1$,则$x\in \{0,1\}$,均值就成了$\mathrm{E}[x|D]=p(x=1|D)=\frac{a}{a+b}$,和等式3.29一致.

这个过程如图3.7(a)所示.开始是用Beta(2,2)作为先验,投图的是$N_1 = 3,N_0 = 17$,即3次人头,17次背面的情况下的后验预测密度.图3.7(b)投图的是最大后验估计(MAP)插值近似.很明显贝叶斯预测(Bayesian prediction)有更长尾(longer tails)概率质量分布的更广泛,所以更不容易过拟合,也更不容易遇到黑天鹅悖论的情况.

此处查看原书图 3.7

## 3.4 狄利克雷-多项式模型(Dirichlet-multinomial model)

上一节讲的抛硬币的概率问题只有两个状态,人头朝上或者背面朝上.本节要对上一节的结论推广到有K个面的骰子的k个状态上.这和另外一个玩具练习有点像,不过这一章要学到的方法还会广泛应用到文本/生物序列等数据的分析上.


### 3.4.1 似然率(Likelihood)

假设观测了N次掷骰子,得到的点数集合为$D=\{x_1,...,x_N\}$,其中$x_i\in \{1,...,K\}$.假设这个数据是独立同分布的(IID),那么似然率如下所示:
$p(D|\theta)=\prod^K_{k=1}\theta^{N_k}_k$(3.36)
上式中的$N_k=\sum^K_{i=1}I(y_i=k)$是事件k出现的次数(这也是该模型的充分统计).多项式模型的似然率与上式形式相同,有不相关常数因子.(The likelihood for the multinomial model has the same form, up to an irrelevant constant factor.)


### 3.4.2 先验(Prior)

参数向量处在K维度概率单纯形(K-dimensional probability simplex)中,所以需要在这个单纯形上定义一个先验.理想情况下应该是共轭的(conjugate).很幸运的就是本书2.5.4中提到的狄利克雷分布就满足这两个条件.所以使用如下的先验:

$Dir(\theta|\alpha )= \frac{1}{B(\alpha)}\prod^K_{}\theta_k^{\alpha_{k-1}}I(x\in S_K)$(3.37)



### 3.4.3 后验(Posterior)

把先验和似然率相乘,就得到了后验了,也是一个狄利克雷分布:

$$
\begin{aligned}
p(\theta|D)& \propto p(D|\theta)p(\theta)&\text{(3.38)}\\
& \propto \prod^K_{k=1}\theta^{N_k}_k\theta_k^{\alpha_k -1} = \prod^K_{k=1}\theta_k^{\alpha_k+N_k-1} &\text{(3.39)}\\
&  =Dir(\theta|\alpha_1+N_1,...,\alpha_K+N_K)&\text{(3.40)}\\
\end{aligned}$$


很明显这个后验是通过将先验的超参数（伪计数pseudo-counts）$\alpha_k$加到经验计数(empirical counts)$N_k$上而获得的。

可以通过积分来推导出这个后验的模,也就是最大后验估计(MAP estimate).不过还要必须强化约束条件$\sum_k\theta_k=1$.可以通过拉格朗日乘数(Lagrange multiplier)来实现.受约束的目标函数,也叫拉格朗日函数(Lagrangian),可以通过对似然率取对数加上对先验取对数然后加上约束条件:
$l(\theta,\lambda) =\sum_kN_k\log\theta_k+\sum_k(\alpha_k-1)\log\theta_k+\lambda(1-\sum_k\theta_k)$(3.41)

为了简化表达,定义一个$\hat N_k\overset\triangle{=} N_k + \alpha_k − 1$.取关于$\lambda$的导数就得到了初始约束(original constraint):
$\frac{\partial l}{\partial \lambda}= (1-\sum_k\theta_k)=0$(3.42)

利用总和为1这个约束条件就可以解出来$\lambda$:
$\sum_k\hat N_k =\lambda\sum_k \theta_k$(3.45)

$N+\alpha_0-K=\lambda$(3.46)
上式中的$\alpha_0\overset{\triangle}{=} \sum^K_{k=1}\alpha_k$等于先验中的样本规模.这样最大后验估计(MAP estimate)为:
$\hat\theta_k = \frac{N_k+\alpha_k-1}{N+\alpha_0-K}$(3.47)

这与等式2.77相一致.如果使用均匀分布作为先验,即$\alpha_k=1$,就能解出最大似然估计(MLE):
$\hat\theta_k=N_k/N$(3.48)

这正好是k面出现次数的经验分数(empirical fraction).


### 3.4.4 后验预测分布(Posterior predictive)


对一个单次多重伯努利实验(single multinoulli trial),后验预测分布如下所示:
$$
\begin{aligned}
p(X=j|D)&=\int p(X=j|\theta)p(\theta|D)d\theta &\text{(3.49)}\\
&=\int p(X=j|\theta_j)[\int p(\theta_{-j},\theta_j|D)d\theta_{-j}]d\theta_j &\text{(3.50)}\\
&=\int \theta_j p(\theta_j |D)d\theta =\mathrm{E}[\theta_j|D]=\frac{\alpha_j+N_j}{\sum_k(\alpha_k+N_k)}=\frac{\alpha_j+N_j}{\alpha_0+N}&\text{(3.51)}\\
\end{aligned}
$$

上式中的$\theta_{-j}$是除了$\theta_j$之外的其他所有$\theta$的成员,参考练习3.13.

上面的表达式避免了零计数问题(zero-count problem),参考3.3.4.1.实际上,贝叶斯光滑(Bayesian smoothing)在多项分布情况比二值分布中更重要,因为一旦将数据分成许多类别了,数据稀疏的可能性就增加了.


#### 3.4.4.1 实例:使用单词袋的语言模型

使用狄利克雷-多项模型进行贝叶斯光滑的一个应用就是语言建模(language modeling),就是预测一个序列中下一个位置出现什么词.
设第i个词为$X_i\in\{1,...K\}$,使用多重伯努利分布$Cat(\theta)$从所有其他词汇中独立取样.这就叫单词袋模型(bag of words model).知道了已经出现的单词序列之后,如何预测下一个单词可能是什么呢?

假设我们观察到的是下面这个序列,来自一段儿歌:

Mary had a little lamb, little lamb, little lamb,
Mary had a little lamb, its fleece as white as snow

然后设我们的词汇表包含下面的单词:


|mary |lamb| little |big |fleece |white |black |snow| rain| unk|
|---|---|---|---|---|---|---|---|---|---|
|1| 2| 3| 4| 5| 6| 7| 8| 9| 10|

上面表格中的 unk表示的是未知词汇,也就是所有没在列表中出现的其他词汇.要对儿歌进行编码,先去掉标点符号,然后去掉停止词(stop words)比如a/as/the等等.这就要进行词干化(stemming),意思就是把所有词汇恢复原形,去掉复数,去掉ing恢复动词本身等等.不过这个儿歌里面到没有这么麻烦的.把每个单词用词汇表中的索引号进行编码就得到了:
1 10 3 2 3 2 3 2
1 10 3 2 10 5 10 6 8
接下来忽略单词排序,只数一下每个单词出现的次数,得到一个频率分布表:


|单词|mary |lamb| little |big |fleece |white |black |snow| rain| unk|
|---|---|---|---|---|---|---|---|---|---|---|
|编号|1| 2| 3| 4| 5| 6| 7| 8| 9| 10|
|次数|2| 4| 4| 0| 1| 1| 0| 1| 0| 4|

上面的计数记作$N_j$.如果用一个狄利克雷函数$Dir(\alpha)$作为$\theta$的先验,后验预测分布为:
$p(\tilde X=j|D)=\mathrm{E}[\theta_j|D]=\frac{\alpha_j+N_j}{\sum_{j'}\alpha_{j'}+N_{j'}}=\frac{1+N_j}{10+17}$(3.52)

如果设$\alpha_j=1$,则有:
$p(\tilde X=j|D)=(3/27,5/27,5/27,1/27,2/27,2/27,1/27,2/27,1/27,5/27)$(3.53)

上面这个预测分布的众数(mode)是$X = 2 \text{(“lamb”)},X = 10 \text{(“unk”)}$.这里要注意,有的单词虽然没出现在当前看过的词汇序列中,但依然被预测了非零概率,也就是以后有可能出现,比如big/black/rain这几个词.后面还有更复杂的语言模型.


## 3.5 朴素贝叶斯分类器(Naive Bayes classiﬁers)

本节讨论的是对离散值特征向量进行分类,其中特征$x\in\{1,...,K\}^D$,K是每个特征的数值个数,D是特征数.这次要用一种通用方法.这就需要确定类条件分布(class conditional distribution)$p(x|y=c)$.最简单的方法,在给定类标签的情况下,假设所有特征有条件独立.这样就可以将类条件密度(class conditional density)写成一维密度的乘积：

$p(x|y=c,\theta)=\prod^D_{j=1}p(x_j|y=c,\theta_{jc})$(3.54)

这样得到的模型就叫做朴素贝叶斯分类器(naive Bayes classiﬁer,缩写为 NBC).

称之为"朴素(naive)"是因为我们并不指望各个特征独立,甚至即便在类标签上也未必有条件独立.不过即便朴素贝叶斯假设不成立,得到的分类结果也还都不错(Domingos and Pazzani 1997).一个原因就是这个模型特别简单,对于C个类D个特征的情况只有$O(CD)$个参数,所以相对来说不容易过拟合.

类条件密度的形式取决于每个特征的类型,下面给出一些可能的情况:
* 如果特征向量是实数值的,可以用高斯分布,也就是正态分布:$p(x|y=c,\theta)=\prod^D_{}N(x_j|\mu_{jc},\sigma^2_{jc})$,其中的$\mu_{jc}$是类c对象中特征j的均值,$\sigma^2_{jc}$是方差.
* 如果特征是二值化的,即$x_j\in\{0,1\}$,可以用伯努利分布:$p(x|y=c,\theta)=\prod^D_{j=1}Ber(x_j|\mu_{jc})$,其中的$\mu_{jc}$是特征j出现在类别c的概率.这有时候也叫做多元伯努利朴素贝叶斯模型(multivariate Bernoulli naive Bayes model).
* 如果是分类特征,$x_j\in\{1,...,K\}$,可以用多重伯努利(multinoulli)分布:$p(x|y=c,\theta)=\prod^D_{j=1}Cat(x_j|\mu_{jc})$,其中的$\mu_{jc}$是类中的$x_j$的K个可能值的频数(histogram).


当然还可以处理其他类型的特征,或者使用不同的分布假设.另外也可以对不同类型特征进行混合和匹配.

### 3.5.1 模型拟合

接下来就要"训练"一个朴素贝叶斯分类器了.一般都是对参数进行最大似然估计(MLE)或者最大后验估计(MAP estimate).不过本节还要讲如何对整个后验$p(\theta|D)$进行计算.

#### 3.5.1.1 朴素贝叶斯分类器的最大似然估计

单数据情况(single data case)下的概率为:
$p(x_i,y_i|\theta)=p(y_i|\pi)\prod_jp(x_{ij}|\theta_j)=\prod_c\pi_c^{I(y_i=c)}\prod_j\prod_cp(x_{ij}|\theta_{jc})^{I(y_i=c)} $(3.55)

这样则有对数似然率(log-likelihood):
$\log p(D|\theta) =\sum^C_{c=1}N_c\log\pi_c+\sum^D_{j=1}\sum^C_{c=1}\sum_{i:y_i=c}\log p(x_{ij}|\theta_{jc})$(3.56)

很明显上面这个表达式可以拆解成一系列子项,其中有一个包含了$\pi$,另外的DC项目包含了$\theta_{jc}$.所以可以对所有这些参数分开优化.

从等式3.48得知,分类先验(class porior)的最大似然估计(MLE)为:
$\hat\pi_c =\frac{N_c}{N}$(3.57)

上式中的$N_c\overset\triangle{=}\sum_iI(y_i=c)$,是类c中的样本个数.

对似然率的最大似然估计(MLE)依赖于我们对特征所选的分布类型.简单起见,假设所有特征都是二值化的,这样使用伯努利分布,即$x_j|y=c\sim  Ber(\theta_{jc} )$.这时候最大似然估计(MLE)则为:
$\hat\theta_{jc}=\frac {N_{jc}}{N_c}$(3.58)


这个模型拟合过程的实现特别简单,可以参考本书算法8作为伪代码,或者MATLAB代码中的naiveBayesFit.这个算法的复杂度是O(ND).此方法也很容易泛化拓展到对混合类型特征的应用上.由于简单,应用广泛.

图3.8给出的例子中,有2个类,600个二值特征,这些特征表示的是一个词是否出现在一个词汇袋模型中.图中对两类中的$\theta_c$向量进行了可视化.107位置上的特别高端峰值对应的是单词"subject",在两类中出现的概率都是1.在3.5.4会讲到如何"滤除(filter out)"这些非信息特征.




此处查看原书图 3.8

#### 3.5.1.2 使用贝叶斯方法的朴素贝叶斯(Bayesian naive Bayes)

最大似然估计有个麻烦就是可能会过拟合.比如图3.8中的例子,"subject"这个词,假设作为特征j,在两类中都出现,所以对应这个特征j的$\hat\theta_{jc}=1$.那如果收到一个新邮件其中不包含这个词会怎么办?算法就会崩溃了,因为发现对于两个类来说此事都有$p(y=c|x,\hat\theta)=0$.这也是3.3.4.1当中提到的黑天鹅悖论的另一种体现.

避免过拟合的简单解决方案就是使用贝叶斯方法.简单起见,使用一个因式化先验:
$p(\theta)=p(\pi)\prod^D_{j=1}\prod^C_{c=1}p(\theta_{jc})$(3.59)

对于$\pi$使用狄利克雷先验$Dir(\alpha)$,对每个参数$\theta_{jc}$采用$\beta$分布$Beta(\beta_0,\beta_1)$.通常就设$\alpha=1,\beta=1$对应的是加一光滑或者拉普拉斯光滑.

结合等式3.56当中的因式化似然率与因式化先验,就得到了下面的因式化后验:
$p(\theta|D)=p(\pi|D) \prod^D_{j=1}\prod^C_{c=1}p(\theta_{jc}|D)$(3.60)

$p(\pi|D)=Dir(N_1+\alpha_1,...,N_C+\alpha_C)$(3.61)

$p(\theta_{jc}|D)=Beta((N_c-N_{jc})+\beta_0,N_{jc}+\beta_1)$(3.62)

换句话说,要计算这个后验,只需要用似然率中的经验计数(empirical counts)更新先验计数(prior counts).修改一下算法8就可以进行这个版本的模型拟合了.

### 3.5.2 使用模型做预测

再测试的时候,目标是计算:

$p(y=c|x,D)\propto p(y=c|D)\prod^D_{j=1}p(x_j|y=c|D)$(3.63)

正确的贝叶斯步骤就是使用积分排除掉未知参数:
$$
\begin{aligned}
p(y=c|x,D)\propto & [\int Cat(y=c|\pi)p(\pi|D)d\pi]&\text{(3.64)}\\
&\prod^D_{j=1}[\int Ber(x_j|y=c,\theta_{jc})p(\theta_{jc}|D)]&\text{(3.65)}\\
\end{aligned}
$$

还好这个比较好实现,至少在后验为狄利克雷分布的时候挺简单的.参考等式3.51,我们知道后验预测密度可以通过插入后验均值参数$\theta$来获得.因此有:


$$
\begin{aligned}
p(y=c|x,D) &\propto  \bar\pi _C\prod^D_{j=1}(\bar\theta_{jc})^{I(x_j=1)} (1-\bar\theta_{jc})^{I(x_j=0)}  &\text{(3.66)}\\
\bar\theta_{jk} & =\frac{N_{jc}+\beta_1}{N_c+\beta_0+\beta_1} &\text{(3.67)}\\
\bar\pi_c & =\frac{N_c+\alpha_c}{N +\alpha_0} &\text{(3.68)}\\
\end{aligned}
$$

上式中$\alpha_0\\sum_c\alpha_c$.
如果我们通过单个点估计了后验,$p(\theta|D)\approx \delta_{\hat\theta}(\theta)$,其中的$\hat\theta$可以使最大似然估计(MLE)或者最大厚验估计(MAP),然后就可以通过对参数插值来得到后验预测密度了,生成的是一个虚拟一致规则(virtually identical rule):
$p(y=c|x,D)\propto \hat\pi_c\prod^D_{j=1}(\hat\theta_{jc})^{I(x_j=1}(1-\hat\theta_{jc})^{I(x_j=0)}$(3.69)

唯一具备就是把后验均值的$\bar\theta$换成了后验众数或者最大似然估计$\hat\theta$.不过这差别虽然小,实践中的影响可能很大,因为后验均值更不容易过拟合,参考本书3.4.4.1.

### 3.5.3 求对数-相加-幂运算组合技巧(log-sum-exp trick)
接下来要讨论的是一个在使用各种通用分类器的时候都很有用的重要应用细节.对类标签的后验计算可以使用等式2.13,使用合适的类条件密度(class-conditional density)(以及插值近似).然而很不幸,直接使用等式2.13进行计算可能会因为数值向下溢出(numerical underﬂow)而失败.这是因为概率$p(x|y=c)$通常都是非常非常小的数值,尤其是如果x是高维度向量的时候更是如此.而概率总和必然是1,即$\sum_xp(x|y)=1$,所以任何特定的高维度向量被观测到的概率都是很小的.要解决这个问题,就需要在应用贝叶斯规则的时候先取对数,如下所示:
$$
\begin{aligned}
\log p(y=c|X)&= b_c-\log[\sumˆC_{c'=1}eˆ{b_{c'}}]&\text{(3.70)}\\
 b_c& \overset\triangle{=}\log p(x|y=c)+\log p(y=c) &\text{(3.71)}
\end{aligned}
$$
然而这需要我们计算下面这个表达式:
$\log[\sum_{c'}e^{b_{c'}}]  = \log[\sum_{c'}p(y=c',x)]=\log p(x)$(3.72)

可是这算起来挺麻烦的,不过好在可以找到最大因子项,然后提取出来,用这一项来表示其他的,如下所示:

$\log(e + e^{−121} ) = \log e −120 (e^0 + e^{−1} ) = \log(e^0 + e^{−1} ) − 120$(3.73)

通常来说就得到下面这种:

$\log\sum_ce^{b_c} =\log[(\sum_ce^{b_c-B})e^B]=[\log(\sum_ce^{b_c-B})]+B$(3.74)

其中的最大公因式项$B=\max_cb_c$.这种手法就是求对数-相加-幂运算组合技巧(log-sum-exp trick),用的很广泛,PMTK3中的logsumexp就是一个实例.

这个方法用在了算法1中,算法以的伪代码是使用朴素贝叶斯分类器来计算$p(y_i|x_i,\hat\theta)$.PMTK3中的naiveBayesPredict是MATLAB代码.如果只要计算$\hat y_i$其实并不需要这样做,因为直接将未归一化的量$\log p(y_i = c) + \log p(x_i |y = c).$最大化就可以了.


### 3.5.4 使用互信息量进行特征选择

朴素贝叶斯分类器是对一个在多个潜在特征上的联合分布进行拟合,所以可能会过拟合.另外其运算上的开销是O(D),对于某些情况下可能太高开销了.一种解决这些问题的常见方法就是进行特征选择(feature selection),移除一些对于分类问题本身没有太大帮助的"不相关(irrelevant)"信息.最简单的信息选择方法就是单独评价每个特征的相关性(relevance),然后选择最大的K个,K是根据精确率和复杂度之间的权衡来选择的.这种方法也叫做变量排序/过滤/筛选.
衡量相关性的一个手段就是利用互信息量(mutual information),参考本书2.8.3.要计算特征$X_j$和分类标签Y之间的互信息量:
$I(X,Y) = \sum_{x_j} \sum_y p(x_j,y) \log \frac{p(x_j,y)}{p(x_j)p(y)}$(3.75)

互信息量可以被理解为在观测了特诊j的值的时候标签分布上的信息熵降低.如果特征是二值化的,就很明显可以用下面的公式来计算(参见练习3.2.1):
$I_j=\sum_c[\theta_{jc}\pi_c\log\frac{\theta_{jc}}{\theta_{j}}+ (1-\theta_{jc})\pi)c\log\frac{1-\theta_{jc}}{1-\theta_{j}}  ]$(3.76)

上式中的$\pi_c=p(y=c),\theta_{jc}=p(x_j=1|y=c),\theta_j=p(x_j=1)=\sum_c\pi_c\theta_{jc}$,所有这些量都可以在拟合朴素贝叶斯分类器的时候作为副产品被计算出来. 


表3.1展示的是将这个方法用于图3.8所示的二值化词汇袋得到的结果.从表中可以看到有最高互信息量的单词会比常见单词有更大区别作用(discriminative).例如两类中最常见的单词就是"subject"主体,者经常出现因为这两份都是新闻组数据,总会包含一个主题行.不过很明显这个词没有什么区别作用.带有分类标签的最高互信息量的词汇按照降序排列为"windows”, “microsoft”, “DOS”,“motif”这就合理了,因为这两个分类对应的是微软的Windows和X Windows.

### 3.5.5 使用词汇袋进行文档分类

文档分类(Document classiﬁcation)问题是要把文本文档分成不同类别.一个简单方法就是把每个文档都看做二值化向量,每个单词是否出现是值,当且仅当单词j出现在文档i当中$x_{ij}=1$,否则$x_{ij}=0$.就可以用下面的分类条件密度了:
$p(x_i|y_i=c,\theta)=\prod^D_{j=1}Ber(x_{ij}|\theta_{jc} =\prod^D_{j=1}\theta_{jc}^{I(x_{ij})}(1-\theta_{jc})^{I(1-x_{ij})} $(3.77)
这也叫做伯努利乘积模型(Bernoulli product model,),或者叫二值独立模型(binary independence model).

可是上面这个模型只有是否包含单词这个信息,缺失了单词出现次数,丢失了很多信息(McCallum and Nigam 1998).更精确的表示需要记录每个单词出现的次数.具体来说设$x_i$是文档i的技术向量,所以有$x_{ij}\in\{0,1,...,N_i\}$,其中$N_i$是文档i中的词汇总数,所以有$\sum^D_{j=1}x_{ij}=N_i$.对于类条件密度,可以使用多项式分布(multinomial distribution):

$p(x_i|y_i=c,\theta)=Mu(x_i|N_i,\theta_c)=\frac{N_i!}{\prod^D_{j=1}x_{ij}!}\prod^D_{j=1}\theta^{x_{ij}}_{jc}$(3.78)

上式中我们隐含着假设了文档长度$N_i$与类别不相关.其中的$\theta_{jc}$是c类文档中生成单词j的的概率;因此对于每个类别c,这些参数都要满足归一化约束$\sum^D_{j=1}\theta_{jc}=1$

虽然多项式分类器(multinomial classiﬁer)训练起来简单,测试的时候用着也简单,但对于文档分类来说并不太适合.一个原因就是这个模型没有考虑单词使用的时候的突发性(burstiness ).这是指单词突发出现的现象,有的单词可能之前从来没在给定的文档中出现过,但是一旦出现一次,之后就可能出现不止一次了.
多项式模型不能捕获这种单词突发现象.具体原因可以参考等式3.78当中的一项为$\theta_{jcv}^{N_{ij}}$,对于罕见词汇来说,$\theta_{jc}<<1$,越来越不可能出现很多了.对于更多常见词,这个衰减速率(decay rate)就没那么显著了.直观理解的话,要注意大多数常见词都是功能词,比如助词介词之类的,并不能够对应特定文档类别.比如 and 这个词出现的概率基本是固定的,不受之前出现多少次(文档长度模数 modulo document length)的影响,所以与文档类别不相关掉假设对于这些常见词就更适合一些.不过罕见词对文档分类来说更重要,我们建模的时候要对这些罕见次仔细对待.

为了改善多项式文档分类器的效果,已经有很多特征启发式(ad hoc heuristics)的方法被开发了出来(Rennie et al. 2003).有另外一种类条件密度(class conditional density)方法,性能表现和特征启发方法一样好,而可以从概率角度解释 (Madsen et al. 2005).

若把多项式类条件密度替换成狄利克雷复合多项式密度(Dirichlet Compound Multinomial,缩写为DCM),定义如下所示:

$p(x_i|y_i=c,\alpha)=\in Mu(x_i|N_i,\theta_c)Dir(\theta_c|\alpha_c)d\theta_c=\frac{N_i!}{prod^D_{j=1}x_{ij}!}\frac{B(x_i+\alpha_c)}{B(\alpha_c)}$(3.79)

这个等式是在等式5.24中推导出来的.令人惊讶的是只要稍作上述改动就可以捕获到罕见词的突发现象.直观来说理由如下:看到一个出现过的词之后,比如词汇j,后验技术$\theta_j$就更新了,让单词j的另一次出现的概率提高.相反,如果$\theta_j$是固定的,那么每个词出现就是独立的.这个多项模型对应的就像是从一个瓮(坛子)里有K种颜色的球当中抽取一个球,记录下颜色,然后替换掉.与之对比的狄利克雷复合多项模型(DCM)对应的是抽取一个球,记录下颜色,然后用一个额外的副本替换掉他;这也叫做波利亚瓮(Polya urn)模型.

如 (Madsen et al. 2005)所述,使用DCM比单纯用多项式的效果更好,并且和现代方法性能表现相当.唯一的劣势就是狄利克雷复合多项式模型(DCM)拟合起来更复杂了些,更多细节参考(Minka 2000e; Elkan 2006) .


# MLAPP 读书笔记 - 04 高斯模型(Gaussian models)

> A Chinese Notes of MLAPP，MLAPP 中文笔记项目 
https://zhuanlan.zhihu.com/python-kivy

记笔记的人：[cycleuser](https://www.zhihu.com/people/cycleuser/activities)

2018年05月16日10:49:49


## 4.1 简介

本章要讲的是多元高斯分布(multivariate Gaussian),或者多元正态分布(multivariate normal ,缩写为MVN)模型,这个分布是对于连续变量的联合概率密度函数建模来说最广泛的模型了.未来要学习的其他很多模型也都是以此为基础的.

然而很不幸的是,本章所要求的数学水平也是比很多其他章节都要高的.具体来说是严重依赖线性代数和矩阵积分.要应对高维数据,这是必须付出的代价.初学者可以跳过标记了星号的章.另外本章有很多等式,其中特别重要的用方框框了起来.

### 4.1.1 记号

这里先说几句关于记号的问题.向量用小写字母粗体表示,比如**x**.矩阵用大写字母粗体表示,比如**X**.大写字母加下标表示矩阵中的项,比如$X_{ij}$.
所有向量都假设为列向量(column vector),除非特别说明是行向量.通过堆叠(stack)D个标量(scalar)得到的类向量记作$[x_1,...,x_D]$.与之类似,如果写**x=**$[x_1,...,x_D]$,那么等号左侧就是一个高列向量(tall column vector),意思就是沿行堆叠$x_i$,一般写作**x=**$(x_1^T,...,x_D^T)^T$,不过这样很丑哈.如果写**X=**$[x_1,...,x_D]$,等号左边的就是矩阵,意思就是沿列堆叠$x_i$,建立一个矩阵.

### 4.1.2 基础知识

回想一下本书2.5.2中关于D维度下的多元正态分布(MVN)概率密度函数(pdf)的定义,如下所示:
$N(x|\mu,\Sigma)\overset{\triangle}{=} \frac{1}{(2\pi)^{D/2}|\Sigma |^{1/2}}\exp[ -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)]$(4.1 重要公式)


此处查看原书图 4.1

指数函数内部的是一个数据向量**x**和均值向量**$\mu$** 之间的马氏距离(马哈拉诺比斯距离,Mahalanobis distance).对$\Sigma$进行特征分解(eigendecomposition)有助于更好理解这个量.$\Sigma = U\Lambda U ^T$,其中的U是标准正交矩阵(orthonormal matrix),满足$U^T U = I$,而$\Lambda $是特征值组成的对角矩阵.经过特征分解就得到了:

$\Sigma^{-1}=U^{-T}\Lambda ^{-1}U^{-1}=U\Lambda  ^{-1}U^T=\sum^D_{i=1}\frac{1}{\lambda_i}u_iu_i^T$(4.2)

上式中的$u_i$是U的第i列,包含了第i个特征向量(eigenvector).因此就可以把马氏距离写作:


$$\begin{aligned}
(x-\mu)^T\Sigma^{-1}(x-\mu)&=(x-\mu)^T(\sum^D_{i=1}\frac{1}{\lambda_i}u_iu_i^T)(x-\mu)&\text{(4.3)}\\
&= \sum^D_{i=1}\frac{1}{\lambda_i}(x-\mu)^Tu_iu_i^T(x-\mu)=\sum^D_{i=1}\frac{y_i^2}{\lambda_i}&\text{(4.4)}\\
\end{aligned}$$

上式中的$y_i\overset{\triangle}{=} u_i^T(x-\mu)$.二维椭圆方程为:
$\frac{y_1^2}{\lambda_1}+\frac{y_2^2}{\lambda_2}=1$(4.5)

因此可以发现高斯分布的概率密度的等值线沿着椭圆形,如图4.1所示.特征向量决定了椭圆的方向,特征值决定了椭圆的形态即宽窄比.

一般来说我们将马氏距离(Mahalanobis distance)看作是对应着变换后坐标系中的欧氏距离(Euclidean distance),平移$\mu$,旋转U.

### 4.1.3 多元正态分布(MVN)的最大似然估计(MLE)

接下来说的是使用最大似然估计(MLE)来估计多元正态分布(MVN)的参数.在后面的章节里面还会说道用贝叶斯推断来估计参数,能够减轻过拟合,并且能对估计值的置信度提供度量.

#### 定理4.1.1(MVN的MLE)
如果有N个独立同分布样本符合正态分布,即$x_i \sim  N(\mu,\Sigma)$,则对参数的最大似然估计为:
$\hat\mu_{mle}=\frac{1}{N}\sum^N_{i=1}x_i \overset{\triangle}{=} \bar x$(4.6)
$\hat\Sigma_{mle}=\frac{1}{N}\sum^N_{i=1}(x_i-\bar x)(x_i-\bar x)^T=\frac{1}{N}(\sum^N_{i=1}x_ix_i^T)-\bar x\bar x^T$(4.7)

也就是MLE就是经验均值(empirical mean)和经验协方差(empirical covariance).在单变量情况下结果就很熟悉了:
$\hat\mu =\frac{1}{N}\sum_ix_i=\bar x$(4.8)
$\hat\sigma^2 =\frac{1}{N}\sum_i(x_i-x)^2=(\frac{1}{N}\sum_ix_i^2)-\bar x^2$(4.9)

#### 4.1.3.1 证明*

要证明上面的结果,需要一些矩阵代数的计算,这里总结一下.等式里面的**a**和**b**都是向量,**A**和**B**都是矩阵.记号$tr(A)$表示的是矩阵的迹(trace),是其对角项求和,即$tr(A)=\sum_i A_{ii}$.

$$
\begin{aligned}
\frac{\partial(b^Ta)}{\partial a}&=b\\
\frac{\partial(a^TAa)}{\partial a}&=(A+A^T)a\\
\frac{\partial}{\partial A} tr(BA)&=B^T\\
\frac{\partial}{\partial A} \log|A|&=A^{-T}\overset{\triangle}{=} (A^{-1})^T\\
tr(ABC)=tr(CAB)&=tr(BCA)
\end{aligned}
$$(4.10 重要公式)


上式中最后一个等式也叫做迹运算的循环置换属性(cyclic permutation property).利用这个性质可以推广出很多广泛应用的求迹运算技巧(trace-trick),对标量内积$x^TAx$就可以按照如下方式重新排序:
$x^TAx=tr(x^TAx)=tr(xx^TA)=tr(Axx^T)$(4.11)


##### 证明过程
接下来要开始证明了,对数似然函数为:

$l(\mu,\Sigma)=\log p(D|\mu,\Sigma)=\frac{N}{2}\log|\Lambda | -\frac{1}{2}\sum^N_{i=1}(x_i-\mu)^T\Lambda  (x_i-\mu)$(4.12)

上式中$\Lambda =\Sigma^{-1}$,是精度矩阵(precision matrix)

然后进行一个替换(substitution)$y_i=x_i-\mu$,再利用微积分的链式法则:

$$
\begin{aligned}
\frac{\partial}{\partial\mu} (x_i-\mu)^T\Sigma^{-1}(x_i-\mu) &=  \frac{\partial}{\partial y_i}y_i^T\Sigma^{-1}y_i\frac{\partial y_i}{\partial\mu}   &\text{(4.13)}\\
&=-1(\Sigma_{-1}+\Sigma^{-T})y_i &\text{(4.14)}\\
\end{aligned}
$$

因此:

$$
\begin{aligned}
\frac{\partial}{\partial\mu}l(\mu.\Sigma) &= -\frac{1}{2} \sum^N_{i=1}-2\Sigma^{-1}(x_i-\mu)=\Sigma^{-1}\sum^N_{i=1}(x_i-\mu)=0 &\text{(4.15)}\\
&=-1(\Sigma_{-1}+\Sigma^{-T})y_i &\text{(4.16)}\\
\end{aligned}
$$
所以$\mu$的最大似然估计(MLE)就是经验均值(empirical mean).

然后利用求迹运算技巧(trace-trick)来重写对$\Lambda$的对数似然函数:
$$
\begin{aligned}
l(\Lambda )&=  \frac{N}{2}\log|\Lambda |-\frac{1}{2}\sum_i tr[(x_i-\mu)(x_i-\mu)^T\Lambda ] &\text{(4.17)}\\
&= \frac{N}{2}\log|\Lambda | -\frac{1}{2}tr[S_{\mu}\Lambda ]&\text{(4.18)}\\
& &\text{(4.19)}\\
\end{aligned}
$$

上式中
$S_{\mu}\overset{\triangle}{=} \sum^N_{i=1}(x_i-\mu)(x_i-\mu)^T$(4.20)

是以$\mu$为中心的一个散布矩阵(scatter matrix).对上面的表达式关于$\Lambda$进行求导就得到了:
$$
\begin{aligned}
\frac{\partial l(\Lambda )}{\partial\Lambda } & = \frac{N}{2}\Lambda ^{-T} -\frac{1}{2}S_{\mu}^T=0 &\text{(4.21)}\\
\Lambda ^{-T} & = \Lambda ^{-1}=\Sigma=\frac{1}{N}S_{\mu} &\text{(4.22)}\\
\end{aligned}
$$

因此有:
$\hat\Sigma=\frac{1}{N}\sum^N_{i=1}(x_i-\mu)(x_i-\mu)^T$(4.23)

正好也就是以$\mu$为中心的经验协方差矩阵(empirical covariance matrix).如果插入最大似然估计$\mu=\bar x$(因为所有参数都同时进行优化),就得到了协方差矩阵的最大似然估计的标准方程.


### 4.1.4 高斯分布最大熵推导(Maximum entropy derivation of the Gaussian)*

在本节,要证明的是多元高斯分布(multivariate Gaussian)是适合于有特定均值和协方差的具有最大熵的分布(参考本书9.2.6).这也是高斯分布广泛应用到一个原因,均值和协方差这两个矩(moments)一般我们都能通过数据来进行估计得到(注:一阶矩（期望）归零，二阶矩（方差）),所以我们就可以使用能捕获这这些特征的分布来建模,另外还要尽可能少做附加假设.

为了简单起见,假设均值为0.那么概率密度函数(pdf)就是:
$p(x)=\frac{1}{Z}\exp (-\frac{1}{2}x^T\Sigma^{-1}x)$(4.24)

如果定义$f_{ij} (x) = x_i x_j , \lambda_{ij} = \frac{1}{2} (\Sigma^{−1})_{ij}\\i, j \in \{1, ... , D\}$,就会发现这个和等式9.74形式完全一样.这个分布（使用自然底数求对数）的（微分）熵为:
$h(N(\mu,\Sigma))  =\frac{1}{2}\ln[(2\pi e)^D|\Sigma|]$(4.25)

接下来要证明有确定的协方差$\Sigma$的情况下多元正态分布(MVN)在所有分布中有最大熵.

#### 定理 4.1.2

设$q(x)$是任意的一个密度函数,满足$\int q(x)x_ix_j=\Sigma_{ij}$.设$p=N(0,\Sigma)$.那么$h(q)\le h(p)$.

证明.(参考(Cover and Thomas 1991, p234)).
(注:KL是KL 散度(Kullback-Leibler divergence),也称相对熵(relative entropy),可以用来衡量p和q两个概率分布的差异性(dissimilarity).更多细节参考2.8.2.)

$$
\begin{aligned}
0 &\le KL(q||p) =\int q(x)\log \frac{q(x)}{p(x)}dx&\text{(4.26)}\\
& = -h(q) -\int q(x)\log p(x)dx &\text{(4.27)}\\
& =* -h(q) -\int ps(x)\log p(x)dx &\text{(4.28)}\\
& = -h(q)+h(p) &\text{(4.29)}\\
\end{aligned}
$$


等式4.28那里的星号表示这一步是关键的,因为q和p对于由$\log p(x)$编码的二次形式产生相同的矩(moments).

## 4.2 高斯判别分析(Gaussian discriminant analysis)

多元正态分布的一个重要用途就是在生成分类器中定义类条件密度,也就是:
$p(x|y=c,\theta)=N(x|\mu_c,\Sigma_c)$(4.30)

这样就得到了高斯判别分析,也缩写为GDA,不过这其实还是生成分类器(generative classifier）,而并不是辨别式分类器（discriminative classifier）,这两者的区别参考本书8.6.如果\Sigma_c$$是对角矩阵,那这就等价于朴素贝叶斯分类器了.


此处查看原书图 4.2

从等式2.13可以推导出来下面的决策规则,对一个特征向量进行分类:
$\hat y(x)=\arg \max_c[\log  p(y=c|\pi)  +\log p(x|\theta_c)]$(4.31)

计算x 属于每一个类条件密度的概率的时候,测量的距离是x到每个类别中心的马氏距离(Mahalanobis distance).这也是一种最近邻质心分类器(nearest centroids classiﬁer).

例如图4.2展示的就是二维下的两个高斯类条件密度,横纵坐标分别是身高和体重,包含了男女两类人.很明显身高体重这两个特征有相关性,就如同人们所想的,个子高的人更可能重.每个分类的椭圆都包含了95%的概率质量.如果对两类有一个均匀分布的先验,就可以用如下方式来对新的测试向量进行分类:



$\hat y(x)=\arg \min_c(x-\mu_c)^T\Sigma_c^{-1}(x-\mu_c)$(4.32)


### 4.2.1 二次判别分析(Quadratic discriminant analysis,QDA)

对类标签的后验如等式2.13所示.加入高斯密度定义后,可以对这个模型获得更进一步的理解:
$p(y=c|x,\theta)  =\frac{ \pi_c|2\pi\Sigma_c|^{-1/2} \exp [-1/2(x-\mu_c)^T\Sigma_c^{-1}(x-\mu_c)]   }{   \Sigma_{c'}\pi_{c'}|2\pi\Sigma_{c'}|^{-1/2} \exp [-1/2(x-\mu_{c'})^T\Sigma_{c'}^{-1}(x-\mu_{c'})]    }$(4.33)

对此进行阈值处理(thresholding)就得到了一个x的二次函数(quadratic function).这个结果也叫做二次判别分析(quadratic discriminant analysis,缩写为QDA).图4.3所示的是二维平面中决策界线的范例.


此处查看原书图 4.3

此处查看原书图 4.4


### 4.2.2 线性判别分析(Linear discriminant analysis,LDA)

接下来考虑一种特殊情况,此事协方差矩阵为各类所共享(tied or shared),即$\Sigma_c=\Sigma$.这时候就可以把等式4.33简化成下面这样:
$$
\begin{aligned}
p(y=c|x,\theta)&\propto \pi_c\exp [\mu_c^T\Sigma^{-1}x-\frac12 x^T\Sigma^{-1}x - \frac12\mu_c^T\Sigma^{-1}\mu_c]&\text{(4.34)}\\
& = \exp [\mu_c^T\Sigma^{-1}x-\frac12 \mu_c^T\Sigma^{-1}\mu_c+\log\pi_c]\exp [-\frac12 x^T\Sigma^{-1}x]&\text{(4.35)}\\
\end{aligned}
$$

由于二次项$x^T\Sigma^{-1}$独立于类别c,所以可以抵消掉分子分母.如果定义了:





$$
\begin{aligned}
\gamma_c &= -\frac12\mu_c^T\Sigma^{-1}\mu_c+\log\pi_c&\text{(4.36)}\\
&\text{(4.37)}\\
\beta_c &= \Sigma^{-1}\mu_c\end{aligned}
$$

则有:
$p(y=c|x,\theta)=\frac{e^{\beta^T_c+\gamma_c}}{\Sigma_{c'}e^{\beta^T_{c'}+\gamma_{c'}}}=S(\eta)_c$(4.38)

当$\eta =[\beta^T_1x+\gamma_1,...,\beta^T_Cx+\gamma_C]$的时候,$S$就是Softmax函数(softmax function,注:柔性最大函数,或称归一化指数函数),其定义如下:
$S(\eta/T)= \frac{e^{\eta_c}}{\sum^C_{c'=1}e^{\eta_{c'}}}$(4.39)

Softmax函数如同其名中的Max所示,有点像最大函数.把每个$\eta_c$除以一个常数T,这个常数T叫做温度(temperature).然后让T趋于零,即$T\rightarrow 0$,则有:

$$S(\eta/T)_c=\begin{cases} 1.0&\text{if } c = \arg\max_{c'}\eta_{c'}\\
0.0 &\text{otherwise}\end{cases} 
$$(4.40)


也就是说,在低温情况下,分布总体基本都出现在最高概率的状态下,而在高温下,分布会均匀分布于所有状态.参见图4.4以及其注解.这个概念来自统计物理性,通常称为玻尔兹曼分布(Boltzmann distribution),和Softmax函数的形式一样.

等式4.38的一个有趣性质是,如果取对数,就能得到一个关于x的线性函数,这是因为$x^T\Sigma^{-1}x$从分子分母中约掉了.这样两个类 c 和 c'之间的决策边界就是一条直线了.所以这种方法也叫做线性判别分析(linear discriminant analysis,缩写为LDA).可以按照如下方式来推导出这条直线的形式:
$$
\begin{aligned}
p(y=c|x,\theta)& = p(y=c'|x,\theta)    &\text{(4.41)}\\
\beta^T_cx+\gamma_c& = \beta^T_{c'}x+\gamma_{c'}   &\text{(4.42)}\\
x^T(\beta_{c'}-\beta)& = \gamma_{c'}-\gamma_c    &\text{(4.43)}\\
\end{aligned}
$$

样例参考图4.5.

除了拟合一个线性判别分析(LDA)模型然后推导类后验之外,还有一种办法就是对某$C\times D$权重矩阵(weight matrix)W,直接拟合$p(y|x,W)=Cat(y|Wx)$.这叫做多类逻辑回归(multi-class logistic regression)或者多项逻辑回归(multinomial logistic regression).此类模型的更多细节将在本书8.2中讲解,两种方法的区别在本书8.6中有解释.


此处查看原书图 4.5

此处查看原书图 4.6



### 4.2.3 双类线性判别分析(Two-class LDA)

为了更好理解上面那些等式,咱们先考虑二值化分类的情况.这时候后验为:
$$
\begin{aligned}
p(y=1|x,\theta)& =\frac{e^{\beta^T_1x+\gamma_1}}{e^{\beta^T_1x+\gamma_1}+e^{\beta^T_0x+\gamma_0}}    &\text{(4.44)}\\
& = \frac{1}{1+e^{(\beta_0-\beta_1))^Tx+(\gamma_0-\gamma_1)}} =sigm((\beta_1-\beta_0)^Tx+(\gamma_1-\gamma_0))  &\text{(4.45)}\\
\end{aligned}
$$

上式中的$sigm(\eta)$就是之前在等式1.10中提到的S型函数(sigmoid function).现在则有:
$$
\begin{aligned}
\gamma_1-\gamma_0 & = -\frac{1}{2}\mu^T_1\Sigma^{-1}\mu_1+\frac{1}{2}\mu^T_0\Sigma^{-1}\mu_0+\log(\pi_1/\pi_0) &\text{(4.46)}\\
& =  -\frac{1}{2}(\mu_1-\mu_0)^T\Sigma^{-1}(\mu_1+\mu_0) +\log(\pi_1/\pi_0) &\text{(4.47)}\\
\end{aligned}
$$

所以如果定义:

$$
\begin{aligned}
w&=  \beta_1-\beta_0=\Sigma^{-1}(\mu_1-\mu_0)&\text{(4.48)}\\
x_0 & =  -\frac{1}{2}(\mu_1+\mu_0)-(\mu_1-\mu_0)\frac{\log(\pi_1/\pi_0) }{(\mu_1-\mu_0)^T\Sigma^{-1}(\mu_1-\mu_0)} &\text{(4.49)}\\
\end{aligned}
$$

然后就有$w^Tx_0=-(\gamma_1-\gamma_0)$,因此:
$p(y=1|x,\theta) = sigm(w^T(x-x_0))$ (4.50)

这个形式和逻辑回归(logistic regression)关系密切,对此将在本书8.2中讨论.所以最终的决策规则为:将x移动$x_0$,然后投影到线w上,看结果的正负号.
如果$\Sigma=\sigma^2I$,那么w就是$\mu_1-\mu_0$的方向.我们对点进行分类就要根据其投影距离$\mu_1$和$\mu_0$哪个更近.如图4.6所示.另外,如果$\pi_1=\pi_0$,那么$x_0=\frac{1}{2}(\mu_1+\mu_0)$,正好在两个均值的中间位置.如果让$\pi_1> \pi_0$,则$x_0$更接近$\mu_0$,所以图中所示线上更多位置属于类别1.反过来如果$\pi_1 < \pi_0$则边界右移.因此,可以看到类的先验$\pi_c$只是改变了决策阈值,而并没有改变总体的结合形态.类似情况也适用于多类情景.

w的大小决定了对数函数的陡峭程度,取决于均值相对于方差的平均分离程度.在心理学和信号检测理论中,通常定义一个叫做敏感度指数(sensitivity index,也称作 d-prime)的量,表示信号和背景噪声的可区别程度:

$d'\overset{\triangle}{=} \frac{\mu_1-\mu_0}{\sigma}$(4.51)

上式中的$\mu_1$是信号均值,$\mu_0$是噪音均值,而$\sigma$是噪音的标准差.如果敏感度指数很大,那么就意味着信号更容易从噪音中提取出来.


### 4.2.4 对于判别分析(discriminant analysis)的最大似然估计(MLE)

现在来说说如何去拟合一个判别分析模型(discriminant analysis model).最简单的方法莫过于最大似然估计(maximum likelihood).对应的对数似然函数(log-likelihood)如下所示:

$\log p(D|\theta) =[\sum^N_{i=1}\sum^C_{c=1}I(y_i=c)\log\pi_c] + \sum^C_{c=1}[\sum_{i:y_i=c}\log N(x|\mu_c,\Sigma_c)]$(4.52)

显然这个式子可以因式分解成一个含有$\pi$的项,以及对应每个$\mu_c,\Sigma_c$的C个项.因此可以分开对这些参数进行估计.对于类先验(class prior),有$\hat\pi_c=\frac{N_c}{N}$,和朴素贝叶斯分类器里一样.对于类条件密度(class-conditional densities),可以根据数据的类别标签来分开,对于每个高斯分布进行最大似然估计:

$\hat\mu_c=\frac{1}{N_c}\sum_{i:y_i=c}x_i,\hat\Sigma_c=\frac{1}{N_c}\sum_{i:y_i=c}(x_i-\hat\mu_c)(x_i-\hat\mu_c)^T(4.53)

具体实现可以参考本书配套的PMTK3当中的discrimAnalysisFit是MATLAB代码.一旦一个模型拟合出来了,就可以使用discrimAnalysisPredict来进行预测了,具体用到的是插值近似(plug-in approximation).

### 4.2.5 防止过拟合的策略

最大似然估计(MLE)的最大优势之一就是速度和简洁.然而,在高维度数据的情况下,最大似然估计可能会很悲惨地发生过拟合.尤其是当$N_c<D$,全协方差矩阵(full covariance matrix)是奇异矩阵的时候(singular),MLE方法很容易过拟合.甚至即便$N_c>D$,MLE也可能是病态的(ill-conditioned),意思就是很接近奇异.有以下几种方法来预防或解决这类问题:

* 假设类的特征是有条件独立的(conditionally independent),对这些类使用对角协方差矩阵(diagonal covariance matrix);这就等价于使用朴素贝叶斯分类器了,参考本书3.5.
* 使用一个全协方差矩阵,但强制使其对于所有的类都相同,即$\Sigma_c=\Sigma$.这称为参数绑定(parameter tying)或者参数共享(parameter sharing),等价于线性判别分析(LDA),参见本书4.2.2.
* 使用一个对角协方差矩阵,强迫共享.这叫做对角协方差线性判别分析,参考本书4.2.7.
* 使用全协方差矩阵,但倒入一个先验,然后整合.如果使用共轭先验(conjugate prior)就能以闭合形式(closed form)完成这个过程,利用了本书4.6.3当中的结果;这类似于本书3.5.1.2当中提到的使用贝叶斯方法的朴素贝叶斯分类器(Bayesian naive Bayes),更多细节参考 (Minka 2000f).
* 拟合一个完整的或者对角协方差矩阵,使用最大后验估计(MAP estimate),接下来会讨论两种不同类型的实现.
* 将数据投影到更低维度的子空间,然后在子空间中拟合其高斯分布.更多细节在本书8.6.3.3,其中讲了寻找最佳线性投影(即最有区分作用)的方法. 

接下来说一些可选类型.

### 4.2.6 正交线性判别分析(Regularized LDA)*

假如我们在线性判别分析中绑定了协方差矩阵,即$\Sigma_c=\Sigma$,接下来就要对$\Sigma$进行最大后验估计了,使用一个逆向Wishart先验,形式为$IW(diag(\hat\Sigma_{mle}),v_0)$,更多内容参考本书4.5.1.然后就有了:

$\hat\Sigma=\lambda diag(\hat\Sigma_{mle})+(1-\lambda)\hat\Sigma_{mle}$(4.54)

上式中的$\lambda$控制的是正则化规模(amount of regularization),这和先验强度(strength of the prior),$v_0$有关,更多信息参考本书4.6.2.1.这个技巧就叫做正则化线性判别分析(regularized discriminant analysis,缩写为 RDA,出自Hastie et al. 2009, p656).

当对类条件密度进行评估的时候,需要计算$\hat\Sigma^{-1}$,也就要计算$\hat\Sigma^{-1}_{mle}$,如果$D>N$那就没办法计算了.不过可以利用对矩阵X的奇异值分解（Singular Value Decomposition,缩写为SVD,参考本书12.2.3)来解决这个问题,如下面所述.(注意这个方法不能用于二次判别分析(QDA,因为QDA不是关于x 的线性函数,是非线性函数了.)

设$X=UDV^T$是对设计矩阵(design matrix)的SVD分解,其中的V/U分别是$D\times N$和$N\times N$的正交矩阵(orthogonal matrix),而D是规模为N的对角矩阵(diagonal matrix).定义一个$N\times N$的矩阵$Z=UD$;这就像是一个在更低维度空间上的设计矩阵,因为我们假设了$N<D$.另外定义$\mu_z=V^T\mu$作为降维空间中的数据均值;可以通过$mu=V\mu_z$来恢复到原始均值,因为$V^TV=VV^T=I$.有了这些定义之后,就可以把最大似然估计(MLE)改写成下面的形式了:
$$
\begin{aligned}\\
\hat \Sigma_{mle} &= \frac{1}{N}X^TX-\mu\mu^T &\text{(4.55)}\\
&= \frac{1}{N}(ZV^T)^T(ZV^T)-(V\mu-z)(V\mu_z)^T &\text{(4.56)}\\
&= \frac{1}{N}VZ^TZV^T-V\mu_z\mu_z^TV^T &\text{(4.57)}\\
&= V(\frac{1}{N}Z^TZ-\mu_z\mu_z^T)V^T &\text{(4.58)}\\
&= V\hat\Sigma_zV^T &\text{(4.59)}\\
\end{aligned}\\
$$

上式中的$\hat\Sigma_z$是**Z**的经验协方差(empirical covariance).因此要重新写成最大后验估计(MAP)为:
$$
\begin{aligned}
\hat\Sigma_{map}&=V\tilde\Sigma_zV^T &\text{(4.60)}\\
\tilde\Sigma_z &= \lambda diag(\hat\Sigma_z)+(1-\lambda)\hat\Sigma_z &\text{(4.61)}
\end{aligned}
$$

注意,我们并不需要真正去计算出来这个$D\times D$矩阵$\hat\Sigma_{map}$.这是因为等式4.38告诉我们,要使用线性判别分析(LDA)进行分类,唯一需要计算的也就是$p(y=c|x,\theta)\propto \exp(\delta_c)$,其中:
$\delta_c=-x^T\beta_c+\gamma_c,\beta_c=\hat\Sigma^{-1}\mu_c,\gamma_c=- \frac{1}{2}\mu_c^T \beta_c+\log \pi_c$(4.62)

然后可以并不需要求逆$D\times D$矩阵就能计算正交线性判别分析(RDA)的关键项$\beta_c$.
$\beta_c =\hat\Sigma^{-1}_{map}\mu_c = (V\tilde\Sigma V^Ts)^{-1}\mu_c =V\tilde\Sigma^{-1}V^T\mu_c=V\tilde\Sigma^{-1}\mu_{z,c}$(4.63)


### 4.2.7 对角线性判别分析(Diagonal LDA)

上文所述的是正交线性判别分析(RDA),有一种简单的替代方法,就是绑定协方差矩阵(covariance matrice),即线性判别分析(LDA)中$\Sigma_c=\Sigma$,然后对于每个类都是用一个对角协方差矩阵.这个模型就叫做对角线性判别分析模型(diagonal LDA model),等价于$\lambda =1$时候的正交线性判别分析(RDA).对应的判别函数如下所示(和等式4.33相对比一下):

$\delta _c(x)=\log p(x,y=c|\theta) =-\sum^D_{j=1}\frac{(x_j-\mu_{cj})^2}{2\sigma^2_j}+\log\pi_c$(4.64)

通常设置$\hat\mu_{cj}=\bar x_{cj},\hat\sigma^2_j=s^2_j$,这个$s^2_j$是特征j(跨类汇集)的汇集经验方差(pooled empirical variance).

$s^2_j=\frac{\sum^C_{c=1}\sum_{i:y_i=c}(x_{ij}-\bar x_{cj})^2}{N-C}$(4.65)

对于高维度数据,这个模型比LDA和RDA效果更好(Bickel and Levina 2004).


此处查看原书图 4.7




### 4.2.8 最近收缩质心分类器(Nearest shrunken centroids classiﬁer)*

对角线性判别分析(diagonal LDA)有一个弱点,就是要依赖所有特征.在高维度情况下,可能更需要一个只依赖部分子集特征的方法,可以提高准确性或者利于解释.比如可以使用筛选方法(screening method),基于互信息量(mutual information),如本书3.5.4所述.本节要说另外一种方法,即最近收缩质心分类器(nearest shrunken centroids classiﬁer, Hastie et al. 2009, p652).

基本思想是在稀疏先验(sparsity-promoting/Laplace prior)情况下对对角线性判别分析模型进行最大后验估计(MAP),参考本书13.3.更确切来说,用类独立特征均值(class-independent feature mean)$m_j$和类依赖偏移量(class-speciﬁc offset)$\Delta_{cj}$ 来定义类依赖特征均值(class-speciﬁc feature mean)$\mu_{cj}$。 则有:
$\mu_{cj}=m_j+\Delta_{cj}$(4.66)

接下来对$\Delta_{cj}$这一项设一个先验,使其为零,然后计算最大后验估计(MAP).对特征j,若有对于所有类别c都有$\Delta_{cj}=0$,则该特征在分类决策中则毫无作用,因为$\mu_{cj}$是与c独立的.这样这些不具有判别作用的特征就会被自动忽略掉.这个过程的细节可以参考 (Hastie et al. 2009, p652)和(Greenshtein and Park 2009).代码可以参考本书配套的PMTK3程序中的 shrunkenCentroidsFit.

基于(Hastie et al. 2009, p652)的内容举个例子.设要对一个基因表达数据集进行分类,其中有2308个基因,4各类别,63个训练样本,20个测试样本.使用对角LDA分类器在测试集当中有五次错误.而是用最近收缩质心分类器对一系列不同的$\lambda$值,在测试集中都没有错误,如图4.7所示.更重要的是这个模型是稀疏的,所以更容易解读.图4.8所示的非惩罚估计(unpenalized estimate),灰色对应差值(difference)$d_{cj}$,蓝色的是收缩估计(shrunken estimates)$\Delta_{cj}$.(这些估计的计算利用了通过交叉验证估计得到的$\lambda$值.)在原始的2308个基因中,只有39个用在了分类当中.

接下来考虑个更难的问题,有16,603个基因,来自144个病人的训练集,54个病人的测试集,有14种不同类型的癌症(Ramaswamy et al. 2001).Hastie 等(Hastie et al. 2009, p656) 称最近收缩质心分类器用了6520个基因,在测试集上有17次错误,而正交判别分析(RDA,本书4.3.6)用了全部的16,603个基因,在测试集上有12次错误.本书配套的PMTK3程序当中的函数cancerHighDimClassifDemo可以再现这些数字.


此处查看原书图 4.8

## 4.3 联合正态分布的推论(Inference in jointly Gaussian distributions)

给定联合分布$p(x_1,x_2)$,边界分布(marginal)$p(x_1)$和条件分布$p(x_1|x_2)$是有用的.下面就说一下如何去计算,并且给出一些应用举例.这些运算在最不理想的情况下大概需要$O(D^3)$的时间.本书的20.4.3会给出一些更快的方法.

### 4.3.1 结果声明

##### 定理 4.3.1 

多元正态分布(MVN)的边界和条件分布.设$x=(x_1,x_2)$是联合正态分布,其参数如下:
$$\mu=\begin{pmatrix}
        \mu_1\\
        \mu_2
        \end{pmatrix} ,
\Sigma=\begin{pmatrix}
        \Sigma_{11}&\Sigma_{12}\\
        \Sigma_{21}&\Sigma_{22}
        \end{pmatrix},
\Lambda =\Sigma^{-1}=\begin{pmatrix}
        \Lambda _{11}&\Lambda _{12}\\
        \Lambda _{21}&\Lambda _{22}
        \end{pmatrix}
\text{  (4.67)}
$$

则边缘分布为:
$$
\begin{aligned}
p(x_1)&=N(x_1|\mu_1,\Sigma_{11})\\
p(x_2)&=N(x_2|\mu_2,\Sigma_{22})
\end{aligned} 
$$(4.68)

后验条件分布则为(重要公式):
$$
\begin{aligned}
p(x_1|x_2)&=N(x_1|\mu_{1|2},\Sigma_{1|2})\\
\mu_{1|2}&=\mu_1+\Sigma_{12}\Sigma^{-1}_{1|2}(x_2-\mu_2)\\
&=\mu_1-\Lambda _{12}\Lambda ^{-1}_{1|2}(x_2-\mu_2)\\
&= \Sigma_{1|2}(\Lambda _{11}\mu_1-\Lambda _{12}(x_2-\mu_2))\\
\Sigma_{1|2}&=\Sigma_{11}-\Sigma_{12}\Sigma^{-1}_{22}\Sigma_{21}=\Lambda ^{-1}_{11}
\end{aligned} 
$$(4.69)

上面这个公式很重要,证明过程参考本书4.3.4.

可见边缘和条件分布本身也都是正态分布.对于边缘分布,只需要提取出与$x_1$或者$x_2$对应的行和列.条件分布就要复杂点了.不过也不是特别复杂,条件均值(conditional mean)正好是$x_2$的一个线性函数,而条件协方差(conditional covariance)则是一个独立于$x_2$的常数矩阵(constant matrix).给出了后验均值(posterior mean)的三种不同的等价表达形式,后验协方差(posterior covariance)的两种不同的等价表达方式,每个表达式都在不同情境下有各自的作用.

### 4.3.2 举例

接下来就在实际应用中进行举例,可以让上面的方程更直观也好理解.


#### 4.3.2.1 二维正态分布的边缘和条件分布

假设以一个二维正态分布为例,其协方差矩阵为:
$$
\Sigma =\begin{pmatrix} \sigma_1^2 & \rho\sigma_1\sigma_2   \\
\rho\sigma_1\sigma_2 & \sigma_2^2
\end{pmatrix}
$$(4.70)

边缘分布$p(x_1)$则是一个一维正态分布,将联合分布投影到$x_1$这条线上即可得到:

$p(x_1)=N(x_1|\mu_1,\sigma_1^2)$(4.71)


此处查看原书图 4.9


假如观测$X_2=x_2$,则可以通过使用$X_2=x_2$这条线来对联合分布进行"切片(slicing)"得到条件分布$p(x_1|x_2)$,如图4.9所示:
$p(x_1|x_2)= N(x_1|\mu_1+ \frac{\rho\sigma_1\sigma_2}{\sigma_2^2}(x_2-\mu_2),\sigma_1^2-\frac{(\rho\sigma_1\sigma_2 )^2}{\sigma_2^2})$(4.72)

若$\sigma_1=\sigma_2=\sigma$,则有:
$p(x_1|x_2)=N(x_1|\mu_1+\rho(x_2-\mu_2),\sigma^2(1-\rho^2))$(4.73)

图4.9所示的为$\rho=0.8,\sigma_1=\sigma_2=1,\mu=0,x_2=1$.可见$\mathrm{E}[x_1|x_2=1]=0.8$,这很好理解,因为$\rho=0.8$就意味着如果$x_2$在其均值基础上加1,那么$x_2$则增加0.8.另外还可以发现$var[x_1|x_2=1]=1-0.8^2=0.36$.这也好理解,由于通过观测$x_2$而对$x_1$有了非直接的了解,所以对$x_1$的不确定性就降低了.如果$\rho=1$,就得到了$p(x_1|x_2)=N(x_1|\mu_1,\sigma_1^2)$,因为如果二者不相关也就是互相独立的话,$x_2$就不可能承载关于$x_1$的任何信息了.

#### 4.3.2.2 无噪音数据插值(Interpolating noise-free data)

若我们要估计一个一维函数,定义在闭区间[0,T]上,对于N次观测的点$t_i$即为$y_i=f(t_i)$.暂时先假设数据没有噪音(noise-free),对其进行插值(interpolate),即拟合一个完全通过数据的函数.(对于有噪音的数据,参考本书4.4.2.3.)那么问题来了:在观测数据点之间间隔的地方,这个函数该是什么样的呢?通常都假设这个函数是光滑的.在本书第15章,会讲如何对函数进行先验编码,以及如何使用观测值对先验进行更新来得到对函数的后验估计.不过本章的内容要简单很多,直接对一维输入上定义的函数进行最大后验估计(MAP),参考了 (Calvetti and Somersalo 2007, p135)的介绍.

先将这个问题离散化(discretizing).首先咱们将这个函数的定义域(支撑,support,我就是要说定义域这种很平民化的词你能怎样?)分割成D个等大子区间(equal subintervals).然后定义:
$x_j=f(s_j),s_j=jh,h=\frac{T}{D},1\le j\le D$(4.74)

此处查看原书图 4.10


光滑先验的编码可以通过下面的方式实现:假设$x_j$是邻近两项$x_{j-1},x_{j+1}$的均值,再加上正态分布的噪音项:

$x_j=\frac{1}{2}(x_{j-1}+x_{j+1})+\epsilon_j ,2\le j\le D-2$(4.75)

上式中的$\epsilon \sim  N(0, (1/\lambda)I)$.精度项(precision term)$\lambda$控制了函数波动幅度:大的$\lambda$表示我们认为函数非常光滑,而小的$\lambda$则表示这个函数可能"拐来拐去的(wiggly)".用向量形式可以将上面的等式写成如下所示:
$Lx=\epsilon$(4.76)
上式中的L是一个$(D − 2) \times D$的二阶有限差分矩阵(second order ﬁnite difference matrix):
$$
L=\frac{1}{2}\begin{pmatrix} -1&2&-1&&&\\
&-1&2&-1&&\\
&&...&&&\\
&&&-1&2&-1\\
\end{pmatrix}
$$(4.77)

对应的先验形式如下:
$p(x)=N(x|0,(\lambda^2L^TL)^{-1})\propto \exp(-\frac{\lambda^2}{2}||Lx||^2_2)$(4.78)


以后就假设已经用$\lambda$对L进行过缩放了,所以就会忽略掉$\lambda$项,就只将精度矩阵(precision matrix)写成$\Lambda =L^TL$.

这里要注意,虽然x是D维的,但是精度矩阵$\Lambda$实际上的秩只是D-2.所以这是一个不适当先验(improper prior),也称作内在高斯随机场(intrinsic Gaussian random ﬁeld)(更多相关信息参考本书19.4.4).
不过只要观测超过2个数据点,即$N\ge2$,这个先验就适用了. 

接下来设$x_2$是N个对函数的无噪音观测，而$x_1$是$D-N$个函数值.不考虑泛化损失,先假设未知变量和已知变量分别被排序.然后就可以对L矩阵进行如下所示的分割:
$L=[L_1,L_2],L_1\in R^{(D-2)\times(D-N)},L_2\in R^{(D-2)\times(N)}$(4.79)
然后也可以对联合分布的精度矩阵进行分割:
$$
\Lambda =L^TL=
\begin{pmatrix}
\Lambda _{11}&\Lambda _{12}\\ 
\Lambda _{21}&\Lambda _{22}
\end{pmatrix}=
\begin{pmatrix}
L_1^TL_1&L_1^TL_2\\ 
L_2^TL_1&L_2^TL_2
\end{pmatrix}
$$(4.80)

利用等式4.69,就可以写出条件分布:
$$
\begin{aligned}
p(x_1|x_2)&=N(\mu_{1|2},\Sigma_{1|2}) &\text{(4.81)}\\
\mu_{1|2}&= -\Lambda ^{-1}_{11}\Lambda _{12}x_2=-L_1^TL_2x_2 &\text{(4.82)}\\
\Sigma_{1|2} &= \Lambda ^{-1}_{11}&\text{(4.83)}\\
\end{aligned}
$$

解下面的线性方程组就可以计算出均值:
$L_1\mu_{1|2}=-L_2x_2$(4.84)

$L_1$是三角形矩阵,所以这解起来很容易.图4.10所示为这些等式的图像.从图中可见后验均值$\mu_{1|2}$等于特定各点的观测数据,而中间位置也都进行了光滑插值.
图中灰色的部分是95%的逐点边界置信区间(pointwise marginal credibility intervals),$\mu_j\pm 2\sqrt{\Sigma_{1|2,jj}}$.观察这部分会发现,远离数据点则方差增大,降低先验精度$\lambda$也会导致方差的增大.不过有趣的是$\lambda$并不会影响后验均值,因为在乘以$\Lambda _{11}$和$\Lambda _{12}$的时候消掉了.与之形成对比的是本书4.4.2.3的有噪音数据,那时候咱们就能发现先验精度会影响后验均值估计的光滑程度了.
边界置信区间并没有捕获到邻近位置上的相关性.对此可以从后验中推出完整的函数,也就是向量x,然后绘制函数图像.如图4.10中的细线所示.这就想个办法后验均值本身那么光滑了.这是因为先验只是处理了一阶差分(prior only penalizes ﬁrst-order differences).更多相关细节参考本书4.4.2.3.

#### 4.3.2.3 数据插补(Data imputation)

假设一个设计矩阵(design matrix)中缺失了某些值(entries).如果各列(columns)相关,可以用观察到的值对缺失值进行预测.如图4.11所示.从一个20维的正态分布中取样若干数据,然后故意在每行(row)隐藏掉一般的数据.接下来使用存留数据对缺失数据进行推测,使用真实(生成)模型(true (generating) model).具体来说,对于每一行i,都计算$p(x_{h_i}|x_{v_i} ,\theta)$,其中的$h_i$和$v_i$分别是 i条件下隐藏和可见值的索引值(indices).从这里就能计算出每个缺失值的边缘分布$p(x_{h_{ij}}|x_{v_i} ,\theta)$.然后对这个分布的均值$\hat x_{ij}=\mathrm{E}[x_j|x_{v_i},\theta]$进行投图;这就代表着对缺失值位置真实值的"最佳猜测",因为这使得期望平方误差(expected squared error)最小,更多细节参考本书5.7.如图4.11所示,这些估计和真实值还是很接近的.(当然了,如果$j\in v_i$则期望值就等于观测值,即$\hat x_{ij} = x_{ij}$.)

然后可以用$var[x_{h_{ij}}|x_{v_i} ,\theta]$来衡量对这个猜测的信心,不过图中没有展示出来.或者可以从$p(x_{h_{ij}}|x_{v_i} ,\theta)$中进行多次取样,这样就叫做多重插补(multiple imputation).

除了推算缺失值之外,我们可能还要计算表格中每个特定观测到的行(row)的似然率(likelihood),$p(x_{v_i}|\theta)$,这可以用等式4.68进行计算.这可以用于检测异常值(outliers)(也就是不太正常的观测结果,atypical observations).

此处查看原书图 4.11

### 4.3.3 信息形式(Information form)


设$x \sim  N(\mu,\Sigma)$.很明显$\mathrm{E}[x]=\mu$就是均指向量,而$cov[x]=\Sigma$就是协方差矩阵(covariance matrix).这些都叫做分布的矩参数(moment parameters).不过有时候可能使用规范参数(canonical parameters)或者自然参数(natural parameters)更有用,具体定义如下所示:
$\Lambda  \overset{\triangle}{=} \Sigma^{-1},\xi \overset{\triangle}{=}  \Sigma^{-1} \mu$(4.85)
还可以转换回矩参数:
$ \mu=\Lambda ^{-1}\xi,\Sigma =\Lambda ^{-1}$(4.86)
使用规范参数,可以将多元正态分布(MVN)写成信息形式(information form)(也就是写成指数组分布的形式(exponential family form),具体定义在本书9.2):
$N_c(x|\xi,\Lambda )=(2\pi)^{-D/2}|\Lambda |^{\frac{1}{2}} \exp[-\frac{1}{2}(x^T\Lambda  x+\xi^T\Lambda ^{-1}\xi-2x^T\xi)]$(4.87)

上式中使用了$N_c()$是为了和矩参数表达形式$N()$相区分.
边缘分布和条件分布公式也都可以推导出信息形式.为:
$p(x_2)=N_c(x_2|\xi_2-\Lambda _{21}\Lambda _{11}^{-1}\xi_1,\Lambda _{22}-\Lambda _{21}\Lambda _{11}^{-1}\Lambda _{12})$(4.88)
$p(x_1|x_2)=N_c(x_1|\xi_1-\Lambda _{12}x_2,\Lambda _{11})$(4.89)

通过上式可见比矩参数形式求边缘分布更容易,而信息形势下求条件分布更容易.
这种信息形式记法的另外一个好处是将两个正态分布相乘更简单了.如下所示:
$N_c(\xi_f,\lambda_f)N_c(\xi_g,\lambda_g)=N_c(\xi_f+\xi_g,\lambda_f+\lambda_g)$(4.90)
而在矩参数形式下,这相乘起来可就麻烦了:
$N(\mu_f,\sigma_f^2)N(\mu_g,\sigma_g^2)=N(\frac{\mu_f\sigma_g^2+\mu_g\sigma_f^2}{\sigma_f^2+\sigma_g^2},\frac{\sigma_f^2 \sigma_g^2}{\sigma_f^2+\sigma_g^2})$(4.91)

### 4.3.4 结论证明*

这一节是要证明定理4.3.1.害怕矩阵代数计算的读者可以直接跳过这部分内容.本节开始要先推到一些有用的结果,这些结论不仅在这节要用到,在本书其他地方也有用.然后在结尾部分就给出证明.

#### 4.3.4.1 使用Schur补(Schur complements)得到分区矩阵的逆矩阵(Inverse)

要想个办法对一个分区矩阵求逆矩阵.可以使用下面的结论.
#### 定理4.3.2
分区矩阵的逆矩阵.设有一个常规分区矩阵(general partitioned matrix):
$$M=\begin{pmatrix}E&F\\ G&H
\end{pmatrix}
$$(4.92)

假设其中的E和H都是可逆的,则有:
$$
\begin{aligned}
M^{-1}&= \begin{pmatrix}(M/H)^{-1}&-(M/H)^{-1}FH^{-1}\\
-H^{-1}G(M/H)^{-1}&H^{-1}+H^{-1}G(M/H)^{-1}FH^{-1}
\end{pmatrix}
&\text{(4.93)}\\
&= \begin{pmatrix}E^{-1}+E^{-1}F(M/E)^{-1}GE^{-1} & -E^{-1}F(M/E)^{-1}\\
-(M/E)^{-1}GE^{-1}& (M/E)^{-1}
\end{pmatrix}
&\text{(4.94)}
\end{aligned}
$$
其中:
$M/H\overset{\triangle}{=} E-FH^{-1}G$(4.95)
$M/E\overset{\triangle}{=} H-GE^{-1}F$(4.96)

我们就说$M/H$是$M wrt H$的Schur补(Schur complement).等式4.93就叫做分区求逆公式(partitioned inverse formula).


#### 证明

如果把矩阵M的对角(diagonalize)去掉(block),就更好求逆矩阵了.可以用如下方式预处理,矩阵M左侧乘以一个三角矩阵来得使矩阵M的右上角部分为零:
$$
\begin{pmatrix}
I&-FH^{-1}\\
0&I
\end{pmatrix}
\begin{pmatrix}
E&F\\
G&H
\end{pmatrix}=
\begin{pmatrix}
E-FH^{-1}&0\\
G&H
\end{pmatrix}
$$(4.97)

用如下方式预处理,矩阵M右侧乘以一个三角矩阵来得使矩阵左下角部分为零:
$$
\begin{pmatrix}
E-FH^{-1}&0\\
G&H
\end{pmatrix}
\begin{pmatrix}
I&0\\
-H^{-1} G&I 
\end{pmatrix}=\begin{pmatrix}
E-FH^{-1}&0\\
0&H
\end{pmatrix}
$$(4.98)

把上面两步结合起来就得到了:
$$
\begin{pmatrix}
I&-FH^{-1}\\
0&I
\end{pmatrix}
\begin{pmatrix}
E&F\\
G&H
\end{pmatrix}
\begin{pmatrix}
I&0\\
-H^{-1} G&I 
\end{pmatrix}=\begin{pmatrix}
E-FH^{-1}&0\\
0&H
\end{pmatrix}
$$(4.99)
上面的四个矩阵从左到右分别为X,M,Z,W,对这几个矩阵同时求逆矩阵就得到了:
$Z^{-1}M^{-1}X^{-1}=W^{-1}$(4.100)

然后就能推出:
$M^{-1}=ZW^{-1}X$(4.101)

用定义拆解出来就得到了:
$$
\begin{aligned}
\begin{pmatrix} E&F\\G&H \end{pmatrix}^{-1}
&= \begin{pmatrix}I&0 \\-H^{-1}G&I 
\end{pmatrix}
\begin{pmatrix}(M/H)^{-1}&0 \\0&H^{-1} 
\end{pmatrix}
\begin{pmatrix}I&-FH^{-1} \\0&I 
\end{pmatrix}
&\text{(4.102)}\\
&= \begin{pmatrix}(M/H)^{-1}&0 \\-H^{-1}G(M/H)^{-1}&H^{-1} 
\end{pmatrix}
\begin{pmatrix}I&-FH^{-1} \\0&I 
\end{pmatrix}
&\text{(4.103)}\\
&= \begin{pmatrix}(M/H)^{-1}& -(M/H)^{-1}FH^{-1} \\-H^{-1}G(M/H)^{-1}&H^{-1} +H^{-1} G(M/H)^{-1}FH^{-1}
\end{pmatrix}
&\text{(4.104)}
\end{aligned}
$$

或者也可以把矩阵M分解成用E来表示,这样就有$M/E=(H-GE^{-1}F)$,就得到了:
$$
\begin{aligned}
\begin{pmatrix} E&F\\G&H \end{pmatrix}^{-1} 
= \begin{pmatrix}E^{-1}+E^{-1}F(</E)^{-1}GE^{-1} & -E^{-1}F(M/E)^{-1} \\-H^{-1}-(M/E)^{-1}GE^{-1}&(M/E)^{-1}
\end{pmatrix}
\end{aligned}
$$(4.105)

证明完毕

#### 4.3.4.2 矩阵求逆引理(the matrix inversion lemma)

接下来要利用上面的结果推出一些有用的推论.

#### 推论4.3.1 矩阵求逆引理(matrix inversion lemma)
设有一个常规分区矩阵(general partitioned matrix)$M=\begin{pmatrix} E&F \\  G&H \end{pmatrix}$,假设E和H都可逆.则有:
$(E-FH^{-1}G)^{-1}= E^{-1}+ E^{-1}F(H-GE ^{-1}F )^{-1}GE^{-1}$(4.106)
$(E-FH^{-1}G)^{-1}FH^{-1}=E^{-1}F(H-GE^{-1}F)^{-1}$(4.107)
$|E-FH^{-1}G|=|H-GE^{-1}F||H^{-1}||E|$(4.108)
上式中前两个方程就叫做矩阵求逆引理(matrix inversion lemma)或者叫做Sherman Morrison-Woodbury 公式(Sherman Morrison-Woodbury formula).第三个等式叫做矩阵行列式引理(matrix determinant lemma).在机器学习和统计学中上面这些公式的典型用法如下所示.设$E=\Sigma$是一个$N\times N$的对角矩阵,设$F=G^T= X$规模为$N\times D$,其中的N远大于D,即$N\gg D$,设$H^{-1}=-I$.则有:
$(\Sigma+XX^T )^{-1} =\Sigma^{-1}-\Sigma^{-1}X(I+X^T\Sigma^{-1}X)^{-1}X^T\Sigma^{-1} $(4.109)

等号左侧的计算需要$O(N^ 3)$时间,等号右侧的计算需要$O(D^ 3)$时间.

另外一种应用涉及到了对逆矩阵的一阶更新(rank one update)进行计算.设$H=-1$是一个标量(scalar),$F=u$是一个列向量(column vector),而$G=v^T$是一个行向量(row vector).然后则有:

$$
\begin{aligned}
(E+uv^T)^{-1}&= E^{-1}+E^{-1}u(-1-v^TE^{-1}u)v^TE^{-1} &\text{(4.110)}\\
&= E^{-1}- \frac{E^{-1}uv^TE^{-1}}{1+v^TE^{-1}u}&\text{(4.111)}\\
\end{aligned}
$$

在对设计矩阵逐渐添加数据向量和对充分统计量进行更新的时候,可以用上上面的式子.(移除一个数据向量的方程与之类似,大家自己推导一下.)

#### 证明

要证明等式4.106,只需要把等式4.93的左上部分和4.94等同起来(equate).为了证明等式4.107,则将等式4.93的右上部分和4.94等同起来(equate).等式4.108的证明留作练习.


#### 4.3.4.3 高斯条件公式(Gaussian conditioning formulas)的证明

接下来回到主线,也就是推导等式4.69.首先把联合概率分布$p(x_1,x_2)$因式分解成$p(x_2)p(x_1|x_2)$:
$$
E=\exp\{-\frac{1}{2}{\begin{pmatrix}  x_1-\mu_1\\x_2-\mu_2 \end{pmatrix}}^T{\begin{pmatrix} \Sigma_{11}&\Sigma_{12}\\ \Sigma_{21}&\Sigma_{22}\end{pmatrix}}^{-1}{\begin{pmatrix}  x_1-\mu_1\\x_2-\mu_2 \end{pmatrix}}\}
$$(4.112)
利用等式4.102,则有:


$$
\begin{aligned}
E&=  \exp   \{-\frac{1}{2}{\begin{pmatrix}  x_1-\mu_1\\x_2-\mu_2 \end{pmatrix}}^T{\begin{pmatrix}I&0\\ -\Sigma_{22}^{-1}\Sigma_{21}&I\end{pmatrix}}^{-1}{\begin{pmatrix}  (\Sigma/\Sigma_{22})^{-1}&0\\0&\Sigma_{22}^{-1} \end{pmatrix}}        &\text{(4.113)}\\
&\times   {\begin{pmatrix}  I & -\Sigma_{12}\Sigma_{22}^{-1}\\0&I\end{pmatrix}}{\begin{pmatrix}  x_1-\mu_1\\x_2-\mu_2 \end{pmatrix}}\}             &\text{(4.114)}\\
&=    \exp\{     -\frac{1}{2}(x_1-\mu_1-\Sigma_{12}\Sigma_{22}^{-1}(x_2-\mu_2))^T(\Sigma/\Sigma_{22})^{-1})     &\text{(4.115)}\\
& (x_1-\mu_1-\Sigma/\Sigma_{22})^{-1}(x_2-\mu_2)) \} \times \exp \{ -\frac{1}{2}(x_2-\mu_2)^T\Sigma_{-1}(x_2-\mu_2) \}           &\text{(4.116)}\\
\end{aligned}
$$

这就成了下面这种形式:
$\exp(x_1 , x_2 \text{的二次型(quadratic form)} ) \times \exp(x_2  \text{的二次型})$(4.117)

因此就可以成功地将联合分布拆解开:
$$
\begin{aligned}
p(x_1,x_2)&=   p(x_1|x_2) p(x_2)     &\text{(4.118)}\\
&=   N(x_1|\mu_{1|2},\Sigma_{1|2})N(x_2|\mu_2,\Sigma_{22})      &\text{(4.119)}\\
\end{aligned}
$$
通过上面的等式也可以得到条件概率分布的参数:
$$
\begin{aligned}
\mu_{1|2}&=    \mu_1+\Sigma_{12}\Sigma_{22}^{-1}(x_2-\mu_2)     &\text{(4.120)}\\
\Sigma_{1|2}&=   \Sigma/\Sigma_{22}=\Sigma_{11}-\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}      &\text{(4.121)}\\
\end{aligned}
$$

还可以根据$|M| = |M/H||H|$来检验归一化常数(normalization constants)是否正确:

$$
\begin{aligned}
(2\pi)^{(d_1+d_2)/2}|\Sigma|^{\frac{1}{2}} &=     (2\pi)^{(d_1+d_2)/2}(|\Sigma/\Sigma_{22}||\Sigma_{22}|)^{\frac{1}{2}}     &\text{(4.122)}\\
&=   (2\pi)^{d_1/2}|\Sigma/\Sigma_{22}|^{\frac{1}{2}}(2\pi)^{d_2/2}|\Sigma_{22}|^{\frac{1}{2}}        &\text{(4.123)}\\
\end{aligned}
$$

上式中的$d_1=\dim (x_1)$,$d_2=\dim (x_2)$.
对等式4.69的其他形式证明留作练习了.

## 4.4 线性高斯系统(Linear Gaussian systems)

假如我们有两个变量x和y.然后设$x\in R^{D_x}$是隐藏变量(hidden variable),而$y\in R^{D_y}$是对x的有噪音观察(noisy observation).假设有下面的先验和似然率(重要公式): 
$$
\begin{aligned}
p(x)&= N(x|\mu_x,\Sigma_x)   \\
p(y|x)&= N(y|Ax+b,\Sigma_y)   \\
\end{aligned}
$$(4.124)
上式中的A是一个$D_y \times D_x$的矩阵.这就是一个线性高斯系统(linear Gaussian system).可以表示为$x\rightarrow y$,意思也就是x生成(generates)了y.本节会讲如何去"逆转箭头方向(invert the arrow)",也就是根据y来推测x.首先是给出结论,然后举几个例子,最后给出推导结论的过程.后面的章节还能看到对这些结论的更多应用.

### 4.4.1 结论表述

#### 定理4.4.1
线性高斯系统的贝叶斯规则.
给定一个线性高斯系统,如等式4.124所述,则后验$p(x|y)$为(重要公式):
$$
\begin{aligned}
p(x|y)&= N(x|\mu_{x|y},\Sigma_{x|y})   \\
\Sigma_{x|y}^{-1}&=\Sigma_x^{-1}+A^T\Sigma_y^{-1}A  \\
\mu_{x|y}&= \Sigma_{x|y}[A^T\Sigma_y^{-1}(y-b)+\Sigma_x^{-1}\mu_x] \\
\end{aligned}
$$(4.125)

另外,归一化常数(normalization constant)$p(y)$为(重要公式):
$p(y)=N(y|A\mu_x+b,\Sigma_y+A\Sigma_x A^T)$(4.126)
证明过程参考本章4.4.3

### 4.4.2 样例
本节举几个对上述结论进行应用的例子.

#### 4.4.2.1 从有噪音测量(noisy measurements)中推测未知标量(unknown scalar)

假如我们对某个隐藏量(underlying quantity)x进行N此有噪音测量$y_i$;然后假设测量噪音有固定的精确率(precision)$\lambda_y=\frac{1}{\sigma^2}$,则似然率(likelihood)为:

$p(y_i|x)=N(y_i|x,\lambda_y^{-1})$(4.127)

然后对未知源(unknown source)的值使用一个高斯先验:

$p(x)=N(x|\mu_0,\lambda_0^{-1})$(4.128)

我们需要计算的是$p(x|y_1,...,y_N,\sigma^2)$.可以把这个改写成一种形式,以便于使用对高斯分布的贝叶斯规则,可以通过定义$y=(y_1,...,y_N),A= a^T_N,\Sigma_y^{-1}=diag (\lambda_yI)$,其中的A的意思是一个$1\times N$的由1构成的行向量(row vector).则有:

$$\begin{aligned}
p(x|y)&=N(x|\mu_N,\lambda_N^{-1})&\text{(4.129)}\\
\lambda_N&=\lambda_0+N\lambda_y&\text{(4.130)}\\
\mu_N&=\frac{N\lambda_y\bar y+\lambda_0\mu_0}{\lambda_N}=\frac{N\lambda_y}{N\lambda_y+\lambda_0}\bar y +\frac{\lambda_0}{N\lambda_y+\lambda_0}\mu_0&\text{(4.131)}\\
\end{aligned}
$$

这几个等式很直观了:后验精度(posterior precision)$\lambda_N$就正好是先验精度(prior precision)$\lambda_0$和N个单位的测量精度(measurement precision)$\lambda_y$的和.另外后验均值(posterior mean)$\mu_N$也就是最大似然估计(MLE)$\bar y$和先验均值(prior mean)$\mu_0$的凸组合(convex combination).很明显,这就表明了后验均值是在最大似然估计(MLE)和先验(prior)之间的妥协折中(compromise).如果先验相对于信号强度来说比较弱(即$\lambda_0$相对于$\lambda_y$来说较小),就赋予最大似然估计(MLE)更多权重.如果先验相对信号强度更强(即$\lambda_0$相对于$\lambda_y$来说更大),就给先验(prior)更高权重.这如图4.12所示,这和图3.6当中的$\beta$二项模型(beta-binomial model)的模拟结果(analogous results)很相似.

这里要注意后验均值写成了$N\lambda_y \bar y$的形式,因此具有测量N次,每次精度$\lambda_y$就相当于进行一次测量得到值$\bar y$而精度为$N\lambda_y$.


此处查看原书图 4.12

我们可以把上面的结果写成后验方差(posterior variance)的形式,而不用后验精度(posterior precision),如下所示:
$$
\begin{aligned}
p(x|D,\sigma^2)&= N(x|\mu_N,\Gamma _N^2 &\text{(4.132)}\\
\Gamma _N^2&=\frac{1}{\frac{N}{\sigma^2}+\frac{1}{\Gamma _0^2} } =\frac{\sigma^2\Gamma _0^2}{N\Gamma _0^2+\sigma^2}&\text{(4.133)}\\
\mu_N&= \Gamma _N^2 (\frac{\mu_0}{\Gamma _0^2}+\frac{N\bar y}{\sigma^2}) =\frac{\sigma^2}{N\Gamma _0^2+\sigma^2}\mu_0+\frac{N\Gamma _0^2}{N\Gamma _0^2+\sigma^2}\bar y&\text{(4.134)}\\
\end{aligned}
$$

上式中的$\Gamma _0^2=1/\lambda_0$是先验方差(prior variance),而$\Gamma _N^2 =1/\lambda_N$是后验方差(posterior variance).

我们也可以通过每次观测后更新来逐渐计算后验.如果$N=1$,在进行一次单独观测后就可以重写后验,如下所示(下面定义了$ \Sigma_y =\sigma^2,\Sigma_0= \Gamma _0^2, \Sigma_1=\Gamma _1^2$分别是似然函数/先验/后验的方差):

$$
\begin{aligned}
p(x|y)&= N(x|\mu_1,\Sigma_1) &\text{(4.135)}\\
\Sigma_1&= (\frac{1}{\Sigma_0}+\frac{1}{\Sigma_y})^{-1} = \frac{\Sigma_y\Sigma_0}{\Sigma_0+\Sigma_y}&\text{(4.136)}\\
\mu_1&= \Sigma_1(\frac{\mu_0}{\Sigma_0}+\frac{y}{\Sigma_y})&\text{(4.137)}\\
\end{aligned}
$$

可以以下面三种不同形式来写出后验均值(posterior mean):
$$
\begin{aligned}
\mu_1 &=  \frac{\Sigma_y}{\Sigma_y+\Sigma_0}\mu_0+\frac{\Sigma_0}{\Sigma_y+\Sigma_0}y&\text{(4.138)}\\
&=\mu_0+(y-\mu_0)\frac{\Sigma_0}{\Sigma_y+\Sigma_0} &\text{(4.139)}\\
&=y-(y-\mu_0)\frac{\Sigma_y}{\Sigma_y+\Sigma_0} &\text{(4.140)}\\
\end{aligned}
$$

上面的三个等式中,第一个式子就是对先验和数据的凸组合(convex combination).第二个是将先验均值朝向数据进行调整.第三个是将数据朝向先验均值调整,这也叫做收缩过程(shrinkage).这三者都是等价的,都表达了在似然率和先验之间的权衡妥协.如果$\Sigma_0$相对于$\Sigma_Y$较小,对应的就是强先验(strong prior),收缩规模(amount of shrinkate)就很大,参考图4.12(a),而如果反过来$\Sigma_0$相对于$\Sigma_Y$更大,对应的就是弱先验(weak prior)收缩规模就小了,参考图4.12(b).

另外一种对收缩规模定量的方法是用信噪比(signal-to-noise ratio,缩写为SNR),定义如下:
$SNR\overset{\triangle}{=} \frac{\mathrm{E}[X^2]}{\mathrm{E}[\epsilon^2]}= \frac{\Sigma_0+\mu_0^2}{\Sigma_y}$(4.141)
上式中的$x \sim  N(\mu_0,\Sigma_0)$是真是信号(true signal),而$y=x+\epsilon$是观测信号,而$\epsilon \sim  N(0,\Sigma_y)$就是噪音项.


#### 4.4.2.2 从有噪音测量(noisy measurements)中推测未知矢量(unknown vector)


接下来考虑一个N次向量值的观测$y_i \sim  N(x, \Sigma_y )$,有高斯先验$x \sim  N(\mu_0 ,\Sigma_0)$.设$A=I,b=0$,精度为$N\Sigma_y^{-1}$的有效观测设为$\bar y$,则有:
$$
\begin{aligned}
p(x|y_1,...,y_N)&= N(x|\mu_N,\Sigma_N)&\text{(4.142)}\\
\Sigma_N^{-1}&= \Sigma_0^{-1} +N\Sigma_y^{-1}&\text{(4.143)}\\
\mu_N&= \Sigma_N(\Sigma_y^{-1}(N\bar y)+\Sigma_0^{-1}\mu_0)  &\text{(4.144)}\\
\end{aligned}
$$



图4.13所示是一个二维情况下的样例.可以把x理解为一个物体在二维空间内的真实位置,但这个位置是未知的,可以想象成导弹或者飞机,然后$y_i$就是带噪音的观测,也就类似雷达上面的信号点.随着收到的信号点越来越多了,就更好去对信号源的位置进行定位了.具体参考本书18.31,其中讲述了对这个例子进行扩展,去追踪运动物体,使用著名的卡尔曼滤波算法(Kalman ﬁlter algorithm).

然后设想我们有多个测量设备,然后想要将他们结合起来;这也就是传感器融合(sensor fusion).如果我们进行了多次观测,每次都有不同的协方差(covariances)(对应的就是不同可靠程度的传感器),后验分布就应当是适当地对数据的加权平均.如图4.14所示.采用的是对x的无信息先验(uninformative prior),名为$p(x)=N(\mu_0,\Sigma_0)=N(0,10^{10}I_2)$.进行了两次有噪音的观测,分别为$y_1 \sim  N(x, \Sigma_{y,1} )$和$y_2 \sim  N(x, \Sigma_{y,2} )$.然后就可以计算$p(x|y_1,y_2)$.

在图4.14(a)中,设置了$\Sigma_{y,1} =\Sigma_{y,2} =0.01I_2$,所以两个传感器就都是可靠程度相同.这时候后验均值就是两次观测$y_1,y_2$的均值.在图4.14(b)中,设置的是$\Sigma_{y,1} =0.05I_2,\Sigma_{y,2} =0.01I_2$,这也就意味着第二个传感器比第一个更可靠.,这时候后验均值就距离$y_2$更近了.在图4.14(c)中,设置有:

$\Sigma_{y,1} =  0.01\begin{pmatrix} 10& 1\\1&1 \end{pmatrix}  , \Sigma_{y,2} = 0.01 \begin{pmatrix}  1&1\\1&10 \end{pmatrix} $(4.145)

所以也就是说第一个传感器对于$y_2$成分(component)(竖着的方向)更可靠,而第二个传感器对于$y_1$成分(横着的方向)更可靠.这时候后验均值就使用了$y_1$的竖直元素和$y_2$的水平元素.

此处查看原书图 4.13

此处查看原书图 4.14


要注意,这个方法关键在于对每个传感器的不确定性的建模;没有考虑权重就计算均值会得到错误结果.不过这是已经假设了每个传感器的精度都已知了.如果不知道每个传感器的精确率,也还是要对$\Sigma_1,\Sigma_2$的精确率进行建模.更多细节参考本书4.6.4.


#### 4.4.2.3 插入噪音数据

再回头看看本书4.3.2.2当中的例子.这次咱们不再假设观测是无噪音的.而是假设进行了N次的有噪音观测$y_i$,为了通用,就假设对应了$x_1,...,x_N$.可以用一个线性高斯系统来对此进行建模:
$y=Ax+\epsilon$(4.146)
上式中的$\epsilon\sim  N(0, \Sigma_ y ), \Sigma_ y= \sigma^2 I$,$\sigma^2$就是观测噪音,而A是一个$N\times D$的投影矩阵(projection matrix),对观测到的元素进行了筛选.例如,如果N =2,D =4,则有:
$A=\begin{pmatrix} 1&0&0&0\\0&1&0&0 \end{pmatrix}$(4.147)

还是用同样的不适当先验(improper prior)$\Sigma_x=(L^TL)^{-1}$,可以很容易计算得出后验均值和方差.如图4.15所示,对后验均值/后验方差以及一些后验样本进行投图.然后可以看出先验精确率$\lambda$同时影响着后验的均值和方差.对于一个强先验(大的$\lambda$),这时候的估计就很光滑,而不确定性就很低.但对于弱先验(小的$\lambda$),估计结果就扭来扭曲,远离数据部分的估计结果的不确定性就高了.

解下面的优化问题就能计算出后验均值:
$\min_x\frac{1}{2\sigma^2}\sum^N_{i=1}(x_i-y_i)^2+\frac{\lambda}{2}\sum^D_{j=1}[(x_j-x_{j-1})^2+(x_j-x_{j+1})^2]$(4.148)

上式中定义了$x_0=x_1,x_{D+1}=x_D$来简化记号.这实际上是对下面问题的离散近似:
$\min_f\frac{1}{2\sigma^2}\in(f(t)-y(t))^2dt+\frac{\lambda}{2}\int[f'(t)]^dt$(4.149)

其中的$f'(t)$是f的一阶导数(first derivative).第一项用于拟合数据,第二项用于抑制函数避免过于扭曲.这是Tikhonov正则化(Tikhonov regularization)的一个例子,这是一种很流行的函数数据分析方法.参见本书第十五章可以看到更高级的方法,保证了更高阶的光滑性(也就是得到的结果不会看上去有很多锯齿).

此处查看原书图 4.15

### 4.4.3 结论证明*

接下来推导一下等式4.125.基本思想是推导联合分布$p(x,y)=p(x)p(y|x)$,然后使用本书4.3.1的结论来计算$p(x|y)$.

更详细来说,按照下面的步骤进行.首先是得到联合分布函数的对数形式,如下所示(取对数是去除了不相关的常数项):

$\log p(x,y)=-\frac{1}{2}(x-\mu_x)^T\Sigma_x^{-1}(x-\mu_x)-\frac{1}{2}(y-Ax-b)^T\Sigma_y^{-1}(y-Ax-b)$(4.150)

很明显这就是一个联合高斯分布,因为是一个二次型的指数.

扩展有x和y的二次项,然后线性项和常数项全部忽略掉,就得到了:

$$
\begin{aligned}
Q&=  -\frac{1}{2}x^T\Sigma_x^{-1}x - \frac{1}{2}y^T\Sigma_y^{-1}y-\frac{1}{2}(Ax)^T\Sigma_t^{-1}(Ax)+y^T\Sigma_y^{-1}Ax  &\text{(4.151)}\\
&= \frac{1}{2}\begin{pmatrix} x\\y \end{pmatrix}^T  \begin{pmatrix}  \Sigma_x^{-1}+A^T\Sigma_y^{-1}A& -A^T\Sigma_y^{-1}\\-\Sigma_y^{-1}A&\Sigma_y^{-1}\end{pmatrix}  \begin{pmatrix} x\\y \end{pmatrix}   &\text{(4.152)}\\
&= \frac{1}{2}\begin{pmatrix}x\\y  \end{pmatrix} ^T\Sigma^{-1} \begin{pmatrix} x\\y \end{pmatrix}     &\text{(4.153)}\\
\end{aligned}
$$


联合分布的精度矩阵则定义为:
$\Sigma^{-1}=\begin{pmatrix}  \Sigma_x^{-1}+A^T\Sigma_y^{-1}A& -A^T\Sigma_y^{-1}\\-\Sigma_y^{-1}A&\Sigma_y^{-1}\end{pmatrix}\overset{\triangle}{=} \Lambda =\begin{pmatrix}   \Lambda _{xx} & \Lambda _{xy} \\\Lambda _{yx} &\Lambda _{yy}     \end{pmatrix}$(4.154)


$$
\begin{aligned}
p(x|y)&=  N(\mu_{x|y},\Sigma_{x|y})  &\text{(4.155)}\\
\Sigma_{x|y}&= \Lambda ^{-1}_{xx}= (\Sigma_x^{-1}+A^T\Sigma_y^{-1}A)^{-1}    &\text{(4.156)}\\
\mu_{x|y}&= \Sigma_{x|y}(\Lambda _{xx}\mu_x-\Lambda _{xy}(y-\mu_y))    &\text{(4.157)}\\
&=  \Sigma_{x|y}(\Sigma_x^{-1}\mu+A^T\Sigma_y^{-1}(y-b))   &\text{(4.158)}\\
\end{aligned}
$$


## 4.5 题外话(Digression):威沙特分布(Wishart distribution)

威沙特分布(Wishart distribution)是将$\gamma$分布(Gamma distrustion)对正定矩阵(positive deﬁnite matrices)的推广.(Press 2005, p107) 称:按照重要性和有用性的顺序来排列,在多元统计中,威沙特分布仅次于正态分布.通常用这个模型来对协方差矩阵$\Sigma$或者逆矩阵$\Lambda =\Sigma^{-1}$的不确定性来进行建模.



Wishart 分布的概率密度函数定义如下:
$Wi(\Lambda |S,v)=\frac{1}{Z_{Wi}}|\Lambda |^{(v-D-1)/2}\exp(-\frac{1}{2}tr(\Lambda  S^{-1})$(4.159)
上式中的v也叫做自由度(degrees of freedom),S就是缩放矩阵(scale matrix).稍后会对这些参数的含义给出更多讲解.
这个分布的归一化常数(normalization constant)(需要在整个对称的概率密度矩阵上进行积分)为下面的表达式:
$Z_{Wi}=2^{vD/2} \Gamma_D(v/2)|S|^{v/2} $(4.160)
上式中的$\Gamma _D$是多元$\gamma$函数(multivariate gamma function):

$\Gamma _D(x)= \pi^{D(D-1)/4 }\prod^D_{i=1}\Gamma(x+(1-i)/2)$(4.161)
因此$\Gamma_1(a)=\Gamma(a)$,以及:
$\Gamma_D(v_0/2)=\prod^D_{i=1}\Gamma(\frac{v_0+1-i}{2})$(4.162)

只有当$v>D-1$的时候才存在归一化常数,因此概率密度函数也仅在此时有意义.

Wishart分布和正态分布之间有一定联系.具体来说就是,设$x_i \sim  N(0,\Sigma)$为正态分布,那么散点矩阵(scatter matrix)$S=\sum^N_{i=1}x_ix_i^T$就有一个Wishart分布:$S \sim  Wi(\Sigma, 1)$.因此$\mathrm{E}[S]=N\Sigma$.另外可以得出分布$Wi(S,v)$的均值(mean)和众数(mode)为:

$mean=vS, mode=(v-D-1)S$(4.163)

其中众数(mode)仅当$v>D+1$的时候才存在.
如果D=1,那么Wishart就降回到了$\gamma$分布(Gamma distribution):
$Wi(\lambda|s^{-1},v)=Ga(\lambda|\frac{v}{2},\frac{s}{2})$(4.164)

### 4.5.1 逆威沙特分布(Inverse Wishart distribution)

在练习2.10中,如果$\lambda\sim  Ga(a, b)$则有$\frac{1}{\lambda}\sim  IG(a, b)$.类似地,如果有$\Sigma^{-1} \sim Wi(S, v)$,则有$\Sigma\sim  IW(S^{-1}, v+D+1)$,IW就是逆威沙特分布(inverse Wishart),是对逆$\gamma$分布(inverse Gamma)的多维推广.定义方式为:对于$v>D-1,S\succ 0$:

$$
\begin{aligned}
IW(\Sigma|S,v) &= \frac{1}{Z_{IW}}|\Sigma|^{-(v+D+1)/2}\exp(-\frac{1}{2}tr(S^{-1}\Sigma^{-1}))
&\text{(4.165)}\\
Z_{IW}&= |S|^{-v/2}2^{vD/2}\Gamma  _D(v/2)  &\text{(4.166)}
\end{aligned}$$

很显然,这个分布有如下的性质:

$mean =\frac{S^{-1}}{v-D-1} , mode=\frac{S^{-1}}{v+D+1}$(4.167)

如果D=1,这个分布就降到了拟$\gamma$分布了:

$IW(\sigma^2|S^{-1},v)=IG(\sigma^2||v/2,S/2)$(4.168)


此处查看原书图 4.16


### 4.5.2 威沙特分布可视化*

威沙特分布(Wishart)是矩阵的分布,所以很难画出密度函数.不过在二维情况下,可以对其进行取样,使用取样结果矩阵的特征向量来定义一个椭圆,具体如本书4.1.2所述.图4.16是一些样例.

对更高维度的矩阵,就可以投影威沙特分布的边缘分布(marginals).威沙特分布的矩阵的对角元素服从$\gamma$分布,所以也容易投影出来.非对角元素的分布通常就比较难以解出来了,不过可以从分钟抽样矩阵,然后根据经验计算抽样得到的矩阵的分布.可以把抽样得到的矩阵转各自转换成一个相关矩阵(correlation matrix)然后进行蒙特卡洛估计(参考本书2.7),来得到相关系数期望:

$\mathrm{E}[R_{ij}]\approx \frac{1}{S}\sum^S_{s=1}R(\Sigma^s)_{ij}$(4.169)

其中的$\Sigma^{(s)} \sim Wi(\Sigma,v)$和$R(\Sigma)$就把矩阵$\Sigma$转换成了一个相关矩阵:
$R_{ij}=\frac{\Sigma_{ij}}{ \sqrt{\Sigma_{ii}\Sigma_{jj}}   }$(4.170)

可以用核密度估计(kernel density estimation,参考本书14.7.2)来对单变量密度$\mathrm{E}[R_{ij}]$生成一个光滑近似来投图.图4.16是一些例子.

## 4.6 多元正态分布(MVN)的参数推测

之前已经讲的是在已知参数$\theta=(\mu,\Sigma)$的时候对一个高斯分布(正态分布)的推测.现在来讨论对这些参数本身的推测.假设数据形式为$x_i\sim N(\mu,\Sigma),i= 1:N$的全部范围都得到了观测,所以就没有缺失数据(本书11.6.1是讨论在有缺失数据的情况下对多元正态分布(MVN)进行参数估计).简单来说,就是把后验推断分成三部分,首先是计算$p(\mu|D,\Sigma)$,然后计算$p(\Sigma|D,\mu)$,最后计算联合分布$p(\mu,\Sigma|D)$.


### 4.6.1$\mu$的后验分布


之前说过如何对$\mu$进行最大似然估计(MLE)了,现在说下如何计算其后验,这对于对其本身值的不确定性进行建模很有用.

似然函数形式为:

$p(D|\mu)=N(\bar x|\mu,\frac{1}{N}\Sigma)$(4.171)

为了简化,使用共轭先验(conjugate prior),这里用的是一个高斯分布.具体来说就是如果$p(\mu)=N(\mu|m_0,V_0)$,然后就可以推出一个对$\mu$的高斯后验分布,这要基于本书4.4.2.2的结论.这样得到了:

$$
\begin{aligned}
p(\mu|D,\Sigma)&= N(\mu|m_N,V_N) &\text{(4.172)}\\
V_N^{-1}&= V_0^{-1}+N\Sigma^{-1} &\text{(4.173)}\\
m_N&=V_N (\Sigma^{-1}(N\bar x)+V_0^{-1}m_0)  &\text{(4.174)}\\
\end{aligned}
$$

这就跟基于有噪音的雷达光电来推测目标位置是一模一样的过程,只不过这时候在推测的是一个分布的均值,而不是有噪音的样本.(对于一个贝叶斯方法来说,参数的不确定性和其他任何事情的不确定性没有区别.)

可以设置$V_0=\infty I$来建立一个无信息先验.这样则有$p(\mu|D,\Sigma)=N(\bar x \frac{1}{N}\Sigma)$,所以后验均值就等于最大似然估计(MLE).另外我们还能发现后验方差降低到了$\frac{1}{N}$,这是频率视角概率统计(frequentist statistics)的标准结果. 

### 4.6.2$\Sigma$的后验分布*

然后说如何计算$p(\Sigma|D,\mu)$.似然函数形式如下:
$p(D|\mu,\Sigma)\propto |\Sigma|^{-\frac{N}{2}}\exp(-\frac{1}{@}tr(S_{\mu}\Sigma^{-1}))$(4.175)

对应的共轭先验正好是逆威沙特分布,参考4.5.1.还记得这就有下面的概率密度函数(pdf):

$IW(\Sigma|S_0^{-1} ,v_0)\propto |\Sigma|^{-(v_0+D+1)/2} \exp(-\frac{1}{2}tr(S_0\Sigma^{-1}))$(4.176)

上式中$v_0\D-1$就是自由度(degrees of freedom,缩写为dof),而$S_0$是对称的概率密度矩阵(symmetric pd matrix).$S_0^{-1}$就是先验散布矩阵(prior scatter matrix),而$N_0\overset\triangle{=}v_0+D+1$控制了先验强度,所以扮演的角色也就类似于取样规模N.

此处查看原书图 4.17


把似然函数和先验乘在一起,就可以发现后验也是一个逆威沙特分布(inverse Wishart):


$$
\begin{aligned}
p(\Sigma|D,\mu)&\propto |\Sigma|^{\frac N2}\exp(-\frac12tr(\Sigma^{-1}S_{\mu})|\Sigma|^{-(v_0+D+1)/2}))  \exp(-\frac12 tr(\Sigma^{-1}S_0) )&\text{(4.177)}\\
&= |\Sigma|^{-\frac{N+(v_0+D+1)}{2}} \exp(-\frac12tr[\Sigma^{-1}(S_{\mu}+S_0 )] ) &\text{(4.178)}\\
&= IW(\Sigma|S_N,v_N)&\text{(4.179)}\\
v_N&=v_0+N &\text{(4.180)}\\
S_N^{-1}&=S_0+S_{\mu} &\text{(4.181)}\\
\end{aligned}
$$

用文字来表述,就是说后验强度(posterior strength)$v_N$就是先验强度(prior strength)$v_)$加上观测次数N,而后验散布矩阵(posterior scatter matrix)$S_N$也就是先验散布矩阵(prior scatter matrix)$S_0$加上数据散布矩阵(data scatter matrix)$S_{\mu}$.

#### 4.6.2.1 最大后验估计(MAP estimation)

通过等式4.7可知$\hat\Sigma_{mle}$是一个秩(rank)为$\min(N,D)$的矩阵.如果$N<D$,就是一个非满秩的(not full rank),因此就不可逆(uninvertible).而如果$N>D$,也可能$\hat\Sigma$是病态的(ill-conditioned)(意思就是近乎奇异矩阵).

要解决这些问题,可以用后验众数(posterior mode)或者均值(mean).使用和最大似然估计(MLE)推导类似的技巧,就可以推出最大后验估计(MAP):
$\hat\Sigma_{map}=\frac{S_N}{v_N+D+1}=\frac{S_0+S_{\mu}}{N_0+N}$(4.182)

如果用一个不适用均匀先验(improper uniform prior),对应的就是$N_0=0,S_0=0$,也就恢复到了最大似然估计(MLE).

如果使用一个适当的含信息先验(proper informative prior),只要$D/N$比较大,比如超过0.1的时候,就很被咬了.设$\mu=\bar x$,则$S_{\mu}=S_{\bar x}$.然后就可以吧最大后验估计(MAP)写成一个先验众数(prior mode)和最大似然估计(MLE)的凸组合(convex combination).设$\Sigma_0\overset{\triangle}{=} \frac{S_0}{N_0}$为先验众数(prior mode).然后可以把后验众数(posterior mode)写成如下形式:

$\hat\Sigma_{map}=\frac{S_0+S_{\bar x}}{N_0+N}=\frac{N_0}{N_0+N}\frac{S_0}{N_0}   + \frac{N_0}{N_0+N} \frac{S}{N}=\lambda\Sigma_0+(1-\lambda)\hat\Sigma_{mle}$(4.183)

其中的$\lambda=\frac{N_0}{N_0+N}$,控制的是朝向先验收缩(shrinkage)的规模(amount).

这就引出了另外一个问题:先验的那些参数都是哪来的?通常可以通过交叉验证来设置$\lambda$.或者可以使用闭合形式公式(closed-form formula),出自(Ledoit and Wolf 2004b,a; Schaefer and Strimmer 2005),是在使用平方损失(squared loss)的情况下的频率论角度的最优估计(optimal frequentist estimate).关于这是不是对协方差矩阵(covariance matrices)最自然的损失函数(loss function)还有争议,因为忽略了正定约束(positive deﬁnite constraint),不过确实能得到一个简单的估计器(estimator),本书配套的PMTK软件中的shrinkcov函数是一个实现.稍后再讨论贝叶斯角度对$\lambda$的估计.


至于先验协方差矩阵(prior covariance matrix)$S_0$,可以用下面的(依赖数据的)先验:$S_0=diag(\hat\Sigma_{mle})$.这时候最大后验估计为:
$\hat\Sigma_{map}(i,j)=\begin{cases} \hat\Sigma_{mle}(i,j) & \text{if } i=j\\ (1-\lambda)\hat\Sigma_{mle}(i,j)  &\text{otherwise}\end{cases}$(4.184)

这样就能发现对角项目等于他们的最大似然估计(MLE),而非对角元素就朝着0收缩了.这也叫收缩估计(shrinkage estimation)或者正则化估计(regularized estimation).

图4.17中就展示了最大后验估计(MAP)的好处.设对一个50维的正态分布进行拟合,分别使用$N=100,N=50,N=25$个数据点.很明显最大后验分布总是良好状态的(well-conditioned),而不像最大似然估计(MLE)会有病态的情况出现.特别是最大后验估计(MAP)的特征谱(eigenvalue spectrum)会比最大似然估计(MLE)的更接近真是矩阵.不过特征向量(eigenvectors)不受影响.

在后面的章节中,当我们要对高维度数据的协方差矩阵进行拟合的时候,对$\Sigma$的正则估计的重要性就很明显了.


#### 4.6.2.2 单变量后验(Univariate posterior)

在一维情况下,似然函数(likelihood)形式如下所示:

$p(D|\sigma^2)\propto (\sigma^2)^{-N/2}\exp (-\frac{1}{2\sigma^2}\sum^N_{i=1}(x_i-\mu)^2)$(4.185)

标准共轭先验(standard conjugate prior)正好就是一个逆$\gamma$分布(inverse Gamma distribution),也就是标量版本的逆威沙特分布(inverse Wishart):
$IG(\sigma^2|a_0,b_0)\propto (\sigma^2)^{1(a_0+1)}\exp(-\frac{b_0}{\sigma^2})$(4.186)


此处查看原书图 4.18

把似然函数(likelihood)和先验(prior)乘起来就会发现后验(posterior)也是IG:
$$
\begin{aligned}
p(\sigma^2|D)&=IG(\sigma^2|a_N,b_N)    &\text{(4.187)}\\
a_N&= a_0+N/2   &\text{(4.188)}\\
b_N&= b_0+\frac{1}{2}\sum^N_{i=1}(x_i-\mu)^2   &\text{(4.189)}\\
\end{aligned}
$$
图4.18为图示.

后验的形式不像多元情况下的那样好看,因为有了个因子$\frac{1}{2}$.这是因为$IW(\sigma^2|s_0,v_0)=IG(\sigma^2|\frac{s_0}{2},\frac{v_0}{2})$.使用逆正态分布$IG(a_0,b_0)$的另一个问题是先验同时对$a_0,b_0$进行编码(encoded).要避免这些问题,通常从统计学角度来说,都是使用对逆向高斯分布(IG distribution)的替代参数化,也就是(缩放)逆卡方分布((scaled) inverse chi-squared distribution),定义如下所示:
$ \chi^{-2}(\sigma^2|v_0,\sigma_0^2)=IG(\sigma^2|\frac{v_0}{2})\frac{v_0\sigma^2_0}{2}\propto (\sigma^2)^{-v_0/2-1}\exp(-\frac{v_0\sigma^2_0}{2\sigma^2})$(4.190)

上式中的$v_0$控制了先验的强度,而$\sigma^2$对先验的值进行了编码.这样后验则成了:

$$
\begin{aligned}
p(\sigma^2|D,\mu)&= \chi^{-2}(\sigma^2|v_N,\sigma^2_N)  &\text{(4.191)}\\
v_N&= v_0+N  &\text{(4.192)}\\
\sigma^2_N&=  \frac{v_0\sigma_0^2+\sum^N_{i=1}(x_i-\mu)^2}{v_N} &\text{(4.193)}\\
\end{aligned}
$$


可见后验的自由度(dof)$v_N$是先验自由度(dof)$v_0$加上N,而后验平方和$v_n\sigma^2_N$就是先验平方和$v_0\sigma^2_0$加上数据的平方和.

可以设$v_0=0$来模拟一个无信息先验(uninformative prior)$p(\sigma^2)\propto\sigma^{-2}$,也很好直观理解,就是对应着零虚拟样本规模(zero virtual sample size).

## 4.6.3$\mu$和$\Sigma$的后验分布*

现在来讨论一下如何计算$p(\mu,\Sigma|D)$.这些结论有点复杂,不过在本书后面的章节会很有用.对于第一次阅读的读者来说,可以先跳过.

#### 4.6.3.1 似然函数(likelihood)

似然函数为:

$p(D|\mu,\Sigma) = (2\pi)^{-ND/2}|\Sigma|^{-\frac{N}{2}}\exp(-\frac{N}{2}(x_i-\mu)^T\Sigma^{-1}(x_i-\mu)  ) $(4.194)

很明显:

$\sum^N_{i=1}(x_i-\mu)^T\Sigma^{-1}(x_i-\mu)=tr(\Sigma^{-1}S_{\bar x})+ N(\bar x-\mu)^T\Sigma^{-1}(\bar x-\mu)$(4.195)

因此可以把似然函数写成如下的形式:
$$
\begin{aligned}
p(D|\mu,\Sigma)&= (2\pi)^{-ND/2}|\Sigma|^{-\frac{N}{2}}\exp(-\frac{N}{2}(\mu-\bar x)^T\Sigma^{-1} (\mu-\bar x)  )   &\text{(4.196)}\\
&\exp(-\frac{N}{2}tr(\Sigma^{-1}S_{\bar x })) &\text{(4.197)}
\end{aligned}
$$
后面会用到这个形式.
 
 
#### 4.6.3.2 先验(Prior)


先验形式为:
$p(\mu,\Sigma)=N(\mu|m_0,V_0)IW(\Sigma|S_0,v_0)$(4.198)

很不幸,这和似然函数不共轭(not conjugate).为什么呢?注意$\mu$和$\Sigma$在似然函数(likelihood)中以非因子形式(non-factorized way)共同出现,因此在后验中也会耦合在一起(coupled together).

上面的先验就也被叫做半共轭(semi-conjugate)或者条件共轭(conditionally conjugate),因为两个条件分布$p(\mu|\Sigma),p(\Sigma|\mu )$都是独立共轭(individually conjugate)的.要建立一个完全共轭先验(full conjugate prior),需要让$\mu,\Sigma$两者相互依赖.所以可以使用下面这样形式的联合分布:

$p(\mu,\Sigma)=p(\Sigma)p(\mu|\Sigma)$(4.199)

参考一下等式4.197中的似然函数等式,就可以发现自然共轭先验(natural conjugate prior)的形式为正态逆威沙特分布(Normal-inverse-wishart,缩写为 NIW),定义形式如下所示:
$$
\begin{aligned}
NIW(\mu,\Sigma|m_0,k_0,v_0,S_0)& \overset\triangle{=}& \text{(4.200)}\\
 & N(\mu|m_0,\frac{1}{k_0}\Sigma)\times IW(\Sigma|S_0,v_0 )   & \text{(4.201)}\\
&=\frac{1}{Z_{NIW}}|\Sigma|^{\frac{1}{2}}\exp(-\frac{k_0}{2}\mu-m_0()^T\Sigma^{-1}(\mu-m_0))   & \text{(4.202)}\\
&\times |\Sigma|^{-\frac{v_0+D+1}{2}}\exp(-\frac{1}{2}tr(\Sigma^{-1}S_0))   & \text{(4.203)}\\
& = \frac{1}{Z_{NIW}}|\Sigma|^{-\frac{v_0+D+2}{2}}  & \text{(4.204)}\\
&\times \exp(-\frac{k_0}{2}(\mu-m_0)^T\Sigma^{-1}(\mu-m_0) -\frac{1}{2}tr(\Sigma^{-1}S_0))   & \text{(4.205)}\\
Z_{NIW}&= 2^{V_0D/2}\Gamma_D(v_0/2)(2\pi/k_0)^{D/2} |S_0|^{-v_0/2}  & \text{(4.206)}\\
\end{aligned}
$$

上式中的$\Gamma_D(a)$是多元$\gamma$分布(multivariate Gamma function).
上面这个逆威沙特分布的参数可以通过如下步骤来进行推断:$m_0$就是$\mu$的先验均值,而$k_0$就是对这个先验的相信程度,$S_0$ 是正比于$\Sigma$的先验均值,而$v_0$ 是对这个先验的相信程度.

参考(Minka 2000f)可以发现,(不适用(improper))无信息先验(uninformative prior)的形式如下所示:
$$
\begin{aligned}
\lim _{k\rightarrow 0} N(\mu|m_0,\Sigma/k)IW(\Sigma|S_0,k&\propto |2\pi\Sigma|^{\frac{1}{2}}|\Sigma|^{-(D+1)/2} &\text{(4.207)}\\
&\propto |\Sigma|^{-(D/2+1)}\propto NIW(\mu,\Sigma|0,0,0,0I)   &\text{(4.208)}\\
\end{aligned}
$$

在实践中,一般都是使用弱含信息数据依赖先验(weakly informative data-dependent prior)比较好.常规选择(参考(Chipman et al. 2001, p81), (Fraley and Raftery 2007, p6))是设置$S_0=diag(S_{\bar x})/N, v_0=D+2$来确保$\mathrm{E}[\Sigma]=S_0$,然后设$\mu_0=\bar x$以及$k_0$为比较小的数值,比如0.01.



#### 4.6.3.3 后验

如练习4.11所示,后验可以表示成更新过参数的逆威沙特分布(NIW):
$$
\begin{aligned}
p(\mu,\Sigma|D)&=  NIW(\mu,\Sigma|m_N,k_N,v_N,S_N) &\text{(4.209)}\\
m_N&= \frac{k_0m_0+N\bar x}{k_N} =\frac{k_0}{k_0+N}m_0+\frac{N}{k_0+N} \bar x &\text{(4.210)}\\
k_N&=k_0+N   &\text{(4.211)}\\
v_N&=v_0+N   &\text{(4.212)}\\
S_N&= S_0+S_{\bar x}+\frac{k_)N}{k_0+N}(\bar x-m_0)(\bar x-m_0)^T  &\text{(4.213)}\\
&= S_0+S+k_0m_0m_0^T-k_Nm_Nm_N^T  &\text{(4.214)}\\
\end{aligned}
$$

上式中我们定义了$S\overset{\triangle}{=} \sum^N_{i=1}x_ix_i^T$,这是一个未中心化的平方和矩阵(uncentered sum-of-squares matrix),相比中心化矩阵这样的更容易进行渐进的增量更新.

结果很直观:后验均值(posterior mean)就是对先验均值(prior mean)和最大似然估计(MLE)的凸组合(convex combination),附带上强度控制项$k_0+N$.而后验散布矩阵(posterior scatter matrix)$S_N$就是先验散布矩阵(prior scatter matrix)$S_0$加上经验散布矩阵(empirical scatter matrix)$S_\bar x$,再加上由均值不确定性带来的附加项(这也创造了自己的一个虚拟散布矩阵(virtual scatter matrix)).

#### 4.6.3.4 后验众数(Posterior mode)

联合分布的众数(mode)如下所示:
$\arg\max p(\mu,\Sigma|D) = (m_N,\frac{S_N}{v_N+D+2})        $(4.215)

如果设置$k_0=0$,就降低(reduce)成了:
$\arg\max p(\mu,\Sigma|D) = (\bar x,\frac{S_0+S_{\bar x}}{v_N+N+D+2}) $(4.216)

对应的估计$\hat \Sigma$几乎和等式4.183所述一样,唯一区别是分母上差了一个1,这是因为这个众数(mode)是联合分布的,而不是边缘分布的.


##### 4.6.3.5 后验边缘分布

$\Sigma$的后验边缘分布就很简单了,如下所示:

$p(\Sigma|D) =\int p(\mu,\Sigma|D)d\mu=IW(\Sigma|S_N,v_N)  $(4.217)

这个边缘分布的众数(mode)和均值(mean)分别为:

$\hat\Sigma_{map}=\frac{S_N}{v_N+D+1}, \mathrm{E}[\Sigma]=\frac{S_N}{v_N-D-1}$(4.218)

不难发现对$\mu$的后验边缘分布正好就是一个多元学生Ｔ分布:

$p(\mu|D)=\int p(\mu,\Sigma|D)d\Sigma = T(\mu|m_N,\frac{１}{v_N－Ｄ＋１}S_N,v_N－Ｄ＋１)      $(4.219)

这是由于学生分布可以表示做多个高斯分布（正态分布）的缩放混合，参考本书等式11.61.


此处查看原书图 4.19


#### 4.6.3.6 后验预测

后验预测(posterior predictive)如下所示:
$p(x|D)=\frac{p(x,D)}{p(D)}$(4.220)

所以很容易用一系列边缘似然函数(marginal likelihood)的比值的形式来进行估算.
结果这个比值也是多元学生T分布:

$$
\begin{aligned}
p(x|D)&= \int \int N(x|\mu,\Sigma)NIW(\mu,\Sigma|m_N,k_N,S_N)d\mu d\Sigma   &\text{(4.221)}\\
&= T(x|m_N,\frac{k_N+1}{k_N(v_N-D+1)}S_N,v_N-D+1)  &\text{(4.222)}\\
\end{aligned}
$$

### 4.6.3.7 标量数据的后验

现在把上面的结论用到一个特殊情况,即$x_i$是一维的.这些结果在统计领域中有很广泛的应用.如本书4.6.2.2所示,通常可能不适用正常逆威沙特分布(normal inverse Wishart),而是使用正常逆卡方分布(normal inverse chi-squared,缩写为NIX),定义如下所示:

$$
\begin{aligned}
NI\chi^2(\mu,\sigma^2|m_0,k_0,v_0,\sigma_0^2)& \overset\triangle{=}N(\mu|m_0,\sigma^2/k_0)\chi^{-2}(\sigma^2|v_0,\sigma_0^2)  &\text{(4.223)}
&\propto (\frac{1}{\sigma^2})^{(v_0+3)/2} \exp (-\frac{v_0\sigma_0^2+k_0(]mu-m_0)^2}{2\sigma^2}) &\text{(4.224)}
\end{aligned}
$$

图4.19所示为其图像.沿着$\mu$轴,分布形状类似正态分布,而沿着$\sigma^2$轴分布形状就像是逆卡方分布($\chi^{-2}$);整个联合概率密度函数的轮廓形状就像是压扁的蛋.有意思的是我们会发现$\mu$的形状比较小数值的$\sigma^2$有更显著的峰值,这也很好理解,因为数据本身方差小(low variance),就能进行更准确的估计了.

后验如下所示

$$
\begin{aligned}
p(\mu,\sigma^2|D)&=   NI\chi^2(\mu,\sigma^2|m_N,k_N,v_N,\sigma^2_N)       &\text{(4.225)}
m_N&= \frac{k_0m_0+N\bar x}{k_N}  &\text{(4.226)}
k_N&= k_0+N   &\text{(4.227)}
v_N&= v_0+N   &\text{(4.228)}
v_N\sigma^2_N&=  v_0\sigma^2_0+\sum^N_{i=1}(x_i-\bar x)^2+\frac{Nk_)}{k_0+N}(m_0-\bar x)^2        &\text{(4.229)}
\end{aligned}
$$

$\sigma^2$的后验边缘分布为:

$p(\sigma^2|D)=\int p(\mu,\sigma^2|D)d\mu =\chi^{-2}(\sigma^2|v_N,\sigma^2_N)$(4.230)

其后验均值为:$\mathrm{E}[\sigma^2|D]=\frac{v_N}{v_N-2}\sigma^2_N$

$\mu$的后验边缘分布为学生T分布,是学生分布的缩放混合形式,如下所示:

$p(\mu|D)= \int  p(\mu,\sigma^2|D)d\sigma^2 =T(\mu|m_N,\sigma^2_N/k_N,v_N) $(4.231)
其后验均值为:$\mathrm{E}[\mu|D]=m_N$

如果我们使用下面的无信息先验,结果会是什么样呢?
$p(\mu,\sigma^2)\propto p(\mu)p(\sigma^2)\propto \sigma^{-2}\propto NI\chi^2(\mu,\sigma^2|\mu_0=0,k_0=0,v_0=-1,\sigma^2_0=0)$(4.232)

有了上面的先验,后验形式如下所示:

$p(\mu,\sigma^2|D)= NI\chi^2(\mu,\sigma^2|\mu_N=\bar x,k_N=N,v_N=N-1,\sigma^2_N=是^2)$(4.233)

上式中的:

$s^2\overset{\triangle}{=} \frac{1}{N-1}\sum^N_{i=1}(x_i-\bar x)^2 =   \frac{N}{N-1}\sigma^2_{mle}$(4.234)

就是标准取样偏差(sample standard deviation).在本书6.4.2中会说明这是一个对方差的无偏见估计(unbiased estimate).这样后验均值的边缘分布为:

$p(\mu|D)=T(\mu|\bar x,\frac{s^2}{N},N-1)$(4.235)

而$\mu$的后验方差为:
$\mathrm{var}[\mu|D]=\frac{v_N}{v_N-2}\sigma^2_N$(4.236)

上面这个后验方差的平方根就是均值的标准差(standard error of the mean):

$\sqrt{ \mathrm{var}[\mu|D]}\approx \frac{s}{\sqrt{N}}$(4.237)

然后均值的估计95%后验置信区间(credible interval)为:

$I_{.95}(\mu|D)=\bar x \pm 2\frac{s}{\sqrt{N}}$(4.238)

(贝叶斯理论的置信空间在本书的5.2.2有更多讲解,而频率论的置信区间与之对比的内容在本书6.6.1.)


#### 4.6.3.8 贝叶斯T检验

架设我们要检验一个假设:给定正态分布$x \sim N(\mu,\sigma^2)$,对某个未知值$\mu_0$(通常都是0),$\mu \ne \mu_0$,这叫做双面单样本t检验(two-sided, one-sample t-test).简单方法就是检查$\mu_0\in I_{0.95+(\mu|D)}$是否成立.如果不成立,则有95%的信心认为$\mu\ne \mu_0$.更普遍的做法是检验两对样本是否有同样的均值.更确切来说,设$y_i \sim N(\mu_1,\sigma^2),z_i\sim N(\mu_2,\sigma^2)$.就可以使用$x_i=y_i-z_i$来验证是否有$\mu=\mu_1-\mu_2 >0$.可以用下面的形式来对这个量进行估计:
$p(\mu>\mu_0|D)= \int^{\infty}_{\mu_0}p(\mu|D)d{\mu} $(4.239)

这也叫做单面成对T检验(one sided paired t-text).(对未配对测试(unpaired test)有类似的方法,对比在二项比例(binomial proportions)上有所不同,本书5.2.3会介绍.)

要计算这个后验,必须要指定一个先验.设用一个无信息先验.如上所述,这样$\mu$的后验边缘分布形式为:

$p(\mu|D)= T(\mu|\bar x,\frac{s^2}{N},N-1)$(4.240)

然后我们定一下吗的T统计(t statistic):

$t\overset{\triangle}{=} \frac{\bar x -\mu_0}{s/\sqrt{N}}$(4.241)

期中的分母是均值标准差.然后有:

$p(\mu|D)=1-F_{N-1}(t)$(4.242)


上式中的$F_v(t)$是标准学生Ｔ分布$T(0,1,v)$的累积密度函数(cdf).


#### 4.6.3.9 和频率论统计学的联系

如果我们使用了无信息先验,就会发现上面的贝叶斯分析给出的结果和使用频率论方法推导的一样.(关于频率论统计学的内容在本书第六章会有详细讲解.)比如从上面的结果中,会看到有:

$\frac{\mu-\bar x}{\sqrt{s/N}}|D\sim t_{N-1}$(4.243)

这也最大似然估计(MLE)的取样分布(sampling distribution)有一样的形式:
$\frac{\mu-\bar x}{\sqrt{s/N}}|\mu \sim t_{N-1}$(4.244)

这是因为学生T分布是关于前两个参数(arguments)对称的(symmetric),所以则有$T(\bar x|\mu,\sigma^2,v)=T(\mu|\bar x,\sigma^2,v)$;因此$\mu$的后验和$\bar x$的取样分布有一样的形式.结果导致了频率测试(frequentist test)返回的(单向(one sided))p值(在本书6.6.2中有定义)和贝叶斯方法返回的$p(\mu>\mu_0|D)$一样.具体参考本书配套的PMTK3当中的bayesTtestDemo为例.

尽管看着非常相似,这两个结果还是有不同阐述的:在贝叶斯方法中,$\mu$是未知的,而$\bar x$是固定的,而在频率论方法中正好相反,$\bar X$是未知的,而$\mu$是固定的.使用无信息先验的简单模型时,频率论和贝叶斯方法之间的更多共同点可以参考(Box and Tiao 1973),本书的7.6.3.3也有更多讲解.

### 4.6.4 未知精度下的传感器融和*

本节会利用4.6.3当中的结论来解决传感器融合的问题,每个测量设备的精确率都不知道.这对本书4.4.2.2的结论进行了泛化,在4.4.2.2里是设测量模型的位置精确率服从正态分布.未知的精确率会导致有定量意义的不同结果,产生一个潜在的多态后验(multi-modal posterior).这里的内容参考了 (Minka 2001e).

假如我们想要从多个来源汇集数据,来估计某个量$\mu\in R$,但是信号源的可靠性都不知道.例如有两个不同的测试设备 x 和 y,有不同的精确率:$x_i|\mu \sim N(\mu,\lambda_x^{-1},y_i|\mu \sim N(\mu,\lambda_y^{-1}$.对两个设备各自进行独立测量,就得到了:


$x_1=1.1,x_2=1.9,y_1=2.9,y_2=4.2$(4.245)


对$\mu,p(\mu)\propto 1$使用一个无信息先验(non-imformative prior),使用一个无限宽度的正态分布$p(\mu)=N(\mu|m_0=0,\lambda_0^{-1}=\infty)$来模拟.如果$\lambda_x,\lambda_y$都知道了,那么后验就也是正态分布了:

$$
\begin{aligned}
p(\mu|D,\lambda_x,\lambda_y)&= N(\mu|m_N,\lambda_N^{-1}) &\text{(4.246)}\\
\lambda_N &= \lambda_0 +N_x\lambda_x+N_y\lambda_y  &\text{(4.247)}\\
m_N &= \frac{\lambda_xN_x\bar x+\lambda_yN_y\bar y}{N_x\lambda_x+N_y\lambda_y} &\text{(4.248)}\\
\end{aligned}
$$


上式中的$N_x=2,N_y=2$分别是x和y的观测次数,而$\bar x =\frac{1}{N_x}\sum^N_{i=1}x_i=1.5,\bar y =\frac{1}{N_y}\sum^N_{i=1}y_i=3.5$.这是因为后验精度(posterior precision)是测量精度的综合,而后验均值是先验均值(这里是0)和数据均值的加权和.

不过测试精度还是不知道啊.开始用最大似然估计来估计一下吧.对数似然函数(log-likelihood)为:

$l(\mu,\lambda_x,\lambda_y)=\log \lambda_x-\frac{\lambda_x}{2}\sum_i(x_i-\mu)^2+\log \lambda_y-\frac{\lambda_y}{2}\sum_i(y_i-\mu)^2$(4.249)

解出下面的联立方程,就能得到最大似然估计(MLE)了:

$$
\begin{aligned}
\frac{\partial l}{\partial \mu}&= \lambda_xN_x(\bar x-\mu)+\lambda_yN_y(\bar y-\mu)=0  &\text{(4.250)}\\
\frac{\partial l}{\partial \lambda_x} &= \frac{1}{\lambda_x}-\frac{1}{N_x}\sum^{N_x}_{i=1}(x_i-\mu)^2=0 &\text{(4.251)}\\
\frac{\partial l}{\partial \lambda_y} &= \frac{1}{\lambda_y}-\frac{1}{N_y}\sum^{N_y}_{i=1}(y_i-\mu)^2=0 &\text{(4.252)}\\
\end{aligned}
$$

解出来就是:



$$
\begin{aligned}
\hat \mu &=  \frac { N_x\hat \lambda_x \bar x+N_y\hat\lambda_y\bar y}{N_x\hat\lambda_y +N_y\hat \lambda_y }  &\text{(4.253)}\\
\frac{1}{\hat\lambda_x}&= \frac{1}{N_x}\sum_i (x_i-\hat \mu)^2  &\text{(4.254)}\\
\frac{1}{\hat\lambda_y}&= \frac{1}{N_y}\sum_i (y_i-\hat \mu)^2 &\text{(4.255)}\\
\end{aligned}
$$



很明显,$\mu$的最大似然估计(MLE)与后验均值$m_N$有同样的形式.

使用固定点迭代(fixed point iteration)就可以解出来了.首先初始化估计$\lambda_x=1/s_x^2,\lambda_y=1/s_y^2$,其中的$s_x^2=\frac{1}{N_x}\sum^{N_x}_{i=1}(x_i-\bar x)^2=0.16,s_y^2=\frac{1}{N_y}\sum^{N_y}_{i=1}(y_i-\bar y)^2=0.36$.
然后就解出来了$\hat \mu =2.1154$,所以有$p(\mu|D,\hat \lambda_x,\hat \lambda_y)=N\mu|2.1154,0.0554)$.如果现在进行迭代,最终会收敛到:$\hat \lambda_x=1/0.1662,\hat \lambda_y=1/4.0509,p(\mu|D,\hat \lambda_x,\hat \lambda_y)= N(\mu|,1.5788,0.0798)$.

对这个后验的插值估计如图4.20(a)所示.每个传感器的权重是根据其估计误差赋予的.由于估计误差表明传感器y远不如传感器x可靠,所以就有$\mathrm{E}[\mu|D\hat \lambda_x,\hat \lambda_y]\approx \bar x$,实际上就是忽略了传感器y.

接下来我们用贝叶斯方法来来积分求未知精度,而不对其进行估计.也就是要计算:


$p(\mu|D)\propto p(\mu)[\int p(D_x|\mu,\lambda_x)p(\lambda_x|\mu)d\lambda_x][\int p(D_y|\mu,\lambda_y)p(\lambda_y|\mu)d\lambda_y]$(4.256)


使用无信息Jeffrey先验(uninformative Jeffrey’s priors)$p(\mu)\propto 1,p(\lambda_x|\mu)\propto 1/\lambda_x,p(\lambda_y|mu)\propto 1/\lambda_y$.x和y两项对称,所以只看其中一个就可以了.关键的积分步骤是:



$$
\begin{aligned}
I= \int p(D_x|\mu,\lambda_x)p(\lambda_x|\mu)d\lambda_x \propto & \int \lambda_x^{-1}(N_x\lambda_x)^{N_x/2}   &\text{(4.257)}
& \exp( -\frac{N_x}{2}\lambda_x(\bar x-\mu)^2-\frac{N_x}{2}s^2_x\lambda_x  )d\lambda_x  &\text{(4.258)}
\end{aligned}
$$


利用$N_x=2$来简化到:

$I=\int \lambda_x^{-1}\lambda_x^1\exp(-\lambda_x[(\bar x-\mu)^2+s_x^2])d\lambda_x$(4.259)

看出来了吧,这个和一个非正则$\gamma$密度函数(unnormalized Gamma density)的积分成正比:

$Ga(\lambda|a,b)\propto \lambda^{a-1}e^{-\lambda b}    $(4.260)

其中的$a=1,b=(\bar x -\mu)^2+s^2_x$.因此这个积分也就和$\gamma$分布的归一化常数(normalizing constant)$\Gamma(a)b^{-a}$成正比,就得到了:


$I\propto \int p(D_x|\mu,\lambda_x)p(\lambda_x|\mu)d\lambda_x  \propto [(\bar x -\mu)^2+s_x^2]^{-1}$(4.261)

然后后验则成了:

$p(\mu|D)\propto \frac{1}{(\bar x -\mu)^2+s^2_x} \frac{1}{(\bar y -\mu)^2+s^2_y} $(4.262)




具体的后验如图4.20(b)所示.可以看到有两个众数(mode),分别在$\bar x=1.5, \bar y=3.5$这两个位置.对应的就是x传感器比y传感器更精确.第一个众数(mode)的权重更高,因为x传感器给出的数据互相更接近,所以看上去就是这个传感器更可靠.(很明显不可能两个都可靠,因为他们给出的值都不一样的.)不过贝叶斯的方案保持了开放性,就是始终保持了y传感器可能更可靠的概率;从两次测量,其实还不能说就按照差值估计得到的结果一样来选择x传感器,这个结果可能过分有信心了,后验太窄了.

练习略.






# MLAPP 读书笔记 - 05 贝叶斯统计(Bayesian statistics)

> A Chinese Notes of MLAPP，MLAPP 中文笔记项目 
https://zhuanlan.zhihu.com/python-kivy

记笔记的人：[cycleuser](https://www.zhihu.com/people/cycleuser/activities)

2018年05月29日12:22:15



## 5.1 概论

之前咱们已经看到过很多不同类型的概率模型了,然后也讲了如何用这些模型拟合数据,比如讲到了如何去进行最大后验估计(MAP)参数$\hat\theta =\arg\max p(\theta|D)$,使用各种不同先验等等还讲了全后验(full posterior)$p(\theta|D)$,以及一些特定情境下的后验预测密度(posterior predictive density)$p(x|D)$(后面的章节中会介绍更多通用算法).


对未知变量,使用后验分布来总结我们知道的信息,这就是贝叶斯统计学的核心思想.在本章要对这个统计学上的方法进行更详细讲解,在本书第六章,也就是下一章,会讲解另一种统计方法,也就是频率论统计,或者也叫做经典统计(frequentist or classical statistics).

## 5.2 总结后验分布


后验分布$p(\theta|D)$总结了我们关于未知量$\theta$的全部信息.在本节我们会讨论一些从一个概率分布,比如后验等等,能推出来的简单量.这些总结性质的统计量通常都比全面的联合分布(full joint)更好理解也更容易可视化.

### 5.2.1 最大后验估计(MAP estimation)

通过计算后验均值(mean)/中位数(median)或者众数(mode)我们可以很容易地对一个未知量进行点估计(point
 estimate).在本书5.7,会讲到如何使用决策理论(decision theory)在这些不同方法之间进行选择.通常后验均值或者中位数最适合用于对实数值变量的估计,而后验边缘分布(posterior marginals)的向量最适合对离散向量进行估计.不过后验众数,也就是最大后验估计(MAP estimate)是最流行的,因为这将问题降低到了一个优化问题(optimization problem),这样就经常能有很多高效率的算法.另外,最大后验分布还可以用非贝叶斯方式(non-Bayesian terms)来阐述,将对数先验(log prior)看作是正则化工具(regularizer)(更多内容参考本书6.5).

虽然最大后验估计的方法在计算上很有吸引力,但还是有很多缺陷的,下面就要详细讲一讲.这也为对贝叶斯方法的详尽理解提供了动力,本章后文以及本书其他地方会讲到.



此处查看原书图 5.1


#### 5.2.1.1 无法测量不确定度



最大后验估计(MAP estimation)最明显的一个缺陷就在于没有对不确定性提供任何量度,其他的各种点估计比如后验均值或者中位数也都有这个问题.在很多应用中,都需要知道对一个估计值到底能信任多少.对于后验置信度的度量可以推导出来,在本书5.2.2中有.



#### 5.2.1.2 可能导致过拟合


最大后验分布估计中进行插值可能导致过拟合.在机器学习里面,对于预测准确性往往比模型参数的可解释性更看重.不过如果对参数的不确定度不能建模的话,就可能会导致预测分布过分有信心(overconfident).在本书第三章有若干这类例子,后面还会看到更多.在风险敏感的情况下,对预测过分置信就可能很是个问题了,具体参考本书5.7.

#### 5.2.1.3 众数(mode)是非典型点(untypical point)

选择众数(mode)来作为一个后验分布的总结通常是非常差的选择,因为众数在一个分布通常不典型的,而不像均值或者中位数那样有代表意义.这一点如图5.1(a)所示,图中是一个一维连续空间.最基本的问题是众数是在测量值为0的位置的一个点,而均值和中位数都把空间的体积(volume)考虑了进去.另外一个例子如图5.1(b)所示:这里面的众数是0,但均值则是非零的.对方差之类的参数进行推测的时候就很容易遇到这种特别完犊子的分布形态,尤其是在分层模型(hierarchical models)中.这种情况下最大后验估计(MAP)和最大似然估计(MLE)很明显都是很差的估计.

如果众数不是一个好的选择,那该怎么去对一个后验分布进行总结概括呢?答案就是使用决策理论(decision theory),在本书5.7会讲到.基本思想就是设置一个损失函数(loss function),其中的$L(\theta,\hat\theta)$表示的意思是在真实值是$\theta$而你估计值是$\hat\theta$的时候造成的损失(loss).如果使用0-1二值化量化损失,即$L(\theta,\hat\theta)=I(\theta\ne \hat\theta)$,那么最优估计就是后验众数了.0-1损失函数就意味着你只使用那些没有误差的点,其他有误差的就不要了:这样这种损失函数的情况下就没有部分置信(partial credit)了.对于连续值变量,通常用平方误差损失函数$L(\theta,\hat\theta)= (\theta-\hat\theta)^2$;对应的最优估计就是后验均值,这也会在本书5.7讲到.或者也可以使用一个更健壮的损失函数,也就是绝对值损失函数:$L(\theta,\hat\theta)= |\theta-\hat\theta|$,这时候最佳估计就是后验中位数了.

此处查看原书图 5.2

#### 5.2.1.4 最大后验估计(MAP estimation)对重参数化(reparameterization)是可变的(not invariant)*

最大后验估计(MAP estimation)的一个更严重问题就是得到的结果依赖于如何对概率分布进行参数化.从一种参数形式转换到另一种等价的参数形式,就会改变结果,这很显然略坑,因为测量单位可以是任意的(比如说测量距离的时候用的单位可以使厘米或者英寸).


为了便于理解,假设要计算x的后验分布.如果定义$y=f(x)$,可以根据等式2.87得到y的分布,这里重复一下:
$p_y(y)=p_x(x)|\frac{dx}{dy}|$(5.1)

上面的$|\frac{dx}{dy}|$叫做雅可比项(Jacobian),衡量的是经过函数f之后单位体积的变化规模.设$\hat x=\arg\max_xp_x(x)$是对x的最大后验估计(MAP estimation).通常来说这并不意味着通过函数$f(\hat x)$就能得到$\hat y= \arg\max_yp_y(y)$.例如,设$x\sim N(6,1),y=f(x)$,其中有:
$f(x)=\frac{1}{1+\exp(-x+5)}$(5.2)

然后使用蒙特卡罗模拟方法(Monte Carlo simulation)(参考本书2.7.1)来推导出y的分布.结果如图5.2所示.可见原来的正态分布被S型非线性函数给"压缩"了.具体来说就是变换后分布的众数和变换之前的众数是不相等的.

在最大似然估计的过程中遇到这种问题会怎么样呢?设想下面这个例子,参考资料 Michael Jordan.伯努利分布(Bernoulli distribution)通常是使用均值(mean)$\mu$来参数化的,也就是$p(y=1|\mu)=\mu , y\in\{0,1\}$.假设在单位间隔(unit interval)上用一个均匀先验(uniform prior):$p_\mu(\mu)=1I(0\le \mu \le 1)$.如果没有数据,最大后验估计正好就是先验的众数(mode)可以在0和1之间的任意位置.不同的参数化就会在这个区间中选择任意的不同的点.

首先设$\theta=\sqrt{\mu},\mu=\theta^2$.新的先验就是:

$p_ \theta (\theta)= p_\mu (\mu)|\frac{d\mu}{d\theta}|$(5.3)

对于$\theta\in[0,1]$,新的众数就是:

$\hat\theta_{MAP} = \arg\max_{\theta\in[0,1]}2\theta =1$(5.4)

然后设$\phi=1-\sqrt{1-\mu}$,新的先验就是:

$p_\phi(\phi)=p_\mu(\mu)|\frac{d\mu}{d\theta}|=2(1-\phi)$(5.5)

对于$\phi\in[0,1]$,新的众数就是:

$\hat\theta_{MAP} = \arg\max_{\theta\in[0,1]}2-2\phi =0$(5.6)

所以最大后验估计明显是依赖参数化设置的.最大似然估计(MLE)就不会有这个问题,因为似然率函数是一个函数而不是概率密度.贝叶斯方法也不会有这个问题,因为测量过程的变化在对参数空间上进行积分的时候都考虑进去了.

这个问题的一个解决方案就是优化下面的目标函数(objective function):

$\hat\theta =\arg\max_\theta p(D|\theta) p(\theta)|I\theta|^{-\frac{1}{2}}$(5.7)

这里的$I(\theta)$就是与$p(x|\theta)$相关的费舍信息矩阵(Fisher information matrix)(具体参考本书6.2.2).这个估计与参数化相独立,具体原因如(Jermyn 2005; Druilhet and Marin 2007)所述.然而很悲剧,对等式5.7进行优化通常都很难,这就极大降低了这个方法的吸引力了.


### 5.2.2 置信区间

除点估计外,我们经常还要对置信度进行衡量.标准的置信度衡量值是某个(标量 scalar)值$\theta$,对应的是后验分布的"宽度(width)".这可以使用一个$100(1-\alpha)%$置信区间(credible interval),是一个(连续(contiguous))区域$C=(l,u)$(这里的l和u的意思是lower和upper的缩写,表示的就是下界和上界),这个区域包含了$1-\alpha$的后验概率质量,即:

$C_\alpha (D)=(l,u):P(l\le \theta\le u|D)=1-alpha$(5.8)

可能会有很多个这样的区间,我们要选一个能满足在每个尾部(tail)有$(1-\alpha)/2$概率质量的一个区间,这个区间就叫做中央区间(central interval).

此处查看原书图 5.3


如果一个后验分布有已知的函数形式,就可以使用$l=F^{-1}(\alpha/2),u=F^{-1}(1-\alpha/2)$来计算得到后验中央区间,其中的F就是后验的累积密度函数(cdf).例如,如果后验是正态分布,$p(\theta|D)=N(0,1),\alpha=0.05$,这样就能得到了$l=\Phi (\alpha/2)=-1.96,u=\Phi(1-\alpha/2)=1.96$,其中的$\Phi$表示的是正态分布的累积密度函数(cdf).如图2.3(c)所示.这也证明了实际应用中使用$\mu\pm 2\sigma$做置信区间的可行性,其中的$\mu$表示的是后验均值,$\sigma$表示的是后验标准差,2是对1.96的一个近似.

当然了,后验分布也不可能总是正态分布的.比如对于抛硬币的那个例子来说,如果使用一个均匀先验,然后观察出N=100次试验中有$N_1=47$次人头朝上,那么后验分布就是一个$\beta$分布,即$p(\theta|D)=Beta(48,54)$.然后会发现其中95%的后验置信区间位于(0.3749,0.5673)(可以参考本书配套的PMTK3当中的betaCredibleInt,里面是单行MATLAB代码来进行这个计算).

如果我们不知道其函数形式,但可以从后验中进行取样,那么也可以使用蒙特卡罗方法近似来对后验的量进行估计:简单排序S个样品,然后找到其中一个出现在排序列表中的$\alpha/S$位置上的样本.由于$S\rightarrow \infty$,这就会收敛到真实值了.具体可以参考本书配套PMTK3当中的mcQuantileDemo.

人们总容易对贝叶斯方法置信区间(Bayesian credible intervals)和频率论的信心区间(frequentist conﬁdence intervals)产生混淆.这两个可不是一回事,本书6.6.1会详细讲到.一般来说,贝叶斯的置信区间往往是人们要去计算的,而实际上他们通常计算的却都是频率论的信心区间,这是因为大多数人都是学习的频率论的统计学,而不是贝叶斯方法统计学.好在计算贝叶斯置信区间和计算频率论信心区间的方法都不太难,这部分可以参考本书配套PMTK3当中的betaCredibleInt来查看如何在MATLAB中进行计算.

#### 5.2.2.1 最高后验密度区(Highest posterior density regions)*


此处查看原书图 5.4

中央区间的一个问题在于可能有不在这个区间内的点却有更高的概率密度,这如图5.3(a)所示,其中左侧置信区间边界之外的点就比右侧区间外的点有更高的概率.

这也导致了另外一个有用的变量,即最高后验密度(highest posterior density,缩写为HPD)区域.这个可以定义为组成总体概率质量的$100(1 − \alpha)\%$最可能的点(的集合).更正式来说,可以定义概率密度函数(pdf)上的阈值(threshold)$p^*$,满足:

$1-\alpha =\int_{\theta:p(\theta|D)>p^*}p(\theta|D)d\theta$(5.9)

然后就可以定义最高后验密度区(HPD)为:
$C_\alpha(D)=\{\theta:p(\theta|D)>p^*\}$(5.10)


在一维情况下,最高后验密度区(HPD)也叫做最高密度区间(highest density interval,缩写为HDI).例如图5.3(b)所示就是一个$Beta(3,9)$分布的95%的最高密度区间(HDI),也就是(0.04,0.48).可以发现这要比置信区间(CI)要更窄一些,虽然也是包含了95%的概率质量;另外,这个区间内的每个点都比区间外的点有更高的概率.

对一个单峰分布(unimodal distribution)来说,最高密度区间(HDI)是围绕众数包含95%概率质量的最窄区间了.可以想象一些灌水的逆过程,将水平面逐渐降低,直到95%的质量暴露出来,而只有5%的部分被淹没.这就使得在一维情况下对最高密度区间(HDI)的计算有了一个很简单的算法:搜索每个点,使区间包含95%的概率质量,然后又有最小的宽度.这可以通过一维数值优化来实现,只要知道概率分布累积密度函数(cdf)的逆函数就可以了,或者如果有一部分样本的话,可以在排序过的数据点上进行搜索(具体可以参考PMTK3当中的betaHPD).

如果后验分布是多峰(multimodal)分布,那么最高密度区间(HDI)可能就不是单个连续区间了,如图5.4(b)所示.不过对多峰后验分布进行总结通常都挺难的.


### 5.2.3 比例差别的推导(Inference for a difference in proportions)

有时候又很多个参数,然后要计算这些参数的某些函数的后验分布.例如,假设你要从亚马逊买个东西,然后又两个不同的卖家,提供同样价格.第一个卖家有90个好评10个差评,第二个卖家有2个好评没有差评,那你从哪个卖家那里买呢?

此处查看原书图 5.5

刚一看,好像你应该选第二个卖家,但也不见得很有信心,因为第二个卖家的评价太少了.本章咱们就用贝叶斯分析(Bayesian analysis)来处理一下这个问题.类似的方法还可以用于其他背景下的不同群体之间的比率或比值的对比.

设$\theta_1,\theta_2$分别是两个卖家的可信度,都是未知的.没有啥其他信息,就都用均匀先验$\theta_i \sim Beta(1,1)$.这样后验分布就是$p(\theta_1|D_1)=Beta(91,11),p(\theta_2|D_2)=Beta(3,1)$.
咱们要计算的是$p(\theta_1>\theta_2|D$.为了方便起见,这里定义一个比率的差值$\delta=\theta_1-\theta_2$.(或者也可以用对数比(log-odds ratio)).使用下面的数值积分就可以计算目标变量:

$p(\delta>0|D) =\int^1_0\int^1_0 I(\theta_1>\theta_2)Beta(\theta_1|y_1+1,N_1-y_1+1)Beta(\theta_2|y_2+1,N_2-y_2+1)d\theta_1 d\theta_2$(5.11)

经过计算会发现$p(\delta>0|D)=0.710$,也就意味着最好还是从第一个卖家那里买!具体可以参考本书配套的PMTK3中的amazonSellerDemo查看代码.(这个积分也可以以解析形式解出来(Cook 2005).)

解决这个问题有一个更简单的方法,就是使用蒙特卡洛方法抽样来估计后验分布$p(\delta|D)$.这就容易多了,因为在后验中$\theta_1,\theta_2$两者是相互独立的,而且都遵循$\beta$分布,可以使用标准方法进行取样.分布$p(\theta_i|D_i)$如图5.5(a)所示,而对$p(\delta|D)$的蒙特卡罗方法(MC)估计,总共95%的最高后验密度(HPD)区域如图5.5(b)所示.对$p(\delta>0|D)$的蒙特卡罗方法估计是通过计算样本中$\theta_1>\theta_2$的部分,这样得到的值是0.718,和真实值已经非常接近了.(具体可以参考本书配套的PMTK3中的amazonSellerDemo查看代码.)

## 5.3 贝叶斯模型选择

在图1.18中,我们看到了使用过高次多项式拟合导致了过拟合,而用过低次数多项式又导致了欠拟合.类似的,在图7.8(a)中可以看到使用的归一化参数(regularization parameter)太小会导致过拟合,而太大又导致欠拟合.一般来说,面对着一系列不同复杂性的模型(比如不同的参数分布族)可选的时候,咱们该怎么选择呢?这就是所谓的模选择问题(model selection problem).

一种方法是使用交叉验证(cross-validation),估算所有备选模型的泛化误差(generalization error),然后选择最优模型.不过这需要对每个模型拟合K次,K是交叉验证的折数(CV folds).更有效率的方法是计算不同模型的后验:

$p(m|D)=\frac{p(D|m)p(m)}{\sum_{m\in M}}p(m,D)$(5.12)

然后就很容易计算出最大后验估计模型(MAP model),$\hat m =\arg \max p(m|D)$,这就叫做贝叶斯模型选择(Bayesian model selection).

如果对模型使用均匀先验,即$p(m)\propto 1$,这相当于挑选能够让下面的项目最大化的模型:

$p(D|m)=\int p(D|\theta)p(\theta|m)d\theta$(5.13)

这个量也叫做模型m的边缘似然率(marginal likelihood),积分似然率(integrated likelihood)或者证据(evidence).具体如何进行积分在本书5.3.2有讲解.不过首先来对这个量的含义给出一下直观解释.

### 5.3.1 贝叶斯估计的奥卡姆剃刀

有人可能会觉得使用$p(D|m)$来选择模型可能总会偏向于选择有最多参数的模型.如果用$p(D|\hat\theta_m)$来选择模型,那么确实如此,其中的$\hat\theta_m$是模型m的参数的最大似然估计(MLE)或者最大后验估计(MAP),因为有更多参数的模型会对数据有更好的拟合,因此就能得到更高的似然率(higher likelihood).不过如果对参数进行积分,而不是最大化,就能自动避免过拟合了:有更多参数并不必然就有更高的边缘似然率(marginal likelihood).这就叫做贝叶斯奥卡姆剃刀效应(Bayesian Occam’s razor effect, MacKay 1995b; Murray and Ghahramani 2005),这是根据奥卡姆剃刀原则得名的,其要旨是说应该选择能解释数据的最简单模型.

理解贝叶斯奥卡姆剃刀的一种方式是将边缘似然率改写成下面的形式,基于概率论的链式规则(等式2.5):
$p(D)=p(y_1)p(y_2|y_1)p(y_3|y_{1:2})...p(y_N|y_{1:N-1})$(5.14)

上式中为了简单起见去掉了关于x的条件.这个和留一交叉验证法(leave-one-out cross-validation)估计似然率(likelihood)(本书1.4.8)看着很相似,因为也是给出了之前的全部点之后预测未来的每个点的位置.(当然了,上面表达式中,数据的顺序就没有影响了.)如果一个模型太复杂,在早期样本的时候就可能会过拟合,对后面余下的样本的预测也可能很差.


此处查看原书图 5.6

另外一种理解贝叶斯奥卡姆剃刀效应的思路是参考概率总和积累起来必然是1.这样就有$\sum_{D'}p(D'|m)=1$,其中的求和是在全部可能的数据点集合上进行的.复杂的模型可能进行很多预测,就必须把概率质量分散得特别细(thinkly),然后对任意给定数据就不能得到简单模型一样大的概率.这也叫做概率质量守恒原则(conservation of probability mass principle),如图5.6所示.水平方向的是所有可能的数据集,按照复杂性递增排序(以某种抽象概念来衡量).在纵轴上投下的是三个可能的概率模型:$M_1,M_2,M_3$复杂性递增.实际观测到底数据为竖直线条所示的$D_0$.图示可知,第一个模型太简单了,给$D_0$的概率太低.第三个模型给$D_0$的概率也很低,因为分布的更宽更窄.第二个模型就看上去正好,给已经观测到底数据给出了合理的置信程度,但又没有预测更多.因此第二个模型是最可选的模型.


图5.7中的数据也是贝叶斯奥卡姆剃刀的一个样例.其中的多项式次数分别为1,2,3,对于N=5个数据点.另外还展示了各个模型的后验,其中使用了正态分布先验(更多细节参考本书7.6).由于没有足够的数据,不能判断复杂模型,所以最大后验估计模型(MAP model)就是d=1.图5.8展示的是当样本规模扩大到N=30的时候的情况.这时候就很明显了d=2是最佳模型(实际上这时候的数据就是用一个二次函数生成的).

另一个例子是图7.8(c),其中是对数投图的$\log p(D|\lambda)$和$\log(\lambda)$,对应的是多项式岭回归模型(polynomial ridge regression model),其中的$\lambda$和交叉验证试验中用的值有相同的范围.可见最大证据(maximum evidence)大概就出现在测试的均方误差(MSE)最小的时候,也就是对应着交叉验证所选择的点.

当使用贝叶斯方法的时候,我们不仅可以仅对有限数值网格来计算证据(evidence).可以用数值优化来找到$\lambda^* =\arg\max_\lambda p(D|\lambda)$.这个方法也叫做经验贝叶斯(empirical Bayes)或者二类最大似然估计(type II maximum likelihood)(参考本书5.6).样例可以参考本书图7.8(b):可以看到曲线和交叉验证估计的形状相似,但计算效率要更高.


此处查看原书图 5.7

### 5.3.2 计算边缘似然率(证据)


当我们讨论推导一个混合模型的参数的时候,通常会写:
$p(\theta|D,m)\propto p(\theta|m)p(D|\theta,m)$(5.15)

然后忽略掉归一化常数$p(D|m)$.因为$p(D|m)$相对于$\theta$来说是恒定的,所以这样也有效.不过如果对比模型的话,需要知道如何去计算边缘似然率(marginal likelihood)$p(D|m)$.一般来说这就挺麻烦,因为必须要对所有可能的参数值来进行积分,但是如果有了一个共轭先验,就很容易计算了.

设$p(\theta)=q(\theta)/Z_0$是先验,然后$q(\theta)$是一个未归一化的分布(unnormalized distribution),而$Z_0$是针对这个先验的归一化常数.设$p(D|\theta)=q(D|\theta)/Z_l$是似然率(likelihood),其中的$Z_l$包含了似然函数中的任意常数项.最终设$p(\theta|D)=q(\theta|D)/Z_N$是后验,其中的$q(\theta|D)=q(D|\theta)q(\theta)$是未归一化的后验,而$Z_N$是这个后验的归一化常数.则有:
$$
\begin{aligned}
p(\theta|D)&= \frac{p(D|\theta)p(\theta)}{p(D)} &\text{(5.16)}\\
\frac{q(\theta|D)}{Z_N}&= \frac{q(D|\theta)q(\theta)}{Z_lZ_0p(D)} &\text{(5.17)}\\
p(D)&=\frac{Z_N}{Z_0Z_l}  &\text{(5.18)}\\
\end{aligned}
$$

所以只要归一化常数能算出来,就可以很简单地计算出边缘似然率了.接下来会给出一些例子.


此处查看原书图 5.8

#### 5.3.2.1$\beta$-二项模型(Beta-binomial model)

先把上面的结论用到$\beta$-二项模型上面.已知了$p(\theta|D)=Beta(\theta|a',b'),a'=a+N_1,b'=b+N_0$.这个后验的归一化常数是$B(a',b')$.因此有:

$$
\begin{aligned}
p(\theta|D)&= \frac{p(D|\theta)p(\theta)}{p(D)}&\text{(5.19)}\\
&= \frac{1}{p(D)}[\frac{1}{B(a,b)}\theta^{a-1}(1-\theta)^{b-1}][\binom{N}{N_1}\theta^{N_1}(1-\theta)^{N_0}] &\text{(5.20)}\\
&= \binom{N}{N_1}\frac{1}{p(D)}\frac{1}{B(a,b)}[\theta^{a+N_1-1}(1-\theta)^{b+N_0-1}]&\text{(5.21)}\\
\end{aligned}
$$

因此有:

$$
\begin{aligned}
\frac{1}{B(a+N_1,b+N_0)}&= \binom{N}{N_1}\frac{1}{p(D)}\frac{1}{B(a,b)} &\text{(5.22)}\\
p(D)&= \binom{N}{N_1}\frac{B(a+N_1,b+N_0)}{B(a,b)} &\text{(5.23)}\\
\end{aligned}
$$

$\beta$-伯努利分布模型(Beta-Bernoulli model)的边缘似然函数和上面的基本一样,唯一区别就是去掉了$\binom{N}{N_1}\$这一项.


#### 5.3.2.2 狄利克雷-多重伯努利模型(Dirichlet-multinoulli model)

和上面$\beta$-伯努利模型类似,狄利克雷-多重伯努利模型(Dirichlet-multinoulli model)的边缘似然函数如下所示:
$p(D)=\frac{B(N+\alpha)}{B(\alpha)}$(5.24)
其中的
$B(\alpha)=\frac{\prod ^K_{k=1}\Gamma(\alpha_k)}{\Gamma(\Sigma_k\alpha_k))}$(5.25)
把上面两个结合起来写成如下所示形式:
$p(D)=\frac{\Gamma(\Sigma_k\alpha_k)}{\Gamma(N+\Sigma_k\alpha_k)}\prod_k \frac{\Gamma(N_k+\alpha_k)}{\Gamma(\alpha_k)}$(5.26)
这个等式在后文中会有很多用处.

#### 5.3.2.3 高斯-高斯-威沙特分布(Gaussian-Gaussian-Wishart model)

设想使用了一个共轭正态逆威沙特分布(NIW)的多元正态分布(MVN).设$Z_0$是先验的归一化项(normalizer),$Z_N$是后验的归一化项,$Z_t=(2\pi)^{ND/2}$是似然函数的归一化项.然后很明显就能发现:

$$
\begin{aligned}
p(D)&= \frac{Z_N}{Z_0Z_1}     &\text{(5.27)}\\
&=  \frac{1}{\pi^{ND/2}}\frac{1}{2^{ND/2}}\frac{ (\frac{2\pi}{k_N})^{D/2} |S_N|^{-v_N/2}2^{(v_0+N)D/2}\Gamma_D(v_N/2) }{ (\frac{2\pi}{k_0})^{D/2} |S_0|^{-v_0/2}2^{v_0D/2}\Gamma_D(v_0/2)  }    &\text{(5.28)}\\
&= \frac{1}{\pi^{ND/2}}( \frac{k_0}{k_N} )^{D/2} \frac{|S_0|^{-v_0/2}\Gamma_D(v_N/2) }{|S_N|^{-v_N/2}\Gamma_D(v_0/2)}  &\text{(5.29)}\\
\end{aligned}
$$

这个等式后面也会用得上.



#### 5.3.2.4 对数边缘似然函数的贝叶斯信息量估计(BIC approximation to log marginal likelihood)



一般来说,直接计算等式5.13里面的积分还挺难的.一种简单又流行的近似方法是使用贝叶斯信息量(Bayesian information criterio,缩写为BIC),形式如下所示(Schwarz 1978):

$BIC\overset\triangle{=}\log p(D|\hat \theta) -\frac{dof(\hat \theta)}{2}\log N\approx \log p(D)$(5.30)

上式中的$dof(\hat\theta)$是模型中的自由度个数(number of degrees of freedom),而$\hat\theta$是模型的最大似然估计(MLE).这有一种类似惩罚对数似然函数(penalized log likelihood)的形式,其中的惩罚项(penalty term)依赖于模型的复杂度.具体信息可以从本书8.4.2查看贝叶斯信息量评分的推导过程.

以一个线性回归为例.如本书7.3所示,最大似然估计为$\hat w = (X^T X)^{-1}X^Ty$,$\hat\sigma^2= RSS/N$,$RSS=\sum^N_{i=1}(y_i -\hat w^T_{mle}x_i)^2$.对应的对数似然函数为:

$\log p(D|\hat\theta)=-\frac{N}{2}\log(2\pi\hat\sigma^2)-\frac{N}{2}$(5.31)


因此对应的贝叶斯信息量(BIC)评分为(去掉了常数项):
$BIC=-\frac{N}{2}\log (\hat\sigma^2)-\frac{D}{2}\log(N)$(5.32)

其中的Ｄ是模型中的变两个数．在统计学中，通常对BIC有另外的一中定义,称之为贝叶斯信息量损失(BIC cost,因为目的是将其最小化):
$BIC-cost\overset{\triangle}{=} -2\log p(D|\hat\theta)+dof(\hat\theta)\log(N)\approx -2\log p(D)$(5.33)

在线性回归的情况下,这就变成了:
$BIC-cost= N\log(\hat\sigma^2)+D \log (N)$(5.34)

贝叶斯信息量(BIC)方法非常类似于最小描述长度原则(minimum description length,缩写为MDL),这个原则是根据模型拟合数据的成都以及定义复杂度来对模型进行评分.更多细节参考(Hansen and Yu 2001).

还有一个和BIC/MDL非常相似的概念叫做赤池信息量(Akaike information criterion,缩写为AIC),定义如下所示:
$AIC(m,D)\overset\triangle{=}\log p(D|\hat\theta_{MLE})-dof(m)$(5.35)

这个概念是从频率论统计学的框架下推导出来的,不能被解释为对边缘似然函数的近似.虽然它的形式和BIC很相似.可以看出AIC当中的称发现该(penalty)要比BIC里面小.这就导致了AIC会挑选比BIC更复杂的模型.不过这也会导致更好的预测精度.具体参考(Clarke et al. 2009, sec 10.2)来了解更多讨论以及这类信息量.


#### 5.3.2.5 先验的效果

有时候咱也不知道该怎么设置先验.在进行后验推导的时候,先验的细节可能也不太重要,因为经常是似然率(likelihood)总会覆盖了先验.不过当计算边缘似然函数的时候,先验扮演的角色就重要多了,因为要对所有可能的参数设定上的似然函数进行平均,然后用先验来做权重.

图5.7和5.8所示的是线性回归的模型选择问题,使用了先验$p(w0=N(0,\alpha^{-1}I)$.其中的$\alpha$是一个用来控制先验强度的调节参数.这个参数效果很大,具体参考本书7.5所属.只管来说,如果$\alpha$很大,意味着权重被"强迫"降低,所以对于一个复杂模型需要使用很多小参数来拟合数据(比如高维度多项式拟合).反过来如果$\alpha$很小,就更倾向于使用简单模型,因为每个参数都可以放大很多倍.

如果先验未知,那么正确的贝叶斯过程就是先对先验给出一个先验.也就是对超参数(hyper-parameter)$\alpha$和参数w给出一个先验.要计算边缘似然函数,就要对所有未知量进行积分,也就是要计算:

$p(D|m)=\int\int p(D|w)p(w|\alpha,m)p(\alpha|m)dwd\alpha$(5.36)

当然,这就需要实现制定一个超先验(hyper-prior,即对先验的先验).好在在贝叶斯层次(Bayesian hierarchy)中越高的层次就对先验设置越不敏感.所以通常就是用无信息的超先验.

计算的一个捷径就是对$\alpha$进行优化,而不是去积分.也就是用下面的近似:

$p(D|m)\approx \int p(D|w)p(w|\hat\alpha,m)dw$(5.37)

其中的

$\hat\alpha=\arg\max_{\alpha} p(D|\alpha,m)=\arg\max_{\alpha}\int p(D|w)p(w|\alpha,m)dw$(5.38)

这个方法就叫做经验贝叶斯(empirical Bayes,缩写为EB),更多相关细节在本书5.6.这正是图5.7和5.8中所用的方法.

|贝叶斯因数(Bayes factor,BF(1,0))|解析|
|---|---|
|BF<1/100|$M_0$决定性证据|
|BF<1/10|$M_0$强证据|
|1/10<BF<1/3|$M_0$中等证据|
|1/3<BF<1|$M_0$弱证据|
|1<BF<3|$M_1$弱证据|
|3<BF<10|$M_1$中等证据|
|BF>10|$M_1$强证据|
|BF>100|$M_1$决定性证据|

##### 表格5.1 Jeffrey 对贝叶斯因数的证据规模解析


### 5.3.3 贝叶斯因数(Bayes factors)

设模型先验是均匀分布的,即$p(m)\propto 1$.那么这时候模型选择就等价于选择具有最大边缘似然率的模型了.接下来假设有两个模型可选,分别是空假设(null hypothesis)$M_0$和替换假设(alternative hypothesis)$M_1$.然后就可以定义边缘似然函数之比就叫做贝叶斯因数(Bayes factor):

$BF_{1,0}\overset\triangle{=}\frac{ p(D|M_1)}{p(D|M_0)}=\frac{p(M_1|D)}{p(M_0|D)}/\frac{p(M_1)}{p(M_0)}$(5.39)

(这个跟似然率比值(likelihood ratio)很相似,区别就是整合进来了参数,这就可以对不同复杂度的模型进行对比了.)如果$BF_{1,0}>1$,我们就优先选择模型1,繁殖就选择模型0.

当然了,也可能这个$BF_{1,0}$就只比1大一点点.这时候也不能确信模型1就一定更好.Jeffreys(1961)提出了一系列的证据范围来解析贝叶斯因数的不同值,如表格5.1所示.这个大概就相当于频率论统计学中的p值(p-value)在贝叶斯统计学中的对应概念.或者也可以把这个贝叶斯因数转换成对模型的后验.如果$p(M_1)=p(M_0)=0.5$,则有:

$p(M_0|D)=\frac{BF_{0,1}}{1+BF_{0,1}}=\frac{1}{BF_{1,0}+1}$(5.40)

#### 5.3.3.1 样例:测试硬币是否可靠

加入我们观察了一些抛硬币试验,然后想要判断所用硬币是否可靠,可靠的意思就是两面朝上的概率都是一半,即有$\theta=0.5$,不可靠就是$\theta$可以在[0,1]中间的任意位置取值了.咱们把两种模型表示为$M_0,M_1$.$M_0$下的边缘似然函数为:

$p(D|M_)=(\frac{1}{2})^N$(5.41)

其中的N就是抛硬币次数.然后$M_1$下的边缘似然函数使用一个$\beta$分布先验:

$p(D|M_1)=\int p(D|\theta)p(\theta)d\theta=\frac{B(\alpha_1+N_1,\alpha_0+N_0)}{B(\alpha_1,\alpha_0)}$(5.42)



此处查看原书图 5.9



对$\log p(D|M_1)$和人头朝上次数$N_1$的关系进行投图得到了图5.9(a),设$N=5,\alpha_1=\alpha_0=1$.(这个曲线的形状对$\alpha_0,\alpha_1$并不敏感,因为这两个相等了.)如果观察到了两次或者三次人头朝上,那么就更倾向认为硬币没问题,即$M_0$的概率大于$M_1$,因为$M_0$是个更简单的模型(没有自由参数).如果硬币有问题而出现人头背面各自一半情况只是碰巧就是很可疑的巧合了.不过随着次数越来越极端,就可能更倾向硬币有问题的假设了.如果把贝叶斯因数的对数函数$\log BF_{1,0}$投图,会发现有一样的形状,因为$\log p(D|M_0)$是一个常量(constant).参考练习3.18.


图5.9(b)是对$\log p(D|M_1)$的贝叶斯信息量(BIC)估计,这个不可靠的硬币样例参考本书5.3.3.1.很明显这个曲线几乎和对数边缘似然函数的形状一模一样,这对于模型选择的目的来说就足够用了,因为绝对范围都没有影响.具体来说就是倾向于用更简单的模型,除非数据本身特别支持更复杂的模型.


### 5.3.4 杰弗里斯 - 林德利悖论(Jeffreys-Lindley paradox)*

当使用不适当先验(improper priors,比如积分不为1的先验)来进行模型选择和假设测试的时候,会遇到各种问题,即便这些先验对于其他目的来说可能还都是可用的.例如,假如测试假设$M_0:\theta\in \Theta_0$和$M_1:\theta\in \Theta_1$.要定义在$\theta$上的边缘分布密度(marginal density),使用下面的混合模型:

$p(\theta)=p(\theta|M_0)p(M_0)+p(\theta|M_1)p(M_1)$(5.43)

只有当$p(\theta|M_0),p(\theta|M_1)$都是适当(归一化)的密度函数的时候,上式才有意义.这种情况下,后验为:

$$
\begin{aligned}
p(M_0|D)& =  \frac{p(M_0)p(D|M_0)}{p(M_0)p(D|M_0)+p(M_1)p(D|M_1)}   & \text{(5.44)}\\
& = \frac{p(M_0)\int_{\Theta_0} p(D|\theta)p(\theta|M_0)d\theta}{p(M_0)\int _{\Theta_0}p(D|\theta)p(\theta|M_0)d\theta + p(M_1)\int _{\Theta_1}p(D|\theta)p(\theta|M_1)d\theta}    & \text{(5.45)}\\    
\end{aligned}
$$

然后假设使用了不适当先验,即有$p(\theta|M_0)\propto c_0,p(\theta|M_1)\propto c_1$.则:

$$
\begin{aligned}
p(M_0|D)& =   \frac{p(M_0)c_0 \int_{\Theta_0} p(D|\theta)d\theta}{ p(M_0)c_0 \int_{\Theta_0} p(D|\theta)d\theta  + p(M_1)c_1 \int_{\Theta_1} p(D|\theta)d\theta  }    & \text{(5.46)}\\
& =  \frac{p(M_0)c_0 l_0}{p(M_0)c_0 l_0+p(M_1)c_1 l_1}   & \text{(5.47)}\\    
\end{aligned}
$$

上式中$l_i=\int_{\Theta_i}p(D|\theta)d\theta$是模型i的整合/边缘似然函数(integrated or marginal likelihood).然后设$p(M_0)+p(M_1)=\frac{1}{2}$.则有:

$p(M_0|D)= \frac{c_0 l_0}{c_0 l_0+c_1 l_1} =\frac{l_0}{l_0+(c_1/c_0)l_1}$(5.48)

然后就可以任意选择$c_1,c_0$来改变后验.要注意,如果使用了适当(proper)但很模糊(vague)先验也能导致类似问题.具体来说,贝叶斯因数总会倾向于选择更简单的模型,因为使用非常分散的先验的复杂模型观察到数据的概率是非常小的.这就叫做杰弗里斯 - 林德利悖论(Jeffreys-Lindley paradox).

所以在进行模型选择的时候选择适当先验是很重要的.不过还是要注意,如果$M_0,M_1$在参数的一个子集上分享了同样的先验,那么这部分先验就可能是不适当的,因为对应的归一化常数会被约掉无效.


## 5.4 先验

贝叶斯统计小最受争议的就是对先验的依赖.贝叶斯主义者认为这是不可避免的,因为没有人是白板一片(tabula rasa/blank slate):所有的推测都必须是以客观世界的某些假设为条件的.不过人们还是希望能够尽量缩小事先假设的影响.接下来就简要讲一下实现这个目的的几种方法.



### 5.4.1 无信息先验

如果关于$\theta$应该是啥样没有比较强的事先认识,通常都会使用无信息先验(uninformative or non-informative prior),然后就去"让数据自己说话".

不过设计一个无信息先验还是需要点技巧的.例如,伯努利参数$\theta\in [0,1]$.有人可能会觉得最无信息的先验应该是均匀分布$Beta(1,1)$.不过这时候后验均值就是$\mathrm{E}[\theta|D]=\frac{N_1+1}{N_1+N_0+2}$,其中的最大似然估计(MLE)为$\frac{N_1}{N_1+N_0}$.因此就可以发现这个先验也并不是完全无信息的.

很显然,通过降低伪计数(pseudo counts)的程度(magnitu),就可以降低先验的影响.综上所述,最无信息的先验应该是:

$\lim_{c\rightarrow 0}Beta(c,c)=Beta(0,0)$(5.49)

上面这个是在0和1两个位置有质量的等价点的混合(a mixture of two equal point masses at 0 and 1),参考(Zhu and Lu 2004).这也叫做Haldane先验(Haldane prior).要注意这个Haldane先验是一个不适当先验,也就是积分不为1.不过只要能看到至少有一次人头朝上以及至少有一次背面朝上,这个后验就是适当的.

在本书5.4.2.1,会论证"正确"的无信息先验是$Beta(\frac12,\frac12)$.很明显这三个先验在实际使用的时候差异很可能是可以忽略不计的.通常来说,都可以进行敏感度分析,也就是检测建模假设的变化对模型结论和预测变化的影响,这种敏感度分析包含了对先验的选择,也包含了似然率的选择以及对数据的处理过程.如果结论是对于模型假设来说并不敏感,那么就可以对结果更有信心了.


### 5.4.2 杰弗里斯先验论(Jeffreys priors)*

哈罗德 杰弗里斯(Harold Jeffreys)设计了一个通用技巧来创建无信息先验.得到的就是杰弗里斯先验论(Jeffreys prior).关键之处是观察到如果$p(\phi)$是无信息的,那么对这个先验重新参数化,比如使用某函数h得到的$\theta=h(\phi)$,应该也是无信息的.然后就可以更改方程变量:

$p_\theta(\theta)= p_\phi(\phi)|\frac{d\phi}{d\theta}|$(5.50)

所以先验会总体上有变化.然后选择

$p_\phi(\phi)\propto (I(\phi))^{\frac12}$(5.51)

其中的$I(\phi)$是费舍信息矩阵(Fisher information matrix):

$I(\phi) \overset{\triangle}{=} -\mathrm{E}[(\frac{d\log p(X|\phi)}{d\phi} )^2]$(5.52)

这是对预期的负对数似然函数的度量,也是对最大似然估计的稳定性的度量,参考本书6.2.2.于是就有:

$\frac{d\log p(x|\theta)}{d\theta}=\frac{d\log p(x|\phi)}{d\phi}\frac{d\phi}{d\theta}$(5.53)

开平方,然后去对x的期望,就得到了:

$$
\begin{aligned}
I(\theta)&= -\mathrm{E}[(\frac{d\log p(X|\theta)}{d\theta} )^2]=I(\phi)(\frac{d\phi}{d\theta})^2 &\text{(5.54)}\\
I(\theta)^{\frac{1}{2}} &= I(\phi)^{\frac12}|\frac{d\phi}{d\theta}|  &\text{(5.55)}\\
\end{aligned}
$$

所以能发现变换后的先验是:

$p_\theta(\theta)=p_\phi(\phi)|\frac{d\phi}{d\theta}|\propto (I(\phi))^{\frac12}|\frac{d\phi}{d\theta}| =I(\theta)^{\frac12}$(5.56)

所以就说明$p_\theta(\theta)$和$p_\phi(\phi)$是一样的.
接下来举几个例子.

#### 5.4.2.1 样例:伯努利模型和多重伯努利模型的杰弗里斯先验论(Jeffreys priors)

设X服从伯努利分布,即$X\sim Ber(\theta)$.一个单独样本(single sample)的对数似然函数为:

$\log p(X|\theta) =X|log \theta(1-X)\log(1-\theta)$(5.57)

得分函数(score function)正好就是对数似然函数的梯度:

$s(\theta)\overset\triangle{=}\frac{d}{d\theta}\log p(X|\theta)=\frac{X}{\theta}-\frac{1-X}{(1-\theta)^2}$(5.58)

观测信息(observed information)就是对数似然函数的二阶导数(second derivative):

$J(\theta)=-\frac{d^2}{d\theta^2}\log p(X|\theta)=-s'(\theta|X)=\frac{X}{\theta^2}+\frac{1-X}{(1-\theta)^2}$(5.59)

费舍信息矩阵(Fisher information)正好就是期望信息矩阵(expected information):

$I(\theta)=\mathrm{E}[J(\theta|X)|X\sim \theta]=\frac{\theta}{\theta^2}+\frac{1-\theta}{(1-\theta)^2}=\frac{1}{\theta(1-\theta)}$(5.60)

因此杰弗里斯先验(Jeffreys’ prior)为:

$p(\theta)\propto \theta^{-\frac12}(1-\theta)^{-\frac12}=\frac{1}{\sqrt{\theta(1-\theta)}}\propto Beta(\frac12,\frac12) $(5.61)


然后考虑有K个状态的多重伯努利随机变量.很明显对应的杰弗里斯先验(Jeffreys’ prior)为:


$p(\theta)\propto Dir(\frac12,...,\frac12)$(5.62)

要注意这个和更明显的选择$Dir(\frac1K,...,\frac1K),Dir(1,...,1)$是不一样的.

#### 5.4.2.2 样例:局部和缩放参数的杰弗里斯先验论(Jeffreys priors)

可以对一个局部参数(location parameter)取杰弗里斯先验(Jeffreys prior),比如以正态分布均值为例,就是$p(\mu)\propto 1$.这是一个转换不变先验(translation invariant prior),满足下述性质,即分配到任意区间[A,B]的概率质量等于分配另一个等宽区间[A-c,B-c]的概率质量.也就是:

$\int^{B-c}_{A-c}p(\mu)d\mu=(A-c)-(B-c)=(A-B)=\int^B_Ap(\mu)d\mu$(5.63)

这可以通过使用$p(\mu)\propto 1$来实现,可以使用一个有限变量的正态分布来近似,即$p(\mu)= N(\mu|0,\infty)$.要注意这也是一个不适当先验(improper prior),因为积分不为1.只要后验适当,使用不适当先验也没问题,也就是有$N\ge 1$个数据点的情况,因为只要有一个单独数据点就可以"确定"区域位置了.

与之类似,也可以对缩放参数(scale parameter)取杰弗里斯先验(Jeffreys prior),比如正态分布的方差,$p(\sigma^2\propto 1/\sigma^2)$.这是一个缩放独立先验(scale invariant prior)满足下面的性质:分配到任意区间[A,B]的概率质量等于分配另一个缩放区间[A/c,B/c]的概率质量,其中的c是某个常数$c>0$.(例如,如果将单位从米换成影驰,还不希望影响参数推导过程等等).这可以使用:

$p(s)\propto 1/s$(5.64)

要注意:

$$
\begin{aligned}
\int ^{B/c}_{A/c}&=  [\log s]^{B/c}_{A/c} = \log(B/c)-\log(A/c) &\text{(5.65)}\\
&= \log(B)-\log(A)=\int^B_Ap(s)ds  &\text{(5.66)}\\
\end{aligned}
$$

可以使用退化$\gamma$分布(degenerate Gamma distribution)来近似,(参考本书2.4.4),即$p(s)=Ga(S|0,0)$.这个先验$p(s)\propto 1/s$也是不适当先验,但只要有观测到超过$N\ge 2$个数据点,就能保证后验是适当的,也就可以了.(因为只要最少有两个数据点就可以估计方差了.)


### 5.4.3 健壮先验(Robust priors)

在很多情况下,我们对先验并不一定很有信心,所以就需要确保先验不会对结果有过多的影响.这可以通过使用健壮先验(robust priors,Insua and Ruggeri 2000)来实现,这种先验通常都有重尾(heavy tailes),这就避免了过分靠近先验均值.

考虑一个来自(Berger 1985,p7)的例子.设x服从正态分布,即$x\sim N(\theta,1)$.观察到了 x=5然后要去估计$\theta$.最大似然估计(MLE)是$\hat\theta=5$,看上去也挺合理.在均匀先验之下的后验均值也是这个值,即$\bar\theta=5$.不过如果假设我们知道了先验中位数(median)是0,而先验的分位数(quantiles)分别是-1和1,所以就有$p(\theta/le -1)=p(-1<\theta/le 0)=p(0<\theta/le 1)=p(1<\theta)=0.25$.另外假设这个先验是光滑单峰的.

很明显正态分布的先验$N(\theta|0,2.19^2)$满足这些约束条件.但这时候后验均值就是3.43了,看着就不太让人满意了.

然后再考虑使用柯西分布作先验(Cauchy prior)$T(\theta|0,1,1)$.这也满足上面的先验约束条件.这次发现用这个先验的话,后验均值就是4.6,看上去就更合理了(计算过程可以用数值积分,参考本书配套的PMTK3当中的 robustPriorDemo中的代码).

### 5.4.4 共轭先验的混合

健壮先验很有用,不过计算开销太大了.共轭先验可以降低计算难度,但对我们把已知信息编码成先验来说,往往又不够健壮,也不够灵活.不过,共轭先验(conjugate priors)的混合(mixtures)还是共轭的(参考联系5.1),然后还可以对任意一种先验进行近似((Dallal and Hall 1983; Diaconis and Ylvisaker 1985).然后这样的先验就能在计算开销和灵活性之间得到一个很不错的折中.

还以之前抛硬币模型为例,考虑要检查硬币是否作弊,是两面概率都一样,还是有更大概率人头朝上.这就不能用一个$\beta$分布来表示了.不过可以把它用两个$\beta$分布的混合来表示.例如,就可以使用:

$p(\theta)=0.5Beta(\theta|20,20)+0.5Beta(\theta|30,10)$(5.67)

如果$\theta$来自第一个分布,就说明没作弊,如果来自第二个分布,就说明有更大概率人头朝上.

可以引入一个潜在指示器变量(latent indicator variable)z来表示这个混合,其中的z=k的意思就是$\theta$来自混合成分(mixture component)k.这样先验的形式就是:

$p(\theta)=\sum_k p(z=k)p(\theta|z=k)$(5.68)

其中的每个$p(\theta|z=k)$都是共轭的,而$p(z=k)$就叫做先验的混合权重(prior mixing weights).(练习5.1)可知后验也可以写成一系列共轭分布的混合形式:

$p(\theta|D)=\sum_k p(z=k)p(\theta|D,z=k)$(5.69)


其中的$p(Z=k|D)$是后验混合权重(posterior mixing weights),如下所示:

$p(Z=k|D)=\frac{p(Z=k)p(D|Z=k)}{\sum_{k'}p(Z=k')p(D|Z=k')}$(5.70)

这里的量$p(D|Z=k)$是混合成分k的边缘似然函数,可以参考本书5.3.2.1.


#### 5.4.4.1 样例

假如使用下面的混合先验:
$p(\theta)=0.5Beta(\theta|a_1,b_1)+0.5Beta(\theta|a_2,b_2)$(5.71)

其中$a_1=b_1=20,a_2=b_2=10$.然后观察了$N_1$次的人头,$N_0$次的背面.后验就成了:

$p(\theta|D)=p(Z=1|D)Beta(\theta|a_1+N_1,b_1+N_0)+p(Z=2|D)Beta(\theta|a_2+N_1,b_2+N_0)$(5.72)

如果$N_1=20,N_0=10$,那么使用等式5.23,就得到了后验如下所示:

$p(\theta|D)=0.346Beta(\theta|40,30)+0.654Beta(\theta|50,20)$(5.73)

如图5.10是对此的图示.



此处查看原书图 5.10



#### 5.4.4.2 应用:在DNA和蛋白质序列中找到保留区域(conserved regions)

之前提到过狄利克雷-多项式模型(Dirichlet-multinomial models)在生物序列分析领域用的很广泛.现在就举个例子来看一下.还要用到本书2.3.2.1当中提到的序列标识(sequence logo).现在假设我们想找到基因中代表了编码区域的位置.这类位置在不同的序列中往往都有同样的字母,这是因为进化原因导致的.所以需要找纯净(pure)或者近似纯净的列(columns),比如都是碱基A/T/C/G当中的一种.一种方法是查找低信息熵的列(low-entropy columns)这些列的分布几乎都是确定的.

然后假设我们相对纯净度都估计的置信程度进行衡量.如果我们认为邻近区域是一同保留的,这就很有用了.这时候设置如果区域t是保留的则$Z_t=1$,反之则$Z_t=0$.可以在临近的$Z_t$变量之间加入一个依赖项(dependence),要用一个马尔科夫链(Markov chain),这部分参考本书第17章有详细内容.

无论任何情况,都要定义一个似然率模型(likelihood model)$p(N_t|Z_t)$,其中的$N_t$是第t列的(ACGT)碱基计数组成的向量.通常设置这是一个参数为$\theta_t$的多项式分布.因为每一列(column)都有不同的分布,所以要对$\theta_t$积分,然后计算边缘似然函数:

$p(N_t|Z_t)=\int p(N_t|\theta_t)p(\theta_t|Z_t)d\theta_t  $(5.74)

但是对$\theta_t$用什么先验呢?当$Z_t=0$的时候可以使用一个均匀显眼,即$p(\theta|Z_t=0)=Dir(1,1,1,1)$,可是如果$Z_t=1$呢?如果一列被保留了,就应该是纯粹(或者近似纯粹)由ACGT四种碱基中的一种组成的.很自然的方法就是使用狄利克雷先验的混合,每一个都朝向四维单形(simplex)中的一角倾斜(tilted),即:

$p(\theta|Z_t=1)=\frac14Dir(\theta|(10,1,1,1))+...+\frac14Dor(\theta|(1,1,1,10))$(5.75)

由于这也是共轭的,所以$p(N_t|Z_t)$计算起来很容易.参考(Brown et al. 1993)来查看一个在现实生物序列问题中的具体应用.




## 5.5 分层贝叶斯(Hierarchical Bayes)

计算后验$p(\theta|D)$的一个关键要求就是特定的先验$p(\theta|\eta)$,其中的$\eta$是超参数(hyper-parameters).如果不知道怎么去设置$\eta$咋办呢?有的时候可以使用无信息先验,之前已经说过了.一个更加贝叶斯风格的方法就是对先验设一个先验!用本书第十章的图模型的术语来说,可以用下面的方式来表达:
$\eta \rightarrow \theta \rightarrow D$(5.76)

这就是一个分层贝叶斯模型(hierarchical Bayesian model),也叫作多层模型(multi-level model),因为有多层的未知量.下面给一个简单样例,后文还会有更多其他的例子.

### 5.5.1 样例:与癌症患病率相关的模型

考虑在不同城市预测癌症患病率的问题(这个样例来自Johnson and Albert 1999, p24).具体来说,加入我们要测量不同城市的人口,$N_i$,然后对应城市死于癌症的人口数$x_i$.假设$x_i\sim Bin(N_i,\theta_i)$,然后要估计癌症发病率$\theta_i$.一种方法是分别进行估计,不过这就要面对稀疏数据问题(低估了人口少即$N_i$小的城市的癌症发病率).另外一种方法是假设所有的$\theta_i$都一样;这叫做参数绑定(parameter tying.结果得到的最大似然估计(MLE)正好就是$\hat\theta =\frac{\Sigma_ix_i}{\Sigma_iN_i}$.可是很明显假设所有城市癌症发病率都一样有点太牵强了.有一种折中的办法,就是估计$\theta_i$是相似的,但可能随着每个城市的不同而又发生变化.这可以通过假设$\theta_i$服从某个常见分布来实现,比如$\beta$分布,即$\theta_i\sim Beta(a,b)$.这样就可以把完整的联合分布写成下面的形式:

$p(D,\theta,\eta|N)=p(\eta)\prod^N_{i=1}Bin(x_i|N_i,\theta_i)Beta(\theta_i|\eta)$(5.77)


上式中的$\eta=(a,b)$.要注意这里很重要的一点是要从数据中推测$\eta=(a,b)$;如果只是随便设置成一个常数,那么$\theta_i$就会是有件独立的(conditionally independent),在彼此之间就没有什么信息联系了.与之相反的,若将$\eta$完全看做一个未知量(隐藏变量),就可以让数据规模小的城市从数据规模大的城市借用统计强度(borrow statistical strength).

要计算联合后验$p(\eta,\theta|D)$.从这里面可以得到后验边缘分布$p(\theta_i|D)$.如图5.11(a)所示,图中的蓝色柱状是后验均值$\mathrm{E}[\theta_i|D]$,红色线条是城市人口均值$\mathrm{E}[a/(a+b_|D]$(这代表了$\theta_i$的均值).很明显可以看到后验均值朝向有小样本$N_i$的城市的汇总估计方向收缩.例如,城市1和城市20都观察到有0的癌症发病率,但城市20的人口数较少,所以其癌症发病率比城市1更朝向人口估计方向收缩(也就是距离水平的红色线更近).

图5.11(b)展示的是$\theta_i$的95%后验置信区间.可以看到城市15有特别多的人口(53637),后验不确定性很低.所以这个城市对$\eta$的后验估计的影响最大,也会影响其他城市的癌症发病率的估计.城市10和19有最高的最大似然估计(MLE),也有最高的后验不确定性,反映了这样高的估计可能和先验相违背(先验视从所有其他城市估计得到的).

上面这个例子中,每个城市都有一个参数,然后对相应的概率进行建模.通过设置伯努利分布的频率参数为一个协变量的函数,即$\theta_i=sigm(w^T_ix)$,就可以对多个相关的逻辑回归任务进行建模了.这也叫作多任务学习(multi-task learning),在本书9.5会有详细讲解.

## 5.6 经验贝叶斯(Empirical Bayes)


在分层贝叶斯模型中,我们需要计算多层的潜在变量的后验.例如,在一个两层模型中,需要计算:
$p(\eta,\theta|D)\propto p(D|\theta)p(\theta|\eta)p(\eta)$(5.78)

有的时候可以通过分析将$\theta$边缘化;这就将问题简化成只去计算$p(\eta|D)$了.

作为计算上的简化,可以对超参数后验进行点估计来近似,即$p(\eta|D)\approx \delta_{\hat\eta}(\eta)$,其中的$\hat\eta=\arg\max p(\eta|D)$.因为$\eta$通常在维数上都比$\theta$小很多,这个模型不太容易过拟合,所以我们可以安全地来对$\eta$使用均匀显眼.这样估计就成了:



$\hat\eta =\arg\max p(D|\eta)=\arg\max[\int p(D|\theta)p(\theta|\eta)d\theta]$(5.79)

其中括号里面的量就是边缘似然函数或整合似然函数(marginal or integrated likelihood),也叫证据(evidence).这个方法总体上叫做经验贝叶斯(Empirical Bayes,缩写为EB)或这也叫座第二类最大似然估计(Type II Maximum Likelihood).在机器学习里面,也叫作证据程序(evidence procedure).

经验贝叶斯违反了先验应该独立于数据来选择的原则.不过可以将其视作是对分层贝叶斯模型中的推导的一种近似,计算开销更低.就好比是讲最大后验估计(MAP estimation)看作是对单层模型$\theta\rightarrow D$的推导的近似一样.实际上,可以建立一个分层结构,其中进行的积分越多,就越"贝叶斯化":

|方法(Method)|定义(Definition)|
|---|---|
|最大似然估计(Maximum Likelihood)|$\hat\theta=\arg\max_\theta p(D|\theta)$|
|最大后验估计(MAP estimation)|$\hat\theta=\arg\max_\theta p(D|\theta)p(\theta|\eta)$|
|经验贝叶斯的最大似然估计(ML-II Empirical Bayes)|$\hat\theta=\arg\max_\eta \int p(D|\theta)p(\theta|\eta)d\theta=\arg\max p(D|\eta)$|
|经验贝叶斯的最大后验估计(MAP-II)|$\hat\theta=\arg\max_\eta \int p(D|\theta)p(\theta|\eta)p(\eta)d\theta=\arg\max p(D|\eta)$|
|全贝叶斯(Full Bayes)|$p(\theta,\eta|D)\propto p(D|\theta)p(\theta|\eta)p(\eta)$|


要注意,经验贝叶斯(EB)也有很好的频率论解释(参考Carlin and Louis 1996; Efron 2010),所以在非贝叶斯模型中也被广泛使用.例如很流行的詹姆斯-斯坦因估计器(James-Stein estimator)就是用经验贝叶斯推导的,更多细节参考本书6.3.3.2.


### 5.6.1 样例:$\beta$-二项模型

还回到癌症发病率的模型上.可以积分掉$\theta_i$,然后直接写出边缘似然函数,如下所示:

$$
\begin{aligned}
p(D|a,b)&=\prod_i \int Bin(x_i|N_i,\theta_i)Beta(\theta_i|a,b)d\theta_i  & \text{(5.80)}\\
	&=\prod_i \frac{B(a+x_i,b+N_i-x_i)}{B(a,b)}  & \text((5.81)}\\
\end{aligned}
$$

关于a和b来最大化有很多方法,可以参考(Minka 2000e).

估计完了a和b之后,就可以代入到超参数里面来计算后验分布$p(\theta_i|\hat a,\hat b,D)$,还按照之前的方法,使用共轭分析.得到的每个$\theta_i$的后验均值就是局部最大似然估计(local MLE)和先验均值的加权平均值,依赖于$\eta=(a,b)$;但由于$\eta$是根据所有数据来估计出来的,所以每个$\theta_i$也都受到全部数据的影响.



### 5.6.2 样例:高斯-高斯模型(Gaussian-Gaussian model)

接下来这个例子和癌症发病率的例子相似,不同之处是这个例子中的数据是实数值的(real-valued).使用一个高斯(正态)似然函数(Gaussian likelihood)和一个高斯(正态)先验(Gaussian prior).这样就能写出来解析形式的解.

设我们有来自多个相关群体的数据.比如$x_{ij}$表示的就是学生i在学校j得到的测试分数,j的取值范围从1到D,而i是从1到$N_j$,即$j=1:D,i=1:N_j$.然后想要估计每个学校的平均分$\theta_j$.可是样本规模$N_j$对于一些学校来说可能很小,所以可以用分层贝叶斯模型(hierarchical Bayesian model)来规范化这个问题,也就是假设$\theta_j$来自一个常规的先验(common prior)$N(\mu,\tau^2)$.

这个联合分布的形式如下所示:
$p(\theta,D|\eta,\sigma^2)=\prod^D_{j=1}N(\theta_j|\mu,\tau^2)\prod^{N_j}_{i=1}N(x_{ij}|\theta_j,\sigma^2)$(5.82)

上式中为了简化,假设了$\sigma^2$是已知的.(这个假设在练习24.4中.)接下来将估计$\eta$.一旦估计了$\eta=(\mu,\tau)$,就可以计算$\theta_j$的后验了.要进行这个计算,只需要将联合分布改写成下面的形式,这个过程利用值$x_{ij}$和方差为$\sigma^2$的$N_j$次高斯观测等价于值为$\bar x_j \overset{\triangle}{=} \frac{1}{N_j}\sum^{N_j}_{i=1}x_{ij}$方差为$\sigma^2_j\overset\triangle{=}\sigma^2/N_j$的一次观测这个定理.这就得到了:


$p(\theta,D|\hat\eta,\sigma^2)=\prod^D_{j=1}N(\theta_j|\hat\mu,\hat\tau^2)N(\bar x_j|\theta_j,\sigma^2_j)$(5.83)

利用上面的式子,再利用本书4.4.1当中的结论,就能得到后验为:

$$
\begin{aligned}
p(\theta_j|D,\hat\mu,\hat\tau^2)&= N(\theta_j|\hat B_j\hat\mu+(1-\hat B_j)\bar x_j,(1-\hat B_j)\sigma^2_j)  \text{(5.84)}\\
\hat B_j &\overset{\triangle}{=}  \frac{\sigma^2_j}{\sigma^2_j+\hat\tau^2}\text{(5.85)}\\
\end{aligned}
$$

其中的$\hat\mu =\bar x,\hat\tau^2$下面会给出定义.

$0\le \hat B_j \le 1$这个量控制了朝向全局均值(overall mean)$\mu$的收缩程度(degree of shrinkage).如果对于第j组来说数据可靠(比如可能是样本规模$N_j$特别大),那么$\sigma^2_j$就会比$\tau^2$小很多;因此这样$\hat B_j$也会很小,然后就会在估计$\theta_j$的时候给$\bar x_j$更多权重.而样本规模小的群组就会被规范化(regularized),也就是朝向全局均值$\mu$的方向收缩更严重.接下来会看到一个例子.

如果对于所有的组j来说都有$\sigma_j=\sigma$,那么后验均值就成了:"
$\hat\theta_j= \hat B\bar x+(1-\hat B)\bar x_j=\bar x +(1-\hat B)(\bar x_j-\bar x)$(5.86)

这和本书在6.3.3.2中讨论到的吉姆斯-斯坦因估计器(James Stein estimator)的形式一模一样.

#### 5.6.2.1 样例:预测棒球得分

接下来这个例子是把上面的收缩(shrinkage)方法用到棒球击球平均数(baseball batting averages, 引自 Efron and Morris 1975).观察D=18个求援在前T=45场比赛中的的击球次数.把这个击球次数设为$b_i$.假设服从二项分布,即$b_j\sim Bin(T,\theta_j)$,其中的$\theta_j$是选手j的"真实"击球平均值.目标是要顾及出来这个$\theta_j$.最大似然估计(MLE)自然是$\hat\theta_j=x_j$,其中的$x_j=b_j/T$是经验击球平均值.不过可以用经验贝叶斯方法来进行更好的估计.

要使用上文中讲的高斯收缩方法(Gaussian shrinkage approach),需要似然函数是高斯分布的,即对于一直的$\sigma^2$有$x_j\sim N(\theta_j,\sigma^2)$.(这里去掉了下标i因为假设了$N_j=1$而$x_j$已经代表了选手j的平均值了.)不过这个例子里面用的是二项似然函数.均值正好是$\mathrm{E}[x_j]=\theta_j$,方差则是不固定的:

$var[x_j]=\frac{1}{T^2}var[b_j]=\frac{T\theta_j(1-\theta_j)}{T^2}$(5.87)

所以咱们对$x_j$应用一个方差稳定变换(variance stabilizing transform 5)来更好地符合高斯假设:
$y_i=f(y_i)=\sqrt{T}\arcsin (2y_i-1)$(5.88)

然后应用一个近似$y_i\sim N(f(\theta_j),1)=N(\mu_j,1)$.以$\sigma^2=1$代入等式5.86来使用高斯收缩对$\mu_j$进行估计,然后变换回去,就得到了:

$\hat\theta_j=0.5(\sin(\hat\mu_j/\sqrt{T})+1)$(5.89)



此处查看原书图 5.12

这个结果如图5.12(a-b)所示.在图(a)中,投图的是最大似然估计(MLE)$\hat\theta_j$和后验均值$\bar\theta_j$.可以看到所有的估计都朝向全局均值0.265收缩.在图(b)中,投图的是$\theta_j$的真实值,最大似然估计(MLE)$\hat\theta_j$和后验均值$\bar\theta_j$.(这里的$\theta_j$的真实值是指从更大规模的独立赛事之间得到的估计值.)可以看到平均来看,收缩的估计比最大似然估计(MLE)更加靠近真实值.尤其是均方误差,定义为$MSE=\frac{1}{N}\sum^D_{j=1}(\theta_j-\bar\theta_j)^2$,使用收缩估计的$\bar\theta_j$比最大似然估计的$\hat\theta_j$的均方误差小了三倍.

#### 5.6.2.2 估计超参数

在本节会对估计$\eta$给出一个算法.加入最开始对于所有组来说都有$\sigma^2_j=\sigma^2$.这种情况下就可以以闭合形式(closed form)来推导经验贝叶斯估计(EB estimate).从等式4.126可以得到:
$p(\bar x_j|\mu,\tau^2,\sigma^2)=\int N(\bar x_j|\theta_j,\sigma^2)N(\theta_j|\mu,\tau^2)d\theta_j =N(\bar x_j|\mu,\tau^2+\sigma^2)$(5.90)

然后边缘似然函数(marginal likelihood)为:

$p(D|\mu,\tau^2,\sigma^2)=\prod^D_{j=1}N(\bar x_j|\mu,\tau^2+\sigma^2)$(5.91)

接下来就可以使用对正态分布(高斯分布)的最大似然估计(MLE)来估计超参数了.例如对$\mu$就有:

$\hat \mu =\frac{1}{D}\sum^D_{j=1}\bar x_j=\bar x$(5.92)

上面这个也就是全局均值.

对于方差,可以使用矩量匹配(moment matching,相当于高斯分布的最大似然估计):简单地把模型方差(model varianc)等同于经验方差(empirical variance):

$\hat \tau^2+\sigma^2 =\frac{1}{D}\sum^D_{j]1}(\bar x_j-\bar x)^2\overset{\triangle}{=} s^2$(5.93)

所以有$\hat \tau^2=s^2-\sigma^2$.因为已知了$\tau^2$必然是正的,所以通常都使用下面这个修订过的估计:

$\hat \tau^2=\max(0,s^2-\sigma^2)=(s^2-\sigma^2)_{+}$(5.94)

这样就得到了收缩因子(shrinkage factor):

$\hat B=\frac{\sigma^2}{\sigma^2+\tau^2}=\frac{\sigma^2}{\sigma^2+(s^2-\sigma^2)_{+}}$(5.95)

如果$\sigma^2_j$各自不同,就没办法以闭合形式来推导出解了.练习11.13讨论的是如何使用期望最大化算法(EM algorithm)来推导一个经验贝叶斯估计(EB estimate),练习24.4讨论了如何在这个分层模型中使用全贝叶斯方法.

## 5.7 贝叶斯决策规则(Bayesian decision rule)

之前的内容中,我们已经看到了概率理论可以用来表征和更新我们对客观世界状态的信念.不过我们最终目标是把信念转化成行动.在本节,讲的就是用最有方法来实现这个目的.

我们可以把任何给定的统计决策问题规范表达成一个与自然客观世界作为对手的游戏(而不是和其他的玩家相对抗,和玩家对抗就是博弈论范畴了,可以参考Shoham and Leyton-Brown 2009).在这个游戏中,自然客观世界会选择一个状态/参数/标签,$y\in Y$,对我们来说是未知的,然后生成了一次观察$x\in X$,这是我们看到的.接下来我们就要做出一次决策(decision),也就是要从某个行为空间(action space)中选择一个行动a.最终会得到某种损失(loss),$L(y,a)$,这个损失函数测量了咱们选择的行为a和自然客观世界隐藏的状态y之间的兼容程度.例如,可以使用误分类损失(misclassitication loss)$L(y,a)= I(y\ne a)$,或者用平方误差损失(squared loss)$L(y,a)=(y-a)^2$.接下来是一些其他例子.

我们的目标就是设计一个决策程序或者决策策略(decision procedure or policy)$\delta:X\rightarrow A$,对每个可能的输入指定了最优行为.这里的优化(optimal)的意思就是让行为能够使损失函数期望最小:

$\delta(x)=\arg\min_{a\in A} \mathrm{E}[L(y,a)]$(5.96)

在经济学领域,更常见的属于是效用函数(utility function),其实也就是损失函数取负值,即$U(y,a)=-L(y,a)$.这样上面的规则就成了:

$\delta(x)=\arg\max_{a\in A} \mathrm{E}[U(y,a)]$(5.97)

这就叫期望效用最大化规则(maximum expected utility principle),是所谓理性行为(rational behavior)的本质.

这里要注意"期望(expected)"这个词,是可以有两种理解的.在贝叶斯统计学语境中的意思是给定了已经看到的数据之后,对y的期望值(expected value)后面也会具体讲.在频率论统计学语境中,意思是我们期待在未来看到y和x的期望值,具体会在本书6.3当中讲解.

在贝叶斯决策理论的方法中,观察了x之后的最优行为定义是能后让后验期望损失(posterior expected loss)最小的行为.

$\rho(a|x)\overset{\triangle}{=} E_{p(y|x)} [L(y,a)]=\sum_y L(y,a)p(y|x)$(5.98)

(如果y是连续的,比如想要估计一个参数向量的时候,就应该把上面的求和替换成为积分.)这样就有了贝叶斯估计器(Bayes estimator),也叫做贝叶斯决策规则(Bayes decision rule):

$\delta(x)=\arg\min_{a\in A}\rho(a|x)$(5.99)

### 5.7.1 常见损失函数的贝叶斯估计器

这一节我们展示了对一些机器学习中常遇到的损失函数如何构建贝叶斯估计器.

#### 5.7.1.1 最大后验估计(MAP estimate)最小化0-1损失

0-1损失(0-1 loss)的定义是:
$L(y,a)=I(y\ne a)=\begin{cases} 0 &\text{if} &a=y\\ 1 &\text{if} &a\ne y\end{cases}$(5.100)

这通常用于分类问题中,其中的y是真实类标签(true class label),而$a=\hat y$是估计得到的类标签.

例如,在二分类情况下,可以写成下面的损失矩阵(loss matrix):

||\hat y=1|\hat y=0|
|---|---|---|
|y=1|0|1|
|y=0|1|0|



此处查看原书图 5.13

(在本书5.7.2,会把上面这个损失函数进行泛化,就可以应用到对偏离对角位置的两种错误的惩罚上了.)

后验期望损失为:

$\rho(a|x)=p(a\ne y|x)=1-p(y|x)$(5.101)

所以能够最小化期望损失的行为就是后验众数(posterior mode)或者最大后验估计(MAP estimate):

$y^\triangle(x)=\arg\max_{y\in Y} p(y|x)$(5.102)

#### 5.7.1.2 拒绝选项(Reject option)
在分类问题中,$p(y|x)$是非常不确定的,所以我们可能更倾向去选择一个拒绝行为(reject action),也就是拒绝将这个样本分类到任何已有的指定分类中,而是告知"不知道".这种模糊情况可以被人类专家等来处理,比如图5.13所示.对于风险敏感的领域(risk averse domains)比如医疗和金融等,这是很有用处的.

接下来讲这个拒绝选项用正规化语言表达一下.设选择一个$a=C+1$对应的就是选择了拒绝行为,然后选择$a\in \{1,...,C\}$对应的就是分类到类标签中去.然后就可以定义下面的损失函数:

$L(y=j,a=i)=\begin{cases} 0 &\text{if} &i=j & i,j \in\{1,...,C\}\\ \lambda_r &\text{if} &i=C+1 \\ \lambda_s &\text{otherwise}\end{cases}$(5.103)

此处查看原书图 5.14


#### 5.7.1.3 后验均值(Posterior mean)最小化$l_2$(二次)损失函数

对于连续参数,更适合使用的损失函数是平方误差函数(squared error),也成为$l_2$损失函数,或者叫二次损失函数(quadratic loss),定义如下:

$L(y,a)=(y-a)^2$(5.104)
后验期望损失为:

$\rho(a|x)=\mathrm{E}[(y-a)^2|x|]=\mathrm{E}[y^2|x]-2a\mathrm{E}[y|x]+a^2$(5.105)

这样最优估计就是后验均值:

$\frac{\partial}{\partial a}\rho(a|x)= -2\mathrm{E}[y|x]+2a=0  \Longrightarrow \hat y=\mathrm{E}[y|x]=\int y p(y|x)dy$(5.106)

这也叫做最小均值方差估计(minimum mean squared error,缩写为MMSE).

在线性回归问题中有:

$p(y|x,\theta)=N(y|x^Tw,\sigma^2)$(5.107)

这时候给定某个训练集D之后的最优估计就是:

$\mathrm{E}[y|x,D]=x^T\mathrm{E}[w|D]$(5.108)

也就是将后验均值参数估计代入.注意不论对w使用什么样的先验,这都是最优选择.


#### 5.7.1.4 后验中位数(Posterior median)最小化$l_1$(绝对)损失函数

$l_2$(二次)损失函数以二次形式惩罚与真实值的偏离,因此对异常值(outliers)特别敏感.所以有一个更健壮的替换选择,就是绝对损失函数,或者也叫做$l_1$损失函数$L(y,a)=|y-a|$(如图5.14所示).这里的最优估计就是后验中位数,也就是使得$P(y < a|x) = P(y \ge a|x) = 0.5$的a值,具体证明参考本书练习5.9.


#### 5.7.1.5 监督学习(Supervised learning)

设想有一个预测函数$\delta: X\rightarrow Y$,然后设有某个损失函数$l(y,y')$,这个损失函数给出了预测出$y'$而真实值是$y$的时候的损失.这样就可以定义采取行为$\delta$(比如使用这个预测器)而未知自然状态为$\theta$(数据生成机制的参数)的时候的损失:

$L(\theta,\delta)\overset{\triangle}{=} E_{(x,y) \sim p(x,y|\theta)}[l(y,\delta(x)]=\sum_x\sum_y L(y,\delta(x))p(x,y|\theta)$(5.109)

这就是泛化误差(generalization error).咱们的目标是最小化后验期望损失,即:

$\rho(\delta|D)=\int p(\theta|D)L(\theta,\delta)d\theta$(5.110)

这和公式6.47当中定义的频率论中的风险(risk)相对应.

### 5.7.2 假阳性和假阴性的权衡

本章关注的是二分类决策问题(binary decision problems),比如假设检验(hypothesis testing),二分类,对象事件监测等等.这种情况下就有两种错误类型:假阳性(false positive,也叫假警报false alarm),就是我们估计的$\hat y=1$而实际上真实的是$y=0$;或者就是假阴性(false negative,也叫做漏检测missed detection),就是我们估计的是$\hat y=0$而实际上真实的是$y=1$.0-1损失函数同等对待这两种错误.可以用下面这个更通用的损失矩阵来表征这种情况:


||\hat y=1|\hat y=0|
|---|---|---|
|y=1|0|$L_{FN}$|
|y=0|$L_{FP}$|0|


上面的$L_{FN}$就是假阴性的损失,而$L_{FP}$是假阳性的损失.两种可能性微的后验期望损失为:

$$
\begin{aligned}
\rho(\hat y=0|x)&= L_{FN} p(y=1|x) &\text{(5.111)}\\
\rho(\hat y=1|x)&= L_{FP} p(y=0|x) &\text{(5.112)}\\
\end{aligned}
$$

因此应选$\hat y=1$ 当且仅当:

$$
\begin{aligned}
\rho(\hat y=0|x) &>  \rho(\hat y=1|x)&\text{(5.113)}\\
\frac{p(y=1|x) }{p(y=0|x) }&>\frac{L_{FP}}{L_{FN}}  &\text{(5.114)}\\
\end{aligned}
$$


如果$L_{FN}=cL_{FP}$,很明显(如练习5.10所示)应该选$\hat y=1$,当且仅当$p(y=1|x)/p(y=0|x)> \tau$,其中的$\tau=c/(1+c)$(更多细节参考 Muller et al. 2004).例如,如果一个假阴性的损失是假阳性的两倍,就设$c=2$,然后在宣称预测结果为阳性之前要先使用一个2/3的决策阈值(decision threshold).

接下来要讨论的是ROC曲线,这种方式提供了学习FP-FN权衡的一种方式,而不用必须去选择特定的阈值设置.

#### 5.7.2.1 ROC 曲线以及相关内容

||真实1| 真实0|$\Sigma$|
|---|---|---|---|
|估计1|TP真阳性|FP假阳性|$\hat N_{+} =TP+FP$|
|估计0|FN假阴性|TN真阴性|$\hat N_{-} =FN+TN$|
|$\Sigma$|$N_{+} =TP+FN$|$N_{-}=FP+TN$|$N = TP + FP + FN + TN$|


表5.2 从混淆矩阵(confusion matrix)可推导的量.$N_+$是真阳性个数,$\hat N_{+}$是预测阳性个数,$N_-$是真阴性个数,$\hat N_{-}$是预测阴性个数.

||$y=1$|$y=0$|
|---|---|---|
|$\hat y=1$|$TP/N_+=TPR=sensitivity=recall$ |$FP/N_− =FPR=type I$ |
|$\hat y=0$|$FN/N_+ =FNR=miss rate=type II$|$TN/N_− =TNR=speciﬁty$|


表5.3 从一个混淆矩阵中估计$p(\hat y|y)$.缩写解释:FNR = false negative rate 假阴性率, FPR = false positive rate 假阳性率, TNR = true negative rate 真阴性率, TPR = true positive rate 真阳性率.


如果$f(x)>\tau$是决策规则,其中的$f(x)$是对$y=1$(应该与$p(y = 1|x)$单调相关,但不必要是概率函数)的信心的衡量,$\tau$是某个阈值参数.对于每个给定的$\tau$值,可以应用局Ce规则,然后统计真阳性/假阳性/真阴性/假阴性的各自出现次数,如表5.2所示./这个误差表格也叫作混淆矩阵(confusion matrix).

从这个表中可以计算出真阳性率(TPR),也叫作敏感度(sensitivity)/识别率(recall)/击中率(hit rate),使用$TPR = TP/N_+ \approx p(\hat y = 1|y = 1)$就可以计算得到.还可以计算假阴性率(FPR),也叫作误报率(false alarm rate)/第一类错误率(type I error rate),利用$FPR = FP/N_− \approx p(\hat y = 1|y = 0)$.这些定义以及相关概念如表格5.3和5.4所示.在计算损失函数的时候可以任意组合这些误差.

不过,与其使用某个固定阈值$\tau$来计算真阳性率TPR和假阳性率FPR,还不如使用一系列的阈值来运行监测器,然后投影出TPR关于FPR的曲线,作为$\tau$的隐含函数.这也叫受试者工作特征曲线(receiver operating characteristic curve，简称ROC曲线),又称为感受性曲线(sensitivity curve),如图5.15(a)就是一例.任何系统都可以设置阈值为1即$\tau =1$来实现左下角的点(FPR = 0, TPR = 0),这样也就是所有的都分类成为阴性了;类似的也可以设置阈值为0即$\tau =0$,都跑到右上角去,即(FPR = 1, TPR = 1),也就是都分类成阳性.如果一个系统在概率层面(chance level)上运行,就可以通过选择适当阈值来实现对角线上的$TPR = FPR$的任一点.一个能够完美区分开阴性阳性的系统的阈值可以使得整个出在图的左上方,即(FPR = 0, TPR = 1);通过变换阈值,这样的系统就可以从左边的轴移动到顶部轴,如图5.15(a)所示.

一个ROC曲线的质量通常用一个单一数值来表示,也就是曲线所覆盖的面积(area under the curve,缩写为AUC).AUC分数越高就越好,最大的显然就是1了.另外一个统计量是相等错误率(equal error rate,缩写为EER),也叫做交错率(cross over rate),定义是满足FPR = FNR的值.由于FNR=1-TPR,所以可以画一条线从左上角到右下角然后看在哪里切穿ROC曲线就是了(参考图5.15(a)中的A和B两个点).EER分数越低越好,最小显然就是0.



此处查看原书图 5.15

||$y=1$|$y=0$|
|---|---|---|
|$\hat y=1$|$TP/\hat N_+=precision =PPV$ |$FP/\hat N_+ =FDP$ |
|$\hat y=0$|$FN/\hat N_-$|$TN/\hat N_− =NPV$|


表5.4 从一个混淆矩阵中估计的量.缩写解释:FDP = false discovery probability 错误发现概率, NPV = negative predictive value 阴性预测值, PPV = positive predictive value阳性预测值.

#### 5.7.2.2 精确率-识别率曲线(Precision recall curves)

探测小概率的罕见事件(比如检索相关文档或在图中查找面孔)时候,阴性结果的数量会非常大.这样再去对比真阳性率$TPR = TP/N_+$和假阳性率$FPR = FP/N_−$就没啥用处了,因为假阳性率FPR肯定会很小的.因此在ROC曲线上的所有行为都会出现在最左边.这种情况下,通常就把真阳性率TPR和假阳性个数投一个曲线,而不用假阳性率FPR.

不过有时候"阴性(negative)"还不太好定义.例如在图像中探测一个对象(参考本书1.2.1.3),如果探测器通过批量分块来进行探测,那么分块检验过的数目,也就是真阴性的数目,是算法的一个参数,而并不是问题本身定义的一部分.所以就要用一个只涉及阳性的概念来衡量.(注:这样就是问题定义控制的,而不是算法决定了.)

精确率(precision)的定义是$TP/\hat N_+ =p(y=1|\hat y=1)$,识别率(recall)的定义是$TP/N_+ =p(\hat y=1|y=1)$.精确率衡量的是检测到的阳性中有多大比例是真正的阳性,而识别率衡量的是在阳性中有多少被我们检测到了.如果$\hat y_i \in \{0,1\}$是预测的分类标签,而$y_i \in \{0,1\}$是真实分类标签,就可以估计精确率和识别率,如下所示:

$P=\frac{\sum_i y_i\hat y_i}{\sum_i \hat y _i},  R= \frac{\sum_iy_i\hat y_i}{\sum_i y_i}$(5.115)

精确率-识别率曲线(precision recall curves)就是随着阈值参数$\tau$的变化对精确率与识别率直接的关系投图得到的曲线.如图5.15(b)所示.在图中曲线尽量往右上角去就好了.

这个曲线可以用一个单一数值来概括,也就是均值精确率(mean precision,在识别到的值上求平均值),近似等于曲线下的面积.或者也可以用固定识别率下的精确率来衡量,比如在前K=10个识别到的项目中的精确率.这就叫做在K分数(K score)的平均精确率.这个指标在评估信息检索系统的时候用得很广.

||Class 1|||Class 2|||Pooled||
|---|---|---|---|---|---|---|---|---|
||$y=1$|$y=0$||$y=1$|$y=0$||$y=1$|$y=0$|
|$\hat y=1$|10|10|$\hat y=1$|90|10|$\hat y=1$|100|20|
|$\hat y=0$|10|970|$\hat y=0$|10|890|$\hat y=0$|20|1860|


表5.5 展示了宏观和微观平均的区别.y是真实类别标签,$\hat y$是名义标签(called label).在这个样例里面,宏观平均精确率是$[10/(10 + 10) + 90/(10 + 90)]/2 = (0.5 + 0.9)/2 = 0.7$.微观平均精确率是$100/(100 + 20) \approx 0.83$.此表参考了(Manning et al. 2008)的表格13.7.



#### 5.7.2.3 F分数(F-scores)*

对于固定阈值,可以计算单个的精确率和识别率的值.然后可以用这些值来计算出一个单个的统计量,就是F分数(F score),也叫做$F_1$分数($F_1$ score),是精确率和识别率的调和均值(harmonic mean):

$F_1 \overset{\triangle}{=} \frac{2}{1/P+1/R} =\frac{2PR}{R+P}$(5.116)

使用等式5.115,就可以把上面的式子写成下面的形式:

$F_1 =\frac{2\sum^N_{i=1}y_i \hat y_i}{\sum^N_{i=1}y_i+\sum^N_{i=1}\hat y_i}$(5.117)

这个量在信息检索测量里面用得很广泛.

要理解为啥用调和均值(harmonic mean)而不用算数均值(arithmetic mean)$(P + R)/2$,可以考虑下面的情况.设识别了全部的项目,也就是识别率$R=1$.精确率可以通过有效率(prevalence)$p(y=1)$来得到.加入有效率很低,比如$p(y=1)=10^{-4}$.这时候P和R的算数均值为$(P + R)/2 = (10^{−4} + 1)/2 \approx 50\%$.与之相对,调和均值则为$\frac{2\times 10^{-4}\times 1}{1+10^{-4}}\approx 0.2\%$.

在多类情况下(比如文档分类问题),有两种办法来泛化$F_1$分数.第一种就叫宏观平均F1分数(macro-averaged F1),定义是$\sum^C_{c=1}F_1(c)/C$,其中的$F_1(c)$是将类别c与其他分类区分开这个过程的F1分数.另一重定义叫微观平均F1分数(micro-averaged F1),定义是将每个类的情形分析表(contingency table)集中所有计数的F1分数.

表5.5给出了一个样例,可以比对这两种平均F1分数的区别.可见类别1的精确率是0.5,类别2是0.9.宏观平均精确率就是0.7,而微观平均精确率是0.83.后面这个更接近类别2的精确率而远离类别1的精确率,这是因为类别2是类别1的五倍.为了对每个类给予同样的权重,就要用宏观平均.


#### 5.7.2.4 错误发现率(False discovery rates)*

假设要用某种高通量(high throughput)测试设备去发现某种罕见现象,比如基因在微观上的表达,或者射电望远镜等等.就需要制造很多二进制决策.形式为$p(y_i =1|D)>\tau$,其中的$D=\{x_i\}^N_{i=1}$,N 可能特别大.这种情况也叫做多重假设检验(multiple hypothesis testing).要注意这和标准的二分类问题的不同之处在于是要基于全部数据而不仅仅是$x_i$来对$y_i$进行分类.所以这是一个同时分类问题(simultaneous classiﬁcation problem),这种问题下我们就希望能比一系列独立分类问题有更好的效果.

该怎么设置阈值$\tau$呢?很自然的方法是尽量降低假阳性的期望个数.在贝叶斯方法中,可以用下面的方式计算:
$FD(\tau,D)\overset{\triangle}{=} \sum_i (1-p_i)I(p_i>\tau)$(5.118)
$(1-p_i): pr. error$
$I(p_i>\tau): discovery$

其中的$p_i\overset\triangle{=}p(y_i=1|D)$是你对目标物体会表现出问题中情形的信心.用如下方式定义后验期望错误发现率(posterior expected false discovery rate):

$FDR(\tau,D)\overset{\triangle}{=} FD(\tau ,D)/N(\tau,D)$(5.119)

上式中的$N(\tau,D)=\sum_i I(p_i>\tau)$,是发现项目数.给定一个理想的错误发现率(FDR)的容忍度(tolerance),比如$\alpha =0.05$,就可以调整$\tau$来实现这个要求l这也叫做控制错误发现率(FDR)的直接后验概率手段(direct posterior probability approach),参考(Newton et al. 2004; Muller et al. 2004).

为了控制错误发现率FDR,更有帮助对方法是联合起来估计各个$p_i$(比如可以使用本书5.5当中提到的分层贝叶斯模型),而不是单独估计.这样可以汇集统计强度,从而降低错误发现率(FDR).更多内容参考(Berry and Hochberg 1999).

### 5.7.3 其他话题*

这一部分讲一点和贝叶斯决策规则相关的其他主题.这就没地方去详细讲了,不过也都给出了参考文献啥的,读者可以自己去进一步学习.

#### 5.7.3.1 情境强盗(Contextual bandits)

单臂强盗(one-armed bandit)是对老虎机(slot machine)的俗称,这东西在赌场中很常见.游戏是这样的:你投进去一些钱,然后拉动摇臂,等到机器停止运转;如果你很幸运,就会赢到钱.现在加入有K个这样的机器可选.那你该选哪个呢?这就叫做一个多臂强盗(multi-armed bandit),就可以用贝叶斯决策理论来建模了:有K个可能的行为,然后每个都有位置的奖励(支付函数,payoff function)$r_k$.建立并维护一个置信状态(belief state)$p(r_{1:K}|D)=\prod_k p(r_k|D)$,就可以推出一个最优策略了;这可以通过编译成一系列的吉廷斯指数(Gittins Indices ,参考 Gittins 1989).这个优化解决了探索-利用之间的权衡(exploration-exploitation tradeoff),这一均衡决定了在决定随着胜者离开之前要将每个行为尝试多少次.

然后考虑扩展情况,每个摇臂以及每个玩家,都有了一个对应的特征向量;就叫x吧.这个情况就叫做情境强盗(contextual bandit 参考Sarkar 1991; Scott 2010; Li et al. 2011).比如这里的手臂可以指代要展示给用户的广告或者新闻文章,而特征向量表示的是这些广告或者文章的性质,比如一个词汇袋,也可以表示用户的性质,比如人口统计信息.如果假设奖励函数有一个线性模型,$r_k=\theta ^T_k x$,就可以构建一个每个摇臂的参数的分布$p(\theta_k|D)$,其中的D是一系列的元组(tuples),形式为$(a,x,r)$,制定对应的要比是否被拉动,以及其他特征是什么,还有就是输出的结果是什么(如果用户点击广告了就令$r=1$,否则令$r=0$).后面的章节中,我们会讲从线性和逻辑回归模型来计算$p(\theta_k|D)$的各种方法.

给定了一个后验,我们必须决定对应采取的行动.常见的一种期发放时,也叫做置信上界(upper confidence bound,缩写为UCB)的思路是要采取能够将下面这个项目最大化的行为:

$K^\overset\triangle{=}\arg\max^K_{k=1}\mu_k +\lambda\sigma_k$(5.120)

上式中$\mu_k=\mathrm{E}[r_k|D],\sigma_k^2=var[r_k|D]$,而$\lambda$是一个调节参数,在探索(exploration)和利用(exploitation)之间进行权衡.指关节度就是应该选择我们觉得会有好结果的行为($\mu_k$大),以及/或者选择我们不太确定的行为($\sigma_k$大).

还有个更简单的方法,叫做汤姆森取样(Thompson sampling),如下所述.每一步都选择一个概率等于成为最优行为选择概率的行为k:

$p_k =\int I( \mathrm{E}[r|a,x,\theta]=\max _{a'} \mathrm{E}[r|a',x,\theta])p(\theta|D)d\theta$(5.121)

可以简单地从后验$\theta_t\sim p(\theta|D)$中取出单一样本来对此进行估计,然后选择$k^* =\arg\max_k \mathrm{E}[r|x,k,\theta^t]$.这个方法不仅简单,用起来效果还不错(Chapelle and Li 2011).

#### 5.7.3.2 效用理论(Utility theory)

假设你是一个医生,要去决定是不是对一个病人做手术.设想这个病人有三种状态:没有癌症/罹患肺癌/罹患乳腺癌.由于行为和状态空间都是连续的,就可以按照下面这个损失矩阵(loss matrix)来表达损失函数$L(\theta,a)$:

||做手术|不做手术|
|---|---|---|
|没有癌症|20|0|
|肺癌|10|50|
|乳腺癌|10|60|

这些数字表明,当病人有癌症的时候不去做手术是很不好的(取决于不同类型的癌症,损失在50-60),因为病人可能因此而去世;当病人没有患上癌症的时候不进行手术就没有损失(0);没有癌症还手术就造成了浪费(损失为20);而如果患上了癌症进行手术虽然痛苦但必要(损失10).

很自然咱们要去考虑一下这些数字是从哪里来的.本质上这些数字代表了一个冒险医生的个人倾向或者价值观,甚至可能有点任意性:有的人可能喜欢巧克力冰淇淋,而有人喜欢香草口味,这类情况下并没有正确/损失/效用函数等等.可是也有研究(DeGroot 1970)表明,任意一组的持续倾向都可以转换成一个标量的损失/效用函数.这里要注意,这个效用可以用任意的尺度来衡量,比如美元啊等等,反正只和对应情况下有影响的值相关.



#### 5.7.3.3 序列决策理论(Sequential decision theory)

之前我们讲的都是单次决策问题(one-shot decision problems),就是每次都是做出一个决策然后就游戏结束了.在本书10.6,我们会把这个繁华到多阶段或者序列化的决策问题上.这些问题在很多商业和工程背景下都会出现.这些内容和强化学习的内容紧密相关.不过这方面的进一步讨论超出了本书的范围了.




练习略.


# MLAPP 读书笔记 - 06 频率论统计(Frequentist statistics)

> A Chinese Notes of MLAPP，MLAPP 中文笔记项目 
https://zhuanlan.zhihu.com/python-kivy

记笔记的人：[cycleuser](https://www.zhihu.com/people/cycleuser/activities)

2018年06月09日10:03:31

## 6.1 概论

第五章中讲的都是贝叶斯统计学(Bayesian statistics).贝叶斯统计学被一些人认为有争议,不过在非统计学领域,贝叶斯统计的应用却没什么争议,比如医疗诊断(本书2.2.3.1)/垃圾邮件过滤(本书3.4.4.1)/飞机追踪(本书18.2.1)等.反对者的理由与统计模型参数和其他未知量之间的区别有关.

然后就有人做出尝试,去避免把参数当作随机变量来推导统计学方法,这样就不需要使用先验和贝叶斯规则了.这种统计学就是频率论统计学(frequentist statistics),也叫经典统计学(classical statistics)或者正统统计学(orthodox statistics).这种统计学不是基于后验分布(posterior distribution),而是基于抽样分布(sampling distribution)的概念.这种分布中,估计器(estimator)在用于不同的数据集的时候,从真实的未知分布中进行抽样,具体细节参考本书6.2.重复试验的变化的概念就构成了使用频率论方法来对不确定性建模的基础.

相比之下,在贝叶斯方法中,只接受被实际观察的数据,而并没有重复测试的概念.这就允许贝叶斯方法用于计算单次事件的概率,比如在本书2.1中讲的.另一方面可能更重要,就是贝叶斯方法能避免一些困扰了频率论方法的悖论(参考本书6.6).不过总还是要熟悉一下频率论的(尤其是本书的6.5),因为这种方法在机器学习中应用也很广泛的.

## 6.2 一个估计器的抽样分布(Sampling distribution of an estimator)

在频率论统计学中,参数估计$\hat\theta$是通过对某个数据集D来使用一个估计器(estimator)$\delta$而计算得到的,也就是$\hat\theta=\delta(D)$.这里参数被当做固定的,而数据可以是随机的,正好和贝叶斯方法中的完全相反.参数估计的不确定性可以通过计算估计器的抽样分布(sampling distribution)来衡量.要理解这个概念,可以设想从来自某个真实模型($p(*|\theta^*)$)的多个不同的数据集$D^{(s)}$中抽样,设$D^{(s)}= \{x_i^{(s)}\}^N_{i=1}$,其中$x_i^{s}\sim p(*|\theta^*)$,而$\theta^*$是真实参数.而$s=1:S$是对抽样数据集的索引,而N是每一个这样的数据集的规模.然后将估计器$\hat\theta(*)$用于每个$D^{(s)}$来得到一系列的估计$\{\hat\theta(D^{(s)}\}$.然后设$S\rightarrow \infty$,$\hat\theta(*)$就是估计器的抽样分布.接下来的章节中我们会介绍很多种应用这个抽样分布的方法.不过首先还是展示两种方法来计算这个抽样分布本身.


此处查看原书图 6.1

### 6.2.1 Bootstrap

Bootstrap是一种简单的蒙特卡罗方法,来对抽样分布进行近似.在估计器是真实参数的复杂函数的情况下特别有用.

这种方法的思想很简单.如果我们知道了真实参数$\theta(*)$,就可以声称很多个,比如S个假的数据结构,每个规模都是N,都是来自于真实分布$x^s_i \sim p(*|\theta^*)$,其中$s=1:S,i=1:N$.然后就可以从每个样本来计算估计器$\hat\sigma^s =f(x^s_{1:N})$,然后使用所得样本的经验分布作为我们对抽样分布的估计。由于$\theta$是未知的,参数化Bootstrap方法的想法是使用$\theta(D)$作为替代来生成样本.另一种方法叫非参数化的Bootstrap方法,是对$x_i^s$从原始数据D中进行可替代抽样,然后按照之前的方法计算诱导分布(induced distribution).有的方法可以在大规模数据集的场景下对Bootstrap进行加速,具体参考 (Kleiner et al. 2011).

图6.1展示了一例,其中使用了参数化Bootstrap来计算一个伯努利分布的最大似然估计(MLE)的抽样分布.(使用非参数化Bootstrap的结果本质上是相同的.)可以看到,当N=10的时候,抽样分布是不对称的,所以很不像高斯分布;而当N=100的时候,这个分布就看上去更像高斯分布了,也正如下文中所述的.

很自然的一个问题是:使用Bootstrap计算出来的参数估计器$\theta^s =\hat\theta(x^s_{1:N})$和采用后验分布抽样得到的参数值$\theta^s\sim p(*|D)$有啥区别呢?
概念上两者很不一样,不过一般情况下,在先验不是很强的时候,这两者可能很相似.例如图6.1(c-d)所示就是一例,其中使用了均匀$\beta$分布$Beta(1,1)$作为先验来计算的后验,然后对其进行抽样.从图中可以看出后验和抽样分布很相似.所以有人可能就认为Bootstrap分布就可以当做是"穷人的"后验;更多内容参考(Hastie et al. 2001, p235).

然而很悲伤,Bootstrap可能会比后验取样要慢很多.原因就是Bootstrap必须对模型拟合S次,而在后验抽样中,通常只要对模型拟合一次(来找到局部众数,local mode),然后就可以在众数周围进行局部探索(local exploration).这种局部探索(local exploration)通常要比从头拟合模型快得多.

### 6.2.2 最大似然估计(MLE)的大样本理论(Large sample theory)

有时候有的估计器(estimator)的抽样分布可以以解析形式计算出来.比如在特定条件下,随着抽样规模趋向于无穷大,最大似然估计(MLE)的抽样分布就成了高斯分布了.简单来说,要得到这个结果,需要模型中每个参数都能"观察"到无穷多个数据量,然后模型还得是可识别的(identifiable).很不幸,这种条件是很多机器学习中常用模型都无法满足的.不过咱们还是可以假设一个简单的环境,使定理成立.

这个高斯分布的中心就是最大似然估计(MLE)$\theta$了.但方差是啥呢?直觉告诉我们这个估计器的方差可能和似然函数面(likelihood surface)的峰值处的曲率(curvature)有关(也可能是负相关).如果曲率很大,峰值那里就很陡峭尖锐,方差就小;这时候就认为这个估计确定性好(well determined).反之如果曲率很小,峰值就几乎是平的,那方差就大了去了.

咱们将这种直观感受用正规数学语言表达一下.定义一个得分函数(score function),也就是对数自然函数在某一点$\theta$处的梯度(gradient):

$s(\hat\theta)\overset{\triangle}{=} \nabla \log p(D|\theta)|_{\hat\theta}$(6.1)

把负得分函数(negative score function)定义成观测信息矩阵(observed information matrix),等价于负对数似然函数(Negative Log Likelihood,缩写为NLL)的海森矩阵(Hessian):

$J(\hat\theta(D))\overset{\triangle}{=} -\nabla s(\hat\theta)=-\nabla^2_\theta \log p(D|\theta)|_{\hat \theta}$(6.2)

在1维情况下,就成了:

$J(\hat\theta(D))=-\frac{d}{d\theta^2}\log p(D|\theta)|_{\hat\theta}$(6.3)

这就是对对数似然函数在点$\hat\theta$位置曲率的一种度量了.

由于我们要研究的是抽样分布,$D=(x_1,...,x_N)$是一系列随机变量的集合.那么费舍信息矩阵(Fisher information matrix)定义就是观测信息矩阵(observed information matrix)的期望值(expected value):

$I_N(\hat\theta|\theta^*) \overset{\triangle}{=}  \mathrm{E}_{\theta^*}[J(\hat\theta|D)]$(6.4)

其中的$ \mathrm{E}_{\theta^*}[f(D)] \overset{\triangle}{=} \frac{1}{N} \sum^N_{i=1}f(x_i)p(x_i|\theta^*)$ 是将函数f用于从$\theta^*$中取样的数据时的期望值.通常这个$\theta^*$表示的都是生成数据的"真实参数",假设为已知的,所以就可以缩写出$I_N(\hat\theta)\overset{\triangle}{=} I_N(\hat\theta|\theta^*)$.另外,还很容易就能看出$I_N(\hat\theta)=NI_1(\hat\theta)$,因为规模为N的样本对数似然函数自然要比规模为1的样本更加"陡峭(steeper)".所以可以去掉那个1的下标(subscript),然后就只写成$I_N(\hat\theta)=I_1(\hat\theta)$.这是常用的表示方法.

然后设最大似然估计(MLE)为$\hat\theta \overset{\triangle}{=}\hat\theta_{mle}(D)$,其中的$D\sim\theta^*$.随着$N \rightarrow \infty$,则有(证明参考Rice 1995, p265)):

$\hat\theta \rightarrow N((\theta^*,I_N(\theta^*)^{-1})$(6.5)

我们就说这个最大似然估计(MLE)的抽样分布是渐进正态(asymptotically normal)的.

那么最大似然估计(MLE)的方差呢?这个方差可以用来衡量对最大似然估计的信心量度.很不幸,由于$\theta^*$是位置的,所以咱们不能对抽样分布的方差进行估计.不过还是可以用$\hat\theta$替代$\theta^*$来估计抽样分布.这样得到的$\hat\theta_k$近似标准差(approximate standard errors)为:

$\hat{se}_k \overset{\triangle}{=} I_N(\hat\theta)_{kk}^{-\frac{1}{2}}$(6.6)

例如,从等式5.60就能知道一个二项分布模型(binomial sampling model)的费舍信(Fisher information)为:

$I(\theta)=\frac{1}{\theta(1-\theta)}$(6.7)

然后最大似然估计(MLE)的近似标准差(approximate standard error)为:

$\hat{se} = \frac{1}{\sqrt{I_N(\hat\theta)}} = \frac{1}{\sqrt{NI(\hat\theta)}}=(\frac{\hat\theta (1-\hat\theta)}{N})^{\frac{1}{2}}$(6.8)

其中$\hat\theta =\frac{1}{N}\sum_iX_i$.可以对比等式3.27,即均匀先验下的后验标准偏差(posterior standard deviation).


## 6.3 频率论决策理论(Frequentist decision theory)

在频率论或者所为经典决策理论中,有损失函数和似然函数,但没有先验,也没有后验,更没有后验期望损失(posterior expected loss)了.因此和贝叶斯方法不同,频率论方法中没有办法来自动推导出一个最优估计器.在频率论方法中,可以自由选择任意的估计器或者决策规则$\delta:X\rightarrow A$.
选好了估计器,就可以定义对应的期望损失(expected loss)或者风险函数(risk),如下所示:
$R(\theta^*,\delta)\overset{\triangle}{=} \mathrm{E} _{p(\tilde D|\theta^*)}[L(\theta^*,\delta(\tilde D))=\int L(\theta^*,\delta(\tilde D))p(\tilde D|\theta^*)d\tilde D]$(6.9)

上式中的$\tilde D$是从"自然分布(nature’s distribution)"抽样的数据,用参数$\theta^*$来表示.也就是说,期望值是估计量大抽样分布相关的.可以和贝叶斯后验期望损失(Bayesian posterior expected loss:)相比:

$\rho(a|D,\pi) \overset{\triangle}{=}  \mathrm{E}[L(\theta,a)]=\int_\Theta L(\theta,a)p(\theta|D,\pi)d\theta  $(6.10)

很明显贝叶斯方法是在位置的$\theta$上进行平均,条件为已知的D,而频率论方法是在$\tilde D$上平均,(也就忽略了观测值),而条件是未知的$\theta^*$.


这种频率论的定义不光看着很不自然,甚至根本就没办法计算,因为$\theta^*$都不知道.结果也就不能以频率论的风险函数(frequentist risk)来对比不同的估计器了.接下来就说一下对这个问题的解决方案.

### 6.3.1 贝叶斯风险

怎么挑选估计器呢?我们需要把$R(\theta^*,\delta)$转换成一个不需要依赖$\theta^*$的单独量$R(\delta)$.一种方法是对$\theta^*$设一个先验,然后定义一个估计器的贝叶斯风险(Bayes risk)或者积分风险(integrated risk),如下所示:

$R_B(\delta) \overset{\triangle}{=}  \mathrm{E}_{p(\theta^*)}[R(\theta^*,\delta)]=\int R(\theta^*,\delta)p(\theta^*)d \theta^*$(6.11)

贝叶斯估计器(Bayes estimator)或者贝叶斯决策规则(Bayes decision rule)就是将期望风险最小化:
$\delta_B \overset{\triangle}{=} \arg\min_\delta R_B(\delta)$(6.12)

要注意这里的积分风险函数(integrated risk)也叫做预制后验风险(preposterior risk),因为实在看到数据之前得到的.对此最小化有助于实验设计.

接下来有一个重要定理,这个定理将贝叶斯方法和频率论方法一起结合到了决策理论中.

#### 定理6.31

贝叶斯估计器可以通过最小化每个x的后验期望损失(posterior expected loss)而得到.

证明.切换积分顺序,就有:
$$
\begin{aligned}
R_B(\delta)& = \int [\sum_x\sum_y L(y,\delta(x))p(x,y|\theta^*)]p(\theta^*)d\theta^* &\text{(6.13)}\\
&\sum_x\sum_y \int_\Theta L(y,\delta(x))p(x,y,\theta^*)d\theta^* &\text{(6.14)}\\
& =\sum_x[\sum_y L(y,\delta(x))p(y|x)dy]p(x) &\text{(6.15)}\\
& =\sum_x \rho (\delta(x)|x)p(x) &\text{(6.16)}\\
\end{aligned}
$$

此处查看原书图 6.2

要最小化全局期望(overall expectation),只要将每个x项最小化就可以了,所以我们的决策规则就是要挑选:

$\delta_B (x)=\arg\min_{a\in A} \rho(a|x)$(6.17)
证明完毕.


#### 定理6.32 (Wald,1950)

每个可接受的决策规则都是某种程度上的贝叶斯决策规则,对应着某些可能还不适当的先验分布.
这就表明,对频率论风险函数最小化的最佳方法就是贝叶斯方法!更多信息参考(Bernardo and Smith 1994, p448).

### 6.3.2 最小最大风险(Minimax risk)

当然咯,很多频率论者不喜欢贝叶斯风险,因为这需要选择一个先验(虽然这只是对估计器的评估中要用到,并不影响估计器的构建).所以另外一种方法就如下所示.定义一个估计器的最大风险如下所示:

$R_{max}(\delta) \overset{\triangle}{=} \max_{\theta^*} R(\theta^*,\delta)$(6.18)

最小最大规则(minimax rule)就是将最大风险最小化:
$\delta_{MM}\overset{\triangle}{=} \arg\min_\delta R_{max}(\delta)$(6.19)

例如图6.2中,很明显在所有的$\theta^*$值上,$\delta_1$有比$\delta_2$更低的最差情况风险(lower worst-case risk),所以就是最小最大估计器(关于如何计算一个具体模型的风险函数的解释可以参考本书6.3.3.1).

最小最大估计器有一定的吸引力.可惜,计算过程可难咯.而且这些函数还都很悲观(pessimistic).实际上,所有的最小最大估计器都是等价于在最不利先验下的贝叶斯估计器.在大多数统计情境中(不包括博弈论情境),假设自然充满敌意并不是一个很合理的假设.


### 6.3.3 可容许的估计器(Admissible estimators)

频率论决策理论的基本问题就是要知道真实分布$p(*|\theta^*)$才能去评估风险.可是有的估计器可能不管$\theta^*$是什么值,都会比其他的一些估计器更差.比如说,如果对于所有的$\theta\in\Theta$,都有$R(\theta,\delta_1)<R(\theta,\delta_2)$,那么就说$\delta_1$支配了$\delta_2$.如果不等关系对于某个$\theta$来说严格成立,就说这种支配关系是严格的.如果一个估计器不被另外的估计器所支配,就说这个估计器是可容许的(Admissible).

#### 6.3.3.1 样例

这个例子基于(Bernardo and smith 1994).这个问题是去估计一个正态分布的均值.假设数据样本抽样自一个正态分布$x_i \sim N(\theta^*,\sigma^2=1)$,然后使用平方损失函数(quadratic loss)$L(\theta,\hat\theta)=(\theta-\hat \theta)^2$.这时候对应的风险函数就是均方误差(MSE).估计器$\hat\theta(x)=\delta(x)$也就是一些可能的决策规则,如下所示:

*$\delta_1(x)=\bar x$,这个是样本均值
*$\delta_2(x)=\tilde x$,这个是样本中位数
*$\delta_3(x)=\theta_0$,这个是某个固定值
*$\delta_k(x)$,这个是在先验$N(\theta|\theta_0,\sigma^2/k)$下的后验均值:
$\delta_k(x)=\frac{N}{N+k}\bar x  + \frac{k}{N+k}\theta_0 =w\bar x +(1-w)\theta_0$(6.20)

对$\delta_k$可以设置一个弱先验$k=1$,以及一个更强的先验$k=5$.先验均值是某个固定值$\theta_0$.然后假设$\sigma^2$已知.(这样$\delta_3(x)$就和$\delta_k(x)一样了,后者有一个无穷强先验$k=\infty$.)

接下来就以解析形式来推导风险函数了.(在这个杨丽中可以这么做,是因为已经知道了真实参数$\theta^*$.)在本书6.4.4,会看到均方误差(MES)可以拆解成平方偏差(squared bias)加上方差(variance)的形式:
$MSE(\hat\theta(*)|ptheta^*$ = var[\hat\theta]+bias^2(\hat\theta)(6.21)

样本均值是没有偏差的(unbiased),所以其风险函数为:
$MSE(\delta_1|\theta^*) =var[\bar x]=\frac{\sigma^2}{N}$(6.22)

此处查看原书图 6.3


样本中位数也是无偏差的.很明显其方差大约就是$\pi/(2N)$,所以有:

$MSE(\delta_2|\theta^*)=\frac{\pi}{2N}$(6.23)


对于固定值的$\delta_3(x)=\theta_0$,方差是0,所以有:

$MSE(\delta_3|\theta^*)= (\theta^*-\theta_0)^2 $(6.24)

最后是后验均值,如下所示:

$$
\begin{aligned}
MSE(\delta_k|\theta^*)&= \mathrm{E}[ (w\bar x+(1-w)\theta_0-\theta^*)^2      ]   &\text{(6.25)}\\
&=\mathrm{E}[(w(\barx-\theta^*)+(1-w)(\theta_0-\theta^*)        )^2]    &\text{(6.26)}\\
&=  w^2\frac{\sigma^2}{N}+(1-w)^2(\theta_0-\theta^*)^2  &\text{(6.27)}\\
&=  \frac{1}{(N+k)^2}(N\sigma^2+k^2(\theta_0-\theta^*)^2)  &\text{(6.28)}\\
\end{aligned}
$$

图6.3中所示是在$N\in \{5,20\}$范围内的上面几个函数的图像.可以看出总体上最佳的估计器都是依赖$\theta^*$值的那几个,可是$\theta^*$还是未知的.如果$\theta^*$很接近$\theta_0$,那么$\delta_3$(实际上就是预测的$\theta_0$)就是最好的了.如果$\theta^*$在$\theta_0$范围内有一定波动,那么后验均值,结合了对$\theta_0$的猜测和数据所反映的信息,就是最好的.如果$\theta^*$远离$\theta_0$,那么最大似然估计(MLE)就是最好的.这也一点都不让人意外:假设先验均值明暗,小规模的收缩(shrinkage)是通常期望的(使用一个若先验的后验均值).

令人意外的是对于任意的$\theta_0$值,决策规则$\delta_2$(样本中位数)的风险函数宗师比$\delta_1$(样本均值)的风险函数更大.也就是说,样本中位数对于这个问题来说是一个不可容许估计器(inadmissible estimator)(这个问题是假设数据抽样自一个正态分布).

可是在实践中,样本中位数其实往往比样本均值更好,因为对于异常值不敏感,更健壮.参考(Minka 2000d)可知,如果假设数据来自于比高斯分布(正态分布)更重尾(heavier tails)的拉普拉斯分布(Laplace distribution),那么样本中位数就是贝叶斯估计器(Bayes estimator)(使用平方损失函数(squared loss)).更一般地,可以对数据使用各种灵活的模型来构建健壮的估计器,比如混合模型,或者不呢书14.7.2会讲到的非参数化密度估计器(non-parametric density estimators),然后再去计算后验均值或者中位数.

#### 6.3.3.2 斯坦因悖论(Stein’s paradox)*


加入有N个独立同分布(iid)随机变量服从正态分布,即$X_i\sim N(\theta_i,1)$,然后想要估计$\theta_i$.很明显估计器应该用最大似然估计(MLE)这时候就是设$\hat\theta_i=x_i$.结果表明:$N\ge 4$的时候,这是一个不可容许估计器(inadmissible estimator).

怎么证明?构建一个更好的估计器就可以了.比如吉姆斯-斯坦因估计器(James-Stein estimator)就可以,定义如下所示:

$\hat\theta_i =\hat B \bar x +(1-\hat B)(x_i-\bar x)$(6.29)

上式中的$\bar x=\frac{1}{N}\sum^N_{i=1}x_i$,而$0<B<1$是某个调节常数.这个估计其会将$\theta_i$朝向全局均值进行收缩(shrink).(在本书5.6.2使用经验贝叶斯方法推导过这个估计器.)

很明显,当$N\ge 4$的时候,这个收缩估计器比最大似然估计(MLE,也就是样本均值)有更低的频率风险(均方误差MSE).这就叫做斯坦因悖论(Stein's paradox).为啥说这是个悖论呢?这就解释一下.加入$\theta_i$是蘑菇而学生i的真实智商值(IQ),而$X_i$是其测试分数.为啥用全局均值来估计特定的$\theta_i$,用其他学生的分数去估计另一个学生的分数?利用不同范畴的东西还可以制造更加荒诞的自相矛盾的例子,比如加入$\theta_1$是我的智商,而$\theta_2$是温哥华平均降雨量,这有毛线关系?

这个悖论的解决方案如下所述.如果你的目标只是估计$\theta_i$,那么用$x_i$来估计就已经是最好的选择了,可是如果你对目的是估计整个向量$\theta$,而且你还要用平方误差(squared error)作为你的损失函数,那么那个收缩估计器就更好.为了更好理解,假设我们要从一个蛋一样笨$x\sim N(\theta,I)$来估计$||\theta||^2_2$.最简单的估计就是$||x||^2_2$,不过会遇到上面的问题,因为:


$\mathrm{E}[||x||^2_2]=\mathrm{E}[\sum_i x^2_i] =\sum^N_{i=1}(1+\theta_i^2)=N+||\theta||^2_2    $(6.30)

结果就需要增加更多信息来降低风险,而这些增加的信息可能甚至来自于一些不相关的信息源,然后估计就会收缩到全局均值上面了.在本书5.6.2对此给出过贝叶斯理论的解释,更多细节也可以参考(Efron and Morris 1975).


#### 6.3.3.3 可容许性远远不够(Admissibility is not enough)

从前文来看,似乎很明显我们应该在可容许估计器范围内来搜索好的估计器.但实际上远不止构建可容许估计器这么简单,比如接下来这个例子就能看出.

#### 定理 6.3.3

设有正态分布$X\sim N(\theta,1)$,在平方误差下对$\theta$进行估计.设$\delta_1(x)=\theta_0$是一个独立与数据的常量.这是一个可容许估计器(admissible estimator).

证明:用反证法,假设结论不成立,存在另外一个估计器$\delta_2$有更小风险,所以有$R(\theta^*,\delta_2)\le R(\theta^*,\delta_1)$,对于某些$\theta^*$不等关系严格成立.设真实参数为$\theta^*=\theta_0$.则$R(\theta^*,\delta_1)=0$,并且有:

$R(\theta^*,\delta_2)=\int (\delta_2(x)-\theta_0)^2p(x|\theta_0)dx$(6.31)

由于对于所有的$\theta^*$都有$0\le R(\theta^*,\delta_2)\le R(\theta^*,\delta_1)$,而$R(\theat_0,\delta_1)=0$,所以则有$R(\theta_0,\delta_2)=0,\delta_2(x)=\theta_0=\delta_1(x)$.这就表明了$\delta_2$只有和$\delta_1$相等的情况下才能避免在某一点$\theta_0$处有更高风险.也就是说不能有其他的估计器$\delta_2$能严格提供更低的风险.所以$\delta_1$是可容许的.证明完毕



## 6.4 估计器的理想性质

由于频率论方法不能提供一种自动选择最佳估计器的方法,我们就得自己想出其他启发式的办法来进行选择.在本节,就讲一下我们希望估计器所具有的一些性质.不过很不幸,我们会发现这些性质不能够同时满足.

### 6.4.1 连续估计器(Consistent estimators)


连续估计器,就是随着取样规模趋近于无穷大,最终能够恢复出生成数据的真实参数的估计器,也就是随着$|D|\rightarrow \infity$,$\hat\hteta(D)\rightarrow \theta^*$(这里的箭头指的是概率收敛的意思).当然了,这个概念要有意义,就需要保证数据确实是来自某个具有参数$\theta^*$的特定模型,而现实中这种情况很少见的.不过从理论上来说这还是个很有用的性质.

最大似然估计(MLE)就是一个连续估计器.直观理解就是因为将似然函数最大化其实就等价于将散度$KL(p(*|\theta^*)||p(*|\hat\theta))$最小化,其中的$p(*|\theta^*)$是真实分布,而$p(*|\hat\theta)$是估计的.很明显当且仅当$\hat\theta=\theta^*$的时候才有0散度(KL divergence).


### 6.4.2 无偏差估计器(Unbiased estimators)

估计器的偏差(bias)定义如下:

$bias(\hat\theta(*)) =\mathrm{E}_{p(D|\theta_*)} [\hat\theta(D)-\theta_* ]  $(6.32)

上式中的$\theta_*$就是真实的参数值.如果偏差为0,就说这个估计器无偏差.这意味着取样分布的中心正好就是真实参数.例如对于高斯分布均值的最大似然估计(MLE)就是无偏差的:

$bias(\hat\mu)  =\mathrm{E}[\bar x]-\mu= =\mathrm{E}[\frac{1}{N{\sum^N_{i=1}x_i] -\mu =\frac{N\mu}{N}-\mu=0 $(6.33)

不过对高斯分布方差$\hat\sigma^2$的最大似然估计(MLE)就不是对$\sigma^2$的无偏估计.实际上可以发现(参考练习6.3):

$\mathrm{E} [\hat\sigma^2]=\frac{N-1}{N}\sigma^2$(6.34)


不过下面这个估计器就是一个无偏差估计器:

$\hat\sigma^2_{N-1}=\frac{N}{N-1}\hat\sigma^2=\frac{1}{N-1}\sum^N_{i=1}(x_i-\bar x)^2$(6.35)

对上式,可以证明有:

$\mathrm{E} [\hat\sigma^2_{N-1}]=\mathrm{E} [\frac{N}{N-1}\sigma^2]=\frac{N}{N-1}\frac{N-1}{N}\sigma^2=\sigma^2 $(6.36)

在MATLAB中,$\var(X)$返回的就是$\hat\simga^2_{N-1}$,而$\var(X,1)$返回的是最大似然估计(MLE)$\sigma^2$.对于足够大规模的N,这点区别就可以忽略了.

虽然最大似然估计(MLE)可能有时候有偏差,不过总会逐渐无偏差.(这也是最大似然估计(MLE)是连续估计器的必要条件.)

虽然无偏听上去好像是个很理想的性质,但也不总是好事,更多细节可以参考本书6.4.4以及(Lindley 1972)的相关讨论.

### 6.4.3 最小方差估计器


直观来看,好像让估计器尽量无偏差是很合理的(不过后面我们会看到事实并非如此简单).不过只是无偏还不够用.比如我们想要从集合$D=\{x_1,..,x_N\}$估计一个高斯均值.最开始对第一个数据点用这个估计器的时候$\hat\theta(D)=x_1$,这时候还是无偏估计,但逐渐就会比经验均值$\bar x$(这也是无偏的)更远离真实的$\theta_*$.所以一个估计器的方差也很重要.

很自然的问题:方差能到多大?有一个著名的结论,叫做克莱默-饶下界(Cramer-Rao lower bound)为任意的无偏估计器的方差提供了下界.具体来说如下所示:

#### 定理6.4.1 (克莱默-饶 不等式)

设$X_1,..,X_n \sim p(X|\theta_0)$,而$\hat\theta=\hat\theta(x_1,..,x_n)$是一个对参数$\theta_0$的无偏估计器.然后在对$p(X|\theta_0)$的各种平滑假设下,有:

$\var [\hat\theta]\ge \frac{1}{nI(\theta_0)}$(6.37)

其中的$I(\theta_0)$是费舍信息矩阵(Fisher information matrix)(参考本书6.2.2).

对此的证明可以参考(Rice 1995, p275).
可以证明最大似然估计(MLE)能达到克莱默-饶下界,因此对于任意无偏估计器都会有渐进的最小方差.所以说最大似然估计(MLE)是渐进最优(asymptotically optimal)的.


### 6.4.4 偏差-方差权衡 

使用无偏估计看上去是个好主意,实际并非如此简单.比如用一个二次损失函数为例.如上文所述,对应的风险函数是均方误差(MSE).然后我们能推出一个对均方误差(MSE)的有用分解.(所有期望和方差都是关于真实分布$p(D|\theta^*)$,但为了表达简洁,这里就把多余的条件都舍掉了.)设$\hat\theta =\hat \theta(D)$表示这个估计,然后$\bar \theta =\mathrm{E}[\hat\theta]表示的是估计的期望值(变化Ｄ来进行估计)．然后就有：

$$
\begin{aligned}
\mathrm{E} [(\hat\theta-\theta^*)^2 ]&=\mathrm{E} [[(\hat\theta-\bar \theta)+(\bar\theta-\theta^*) ]^2]  &\text{(6.38)\\
&=\mathrm{E} [(\hat\theta-\bar \theta)^2] +2(\bar\theta-\theta^*)\mathrm{E}[\hat\theta-\theta^*]+(\bar\theta-\theta^*)^2  &\text{(6.39)\\
&=\mathrm{E}[(\hat\theta-\bar\theta)^2]+(\bar\theta-\theta^*)^2   &\text{(6.40)\\
&=\var[\hat\theta]+bias^2(\hat\theta)   &\text{(6.41)\\
\end{aligned}
$$

用文字表达就是：

$MSE= variance +bias^2$(6.42)重要公式

这也就是偏差－方差之间的权衡（bias-variance tradeoff），可以参考(Geman et al. 1992)．这就意味着架设我们的目标是要最小化平方误差，那么选择一个有偏差估计器也可能是可取的，只要能够降低方差．

##### 6.4.4.1 样例:估计高斯均值

然后举个例子吧，基于(Hoff 2009, p79).假如要从$x=(x_1,..,x_N)$估计高斯均值.架设数据采样自一个正态分布$x_i\sim N(\theta^*=1,\sigma^2)$.很明显可以用最大似然估计(MLE).这样估计器偏差为0,方差为:

$\var[\bar x|\theta^*] =\frac{\sigma^2}{N} $(6.43)


不过也可以使用最大后验估计(MAP estimate).在本书4.6.1中,我们已经遇到过使用正态分布$N(\theta_0,\sigma^2/K_0)$先验的最大后验估计为:


$\tilde x \overset{\triangle}{=} \frac{N}{N+k_0}\bar x+\frac{k_0}{N+k_0}\theta_0=w\bar x+(1-w)\theta_0 $(6.44)

其中$0\le w \le 1$控制了我们对最大似然估计(MLE)相比先验的信任程度.(这也是后验均值,因为高斯分布的均值和众数相等.)偏差和方差为:

$$
\begin{aligned}
\mathrm{E}[\tilde x]-\theta^* &=  w\theta_0+(1-w)\theta_0-\theta^*=(1-w)(\theta_0-\theta^*)   &\text{(6.45)\\
\var[\tilde x]&= w^2\frac{\sigma^2}{M}  &\text{(6.46)\\
\end{aligned}
$$

此处查看原书图 6.4


虽然最大后验估计有偏差(设 w<1),但方差更低.

假设先验有些错误,所以使用$\theta_0=0$,而真实的$\theta^*=1$.如图6.4(a)所示,可以看到对$k_0>0$的最大后验估计的抽样分布是偏离于真实值的,但方差比最大似然估计(MLE)的更低(也就是更窄).

如图6.4(b)所示是$mse(\tilde x)/mse(\bar x)$对 N 的函数曲线.可见最大后验估计(MAP)比最大似然估计(MLE)有更低的均方误差(MSE),尤其是样本规模小的时候,比如$k_0\in \{1,2\}$.$k_0=0$的情况对应的就是最大似然估计(MLE),而$k_0=3$对应的就是强先验,这就会影响性能了,因为先验均值是错的.很明显,对先验强度的调整很重要,后面会讲到.

#### 6.4.4.2 样例:岭回归(ridge regression)


在偏差方差之间进行权衡的另外一个重要例子就是岭回归(ridge regression),我们会在本书7.5讲到.简单来说,对应的就是在高斯先验$p(w)=N(w|0,\lambda^{-1}I$下对线性回归(linear regression)的最大后验估计(MAP).零均值先验使得先验的权值很小,也就降低了过拟合的概率;精度项$\lambda$控制了先验的强度.设置$\lambda=0$就是最大似然估计(MLE);使用$\lambda>0$就得到了一个有偏差估计.要展示方差的效果,可以考虑一个简单的例子.比如图6.5左边的就是每个拟合曲线的投图,右边的是平均的拟合曲线.很明显随着归一化强度的增加,方差降低了,但是偏差增大了.


此处查看原书图 6.5


#### 6.4.4.3 对于分类的偏差-方差权衡

如果使用0-1损失函数,而不是用平方损失,上面的分析就不适合了,因为频率论的风险函数不再能表达成平方偏差加上方差的形式了.实际上可以发现(参考练习7.2(Hastie et al. 2009)):偏差和方差是以相乘方式结合起来的(combine multiplicatively).如果估计结果处于决策边界的正确一侧,偏差就是负的,然后降低方差就可以降低误分类率.但如果估计位于决策边界的错误一侧,那么偏差就是正的,就得增加方差(Friedman 1997a).这就表明对于分类来说,偏差方差权衡没多大用.最好还是关注到期望损失(expected loss)上,而不是直接关注偏差和方差.可以使用交叉验证来估计期望损失,具体会在本书6.5.3中讲到.





## 6.5 经验风险最小化(Empirical risk minimization)

频率论决策方法难以避免的一个基本问题就是不能计算出风险函数,因为要知道真实数据分布才行.(作为对比,贝叶斯后验期望损失就总能计算出来,因为条件是在数据上的,而不是真实参数$\theta^*$.)不过也有个办法能避免这个问题,也就是要预测已观测量,而不是估计隐藏变量或者隐藏参数.也就是不以$L(\theta,\delta(D))$的形式来找损失函数(其中的$\theta$是未知的真实参数,而$\delta(D)$是估计器),而是以$L(y,\delta(x))$形式来找损失函数,其中的y是未知的真实响应变量(response),而$\delta(x)$是对给定的输入特征x做出的预测.这样一来,频率论的风险函数就是: 

$R(p_*,\delta \overset{\triangle}{=} \mathrm{E}_{(x,y)\sim p_*}[L(y,\delta(x)]=\sum_x\sum_yL(y,\delta(x))p_*(x,y)$(6.47)

上式中的$p_*$表示的是真实的自然分布.当然这个分布是未知的,不过可以使用一个经验分布来近似,这个经验分布是通过训练及数据来得到:

$p_*(x,y)\approx p_{emp}(x,y) \overset{\triangle}{=}\frac{1}{N}\sum^N_{i]1}\delta_{x_i}(x)\delta_{y_i}(y)  $(6.48)

然后可以定义经验风险(empirical risk):

$R_{emp}(D,D) \overset{\triangle}{=} R(P_{emp},\delta=\frac{1}{N}\sum^N_{i=1}L(y_i,\delta(x_i))$(6.49)

在0-1损失函数的情况下,上面的$L(y,\delta(x))= I(y\ne \delta(x))$,上面这个经验风险就成了误分类率(misclassification rate)了.在平方误差损失函数的情况下,上式中的$L(y,\delta(x))= (y-\delta(x))^2$,这就成了均方误差(mean squared error).然后定义经验风险最小化(empirical risk minimization, 缩写为ERM),就是找到一个能使经验风险最小化的决策过程(通常都是分类规则):

$\delta_{ERM}(D)=\arg\min_{\delta}R_{emp}(D,\delta)$(6.50)

在无监督学习的情况下,可以去掉所有带y的项目,然后将$L(y,\delta(x))$替换成$L(x,\delta(x))$,比如,设$L(x,\delta(x))=||x-\delta(x)||^2_2$,衡量的是重建误差(reconstruction error).然后使用$\delta(x)=decode(encode(x))$定义决策规则,就类似向量量化(vector quantization,参考本书11.4.2.6)和主成分分析(principal component analysis,缩写为PCA,本书12.2).最后就得到了经验风险函数的定义形式如下:

$R_{emp}(D,\delta) =\frac{1}{N}\sum^N_{i=1} L(x_i,\delta(x_i))$(6.51)

当然了,总还可以设置$\delta(x)=x$来最小化风险,所以对于解码编码来说,某些瓶颈都很关键.



### 6.5.1 规范化风险最小化(Regularized risk minimization)

要注意,如果对"自然分布"的先验严格等于经验分布,那么贝叶斯风险就和经验风险相等了(Minka 2001b):

$\mathrm{E}[R(p_*,\delta)|p_*=p_{emp}]=R_{emp}(D,\delta)$(6.52)

因此最小化经验风险,就可能导致过拟合.所以通常都得为目标函数增加一个复杂度惩罚函数(complexity penalty):

$R" (D,\delta)=  R_{emp}(D,\delta)+\lambda C(\delta)  $(6.53)

上式中的$C(\delta)$衡量的是预测函数$\delta(x)$的复杂度,而$\lambda$控制的是复杂度惩罚的程度.这个方法就叫做规范风险最小化(regularized risk minimization,缩写为RRM).要注意如果损失函数是对数似然函数的负数,那么规范化项(regularizer)就是负的对数先验,这也就等价于最大后验估计(MAP).

规范化风险最小化(RRM)有两个关键问题:如何衡量复杂度,以及如何挑选$\lambda$.对于线性模型来说,可以用其自由度定义成复杂度,具体细节参考本书7.5.3.更多的通用模型,可以使用VC维度(VC dimension),参考本书6.5.4.要挑选$\lambda$,可以使用在6.5.2中要讲到的方法.


### 6.5.2 结构风险最小化

规范化风险最小化原则表明,对于给定的复杂度惩罚函数(complexity penalty),可以使用下面的公式来拟合模型:


$ \hat\delta_{\lambda}=\arg\min_{\delta}[R_{emp}(D,\delta)+\lambda C(\delta)]   $(6.54)

可是要怎么选择$\lambda$?不能使用训练集,因为这会低估真实风险,也就是所谓的训练误差优化(optimism of the training erro)问题.或者也可以使用干下面的规则,也就是结构风险最小化(structural risk minimization)原则(Vapnik 1998):

$\hat\lambda =\arg\min_{\lambda} \hat R(\hat \delta _{\lambda})$(6.55)

上式中的$\hat R(\delta)$是对风险的估计.有两种广泛应用的估计:交叉验证,以及风险理论上界约束.接下来两种都讲一下.

### 6.5.3 使用交叉验证估计风险函数

可以利用一个验证集来估计某个估计器的风险.如果没有单独的验证集,可以使用交叉验证(cross validation,缩写为CV),在本书1.4.8中已经简单讲过了.更确切来说,交叉验证定义如下.设训练集中有$N=|D|$个数据.将第k份数据表达为$D_k$,而其他的所有数据就表示为$D_{-k}$.(在分层交叉验证(stratified CV)中,如果类标签是离散的,就选择让每份数据规模都基本相等.)然后设Ｆ是一个学习算法或者拟合函数，使用数据集D,并且模型索引为m(这个可以使离散索引,比如多项式指数,也可以是连续的,比如规范化强度等等),然后返回的就是参数向量:


$\hat\theta_m =F(D,m)$(6.56)

最后,设P是一个预测函数,接受一个输入特征和一个参数向量,然后返回一个预测:


$\hat y=P(x,\hat \theta)=f(x,\hat \theta)$(6.57)

这样就形成了一个拟合-预测循环(fit-predict cycle):

$f_m(x,D)=P(x,F(D,m))$(6.58)


对$f_m$的风险函数的K折交叉验证估计的定义为:

$R(m,D,K)\overset{\triangle}{=} \frac{1}{N}\sum^N_{k=1}\sum_{i\inD_k}L(y_i, P(x_i,F(D_{-k},m)))$(6.59)

然后就可以对每一份数据都调用运行一次拟合算法.设$f^k_m(x)=P(x,F(D_{-k},m))$是我们要对出去验证集k之外所有几何训练得到的函数.然后就可以把交叉验证估计改写成下面的形式:

$R(m,D,K)=\frac{1}{N}\sum^N_{k=1}\sum_{i\inD_k}L(y_i,f^{-i}_m(x_i))=\frac{1}{N}\sum^N_{i=1}L(y_i,f^{-i}_m(x_i))$(6.60)

上式中的$k(i)是所用的验证集所在折数(份数),而i是用作验证的数据.也就是说,我们使用一个不包含$x_i$的数据训练出的模型来预测$y_i$.

如果K=N,这个方法就成了留一交叉验证(leave one out cross validation,缩写为 LOOCV).这时候估计的风险就成了:

$R(m,D,N)=\frac{1}{N}\sum^N_{i=1}L(y_i,f^{-i}_m(x_i))$(6.61)

上式中的$f^{-i}_m(x_i)=P(x,F(D_{-i},m))$ .这需要对模型进行N次拟合,其中$f^{-i}_m$时候用到的是第i个训练样例.很幸运的是,有的模型分类和损失函数(比如线性模型和平方损失函数)可以只拟合一次,然后以解析方式每次去除掉第i个训练样本的效果.这样就叫做通用交叉验证(generalized cross validation,缩写为GCV).



#### 6.5.3.1 样例:使用交叉验证来为岭回归选择参数$\lambda$


举个例子,比如要为一个惩罚线性回归挑选$l_2$规范项强度.可以用下面的规则:

$ \hat\lambda =\arg \min _{\lambda \in\{\lambda_{min},\lambda_{max}\}} R(\lambda,D_{train},K)$(6.62)

其中的$[\lambda_{min},\lambda_{max}]$是一个有限区间,我们在这个范围内搜索$\lambda$的值,而$ R(\lambda,D_{train},K)$是使用$\lambda$之后对风险函数的K折交叉验证估计,如下所示:

$R(\lambda,D_{train},K)= \frac{1}{D_{train}}\sum^K_{k=1}\sum_{i\in D_k}L(y_i,f^k_\lambda(x_i))$(6.63)

上式中的$f^k_{\lambda}(x)=x^T\hat w_{\lambda} (D_{-k})$是对除K折外数据所训练得到的预测函数,而$\hat w_{\lambda}(D)=\arg\min_wNLL(w,D)+\lambda||w||^2_2$是最大后验估计(MAP).图6.6(b)所示为交叉验证估计的风险函数与$\log(\lamba)$关系图像,其中的损失函数使用的是平方误差.

当进行分类的时候,通常用0-1损失函数.这时候可以在对$w_\lambda m$估计的经验风险上优化一个凸上界约束(convex upper bound),但我们优化了风险函数本身(对其使用交叉验证估计)来估计$\lambda$.估计$\lambda$的时候可以使用不光滑的0-1损失函数,因为这是在整个(一维)空间上使用满立法进行搜索.

当调节参数不仅一两个的时候,这个方法就不灵了.这时候可以使用经验贝叶斯,经验贝叶斯方法允许使用基于梯度的优化方法来替代蛮力查找,就可以优化大量的超参数了.这部分参考本书5.6.

此处查看原书图6.6


#### 6.5.3.2 单标准差规则(The one standard error rule)


上面的过程都是估计风险函数,但并没有给出对不确定度的衡量.在频率论中,对一个估计的不确定度的标准衡量是均值标准差,定义如下:

$  se=\frac{\hat\sigma}{\sqrt {N}} =\sqrt{\frac{\hat\sigma^2}{N}}  $(6.64)

上式中的$\hat \sigma^2$是对损失函数方差的估计:

$   \hat\sigma^2=\frac{1}{N}\sum^N_{i=1}(L_i-\bar L)^2 , L_i =L(y_i,f^{k(i)}_m(x_i)) , \bar L=\frac{1}{N}\sum^N_{i=1}L_i  $(6.65)

要注意这里的$\sigma$衡量的是样本空间$L_i$的内在变异性,而标准差(se)衡量的是对均值$\bar L$的不确定度.

对一个模型集合使用交叉验证来计算这些模型估计风险的均值和标准差.从这些有噪音估计中选择模型的一个常用的启发手段是选一个对应最简单模型的值,这个模型的风险不能超过最佳模型风险的单个标准差,这就叫单标准差规则(one standard error rule)(Hastie et al. 2001, p216).例如图6.6中,就能看到这个启发式方法并没有选择曲线上的最低点,而是选择偏右一点的点,因为那个点对应了更强规范化模型(more heavily regularized model),而经验性能本质上是一样的.




#### 6.5.3.3 非概率无监督学习中模型选择的交叉验证(CV for model selection in non-probabilistic unsupervised learning)


如果我们进行无监督学习,就必须使用一个损失函数来衡量重建误差(reconstruction error),比如$L(x,\delta(x))=||x-\delta(x)||^2$等等损失函数.这里的$\delta(x)$是某种解码编码机制(encode-decode scheme).不过我们不能使用交叉验证来确定这个$\delta$的复杂度(complexity),正如本书11.5.2所述.这是因为更复杂的模型会更少压缩数据,而降低了失真(distortion).所以要么使用概率模型,要么就用其他的启发式模型.


### 6.5.4 使用统计学习理论的风险上界(Upper bounding the risk using statistical learning theory)*

交叉验证的根本问题是速度太慢,因为必须对模型进行多次拟合.这就使得我们更希望计算泛化误差(generalization error)的解析近似或者上下界.这个问题是统计学习理论(statistical learning theory,缩写为SLT)的研究范围.具体来说,统计学习理论(SLT)所做的是对任意数据分布$p_*$来建立其风险函数$R(p_*,h)$的边界约束,$h\in H$是假设,$R_{emp}(D,h)$是经验风险(empirical risk),取样规模$N=|D|$,H就是假设空间规模.

首先考虑假设空间有限的情况,也就是有固定的$(H)=|H|$.也就是说,要从一个有限的列表中选择一个模型或者假设,而不是优化实数值参数.这样就可以证明有下面的结论了.

#### 定理 6.5.1
对于任意数据分布$p_*$,以及任意从$p_*$中取样得到的规模为N的数据集D,则我们估计的误差率(errir rate)超过错误率(wrong)$\epsilon$的概率的上界为(这也就是最坏的情况):

$  P(\max_{h\in H} |R_{emp}(D,h) -R(p_*,h)|>\epsilon )\le 2dim(H)e^{-2N\epsilon^2}  $(6.66)

证明. 要证明这个,需要两个有用的结论.首先是霍夫丁不等式(Hoeffding’s inequality),说的是如果有个伯努利分布,$X_1,...,X_N\sim Ber(\theta)$,对于任意的$\epsilon>0$,则有:

$ P(|\bar x-\theta|>\epsilon)\le 2e^{-2N\epsilon^2}    $(6.67)

上式中的$\bar x =\frac{1}{N}\sum^N_{i=1}x_i$.
第二个结论是联合约束(union bound),说得是如果$A_1,...,A_d$是一系列事件集合,那么有$P(U^d_{i=1}A_i)\le \sum^d_{i=1}P(A_i)$.

最后为了表述简洁,设$R(h)=R(h,p_*)$表示真实风险函数(true risk),而$\hat R_N(h)=R_{emp}(D,h)$是经验风险函数(empirical risk).

利用上面的结论,就得到了:



$$
\begin{aligned}
P(\max_{h\in H}|\hat R_N (h) -R(h)|>\epsilon )&= P(U_{h\in H}|\hat R_N(h)-R(h)|>\epsilon ) &\text{(6.68)}\\
&\le  \sum_{h\in H} P(|\hat R_N(h)-R(h)|>\epsilon)   &\text{(6.69)}\\
&\le  \sum_{h\in H}2e^{-2N\epsilon^2}=2 dim (H)e^{-2N\epsilon^2}   &\text{(6.70)}\\
\end{aligned}
$$

这个上界的约束条件表明训练误差的优化会随着$dim(H)$提高而提高,但又随着$N=|D|$而降低,正如我们所料.

如果假设空间H是无穷的,比如说是实数值参数了,那就不能使用$dim(H)=|H|$了.这时候要使用VC维度(Vapnik-Chervonenkis ,缩写为VC).具体细节参考(Vapnik 1998).

回到理论上来看,统计学习背后的关键思想其实很简单.假如要找一个低经验风险的模型.如果假设空间H相对于数据规模来说非常大,那么我们很幸运,得到的数据就碰巧能用我们选中的函数建模.不过这并不意味着这样的一个函数就有很低的泛化误差.但如果假设类别的规模特别有限,或者训练及规模超级大,那我们可能就不能那么幸运了,所以具有低经验风险才能证明真正有低风险.

要注意对训练误差的优化并不一定就随着模型复杂度的提高而改善,但会随着搜索的不同模型数目而增加.

统计学习理论相比交叉验证来说,有一个优势,就是风险函数的上界约束比交叉验证算起来更快.缺点就是很多有用模型都很难算出VC维度,而且上界通常也可能很松散(参考 Kaariainen and Langford 2005).

可以通过加入学习程序的复杂度计算来扩展统计学习理论.这个领域就叫做计算学习理论(computationa learning theory,缩写为COLT).大多数这类研究关注的都是当h是二分类,而损失函数为0-1损失的情况.如果观察到了一个低经验风险的情况,那么架设样本空间就适当地小,然后就可以说这个估计函数是可能近似正确的(probably approximately correct,缩写为PAC).如果使用多项式规模复杂度的算法能够找到一个可能近似正确(PAC)的函数,就说这个假设空间是有效PAC可学习的(efficiently PAC-learnable).更多内容参考(Kearns and Vazirani 1994).

### 6.5.5 代理损失函数(Surrogate loss functions)


在经验误差最小化(ERM)/规范误差最小化(RRM)框架中最小化损失函数并不总是很简单.例如可能要优化曲线所覆盖的面积(AUC)或者F1分数.或者更简单的情况,在分类里面需要最小化0-1损失函数.可很不幸的是0-1风险函数是非光滑的,所以很难去优化.替代方法就是用最大似然估计替代,因为对数似然函数是个光滑凸函数,上界就是0-1风险函数,下面就来将这个.

考虑二项逻辑回归,设$y_i\in \{-1,1\}$.然后设我们的决策函数计算量对数比值:

$f(x_i)=\log \frac{p(y=1|x_i,w)}{p(y=-1|x_i,w)}=w^Tx_i=\eta_i$(6.71)


然后对应的输出标签上的概率分布就是:

$p(y_i|x_i,w)= sigm(y_i,\eta_i)$(6.72)

接下来定义对数损失函数(log-loss)为:

$L_{nll}(y,\eta)=-\log p(y|x,w)=\log(1+e^{-u\eta})$(6.73)


此处查看原书图6.7

很明显,最小化平均对数损失函数就等价于最大化似然函数.

接下来设要计算最大概率标签,也就是等价于使用如果$\eta_i<0$,则$\hat y=-1$,如果$\eta\ge 0$,则$\hat y= +1$.这样函数的0-1损失函数就是:

$L_{01}(y,\eta)=I(y\ne \hat y)=I(y\eta<0)$(6.74)


图6.7所示的就是这两个不同的损失函数,很明显负对数似然函数(NLL)就是在0-1损失函数的上界上.
对数损失是代理损失函数(surrogate loss function)的一个例子.另外一个是铰链损失函数(hinge loss):

$L_{hinge}(y,\eta)=\max(0,1-y\eta)$(6.75)

如图6.7所示,这个函数看着像是门的铰链,因此得名.这个损失函数一种流行的分类方法的基础,这种流行方法就是支持向量机(support vector machine,缩写为SVM),在本书14.5会讲到.

代理损失函数通常是选凸上界的函数,因为凸函数容易最小化.更多信息参考(Bartlett et al. 2006).



## 6.6 频率论统计学的缺陷(Pathologies of frequentist statistics)*

> 说服一个聪明人去接受频率论统计学在实践中的应用是很困难的,但如果用似然函数和贝叶斯定理之类的方法来讲就容易接受了.— George Box, 1962.

频率论统计学有各种各样怪异又难缠的缺陷.本节部分就是讲一个例子来简单展示一下,更多细节参考(Lindley 1972; Lindley and Phillips 1976; Lindley 1982; Berger 1985; Jaynes 2003; Minka 1999).

### 6.6.1 置信区间的反直觉行为

置信区间(conﬁdence interval)就是一个区间,是从估计器的抽样分布中推导出来的(在贝叶斯理论统计学中,置信区间是从一个参数的后验中推导出来的,参考本书5.2.2).具体来说,对于某个参数$\theta$的频率论的置信区间定义如下(相当反直觉不自然反人类!):
$C'_\alpha(\theta)=(l,u):P(l(\tilde D )\le \theta\le u(\tilde D)|\tilde D\sim \theta)=1-\alpha$(6.76)

也就是说,如果我们从$\theta$中取样假设的未来数据$\tilde D$,然后就有$(l(\tilde D),u(\tilde D))$就是参数$\theta$在这个$1-\alpha$比例内所在的置信区间.

在贝叶斯统计学里面,我们的条件是建立在已知上的,也就是已经观测到的数据D,而在未知参数$\theta$上取平均,.在频率论统计里,正好相反,我们将条件建立在未知上,即真实参数值$\theta$,取平均却是在假设的未来数据集$\tilde D$上.

这样对置信区间的定义是很违背直觉的,会带来很多怪异结果.比如下面这个例子来自(Berger 1985, p11).设要从$D=(x_1,x_2)$中取两个区间:

$p(x|\theta)=\begin{cases}0.5 &\text{ if } x=\theta\\ 0.5 &\text{ if } x=\theta+1 \\0 &\text{   otherwise}\end{cases}$(6.77)

如果$\theta =39$,那就期待下面每个区间的出现概率都是0.25:

$(39,39),(39,40),(40,39),(40,40)$(6.78)


设$m=\min(x_1,x_2)$,然后定义下面的置信区间:

$[l(D),u(D)]=[m,m]$(6.79)

从上面的抽样就得到了:

$[39,39],[39,39],[39,39],[40,40]$(6.80)

因此等式6.79是一个75%的置信区间(CI),因为39有75%的概率被包含在这些区间中.可是如果$D=(39,40)$,$p(\theta=39|D)=1.0$,就知道$\theta$ 必须是39了,虽然事实上对此只有75%的置信度.

再举个例子.设要估计一个伯努利分布的参数$\theta$.设其取样均值为:$\bar x =\frac{1}{N} \sum^N_{i=1}x_i$.最大似然估计(MLE)就是$\hat \theta =\bar x$.对一个伯努利分布参数的近似95%置信区间就是$\bar x \pm 1.96\sqrt{\bar x(1-\bar x)/N}$(这个也叫瓦尔德区间,Wald interval,是来自对二项分布的高斯估计,可以和等式3.27相对照.)然后有一个单次试验,其中$N=1,x_1=0$.这样最大似然估计(MLE)就是0,过拟合了,可以参考本书3.3.4.1.可是这时候的95%置信区间也还是(0,0),看着更差.可能是因为之前用了高斯分布估计了真实样本分布,或者可能是因为样本规模太小,又或者就是真实参数太极端.不过实际上即便规模很大的N或者不极端的参数下,瓦尔德区间(Wald interval)效果也不好(Brown et al. 2001).

### 6.6.2 P值(p-values)是祸害

假设我们想要决定是否接受某个基准模型(baseline model,称其为零假设(null hypothesis).需要先定义某个决策规则.在频率统计学中,标准做法是计算一个叫做P值(p-values)的量,定义是观测到跟实际观测规模相当或更大的某个测试统计(test statistic)$f(D)$(比如卡方分布统计等)的概率(在零假设条件下):

$pvalue(D) \overset{\triangle}{=}P(f(\tilde D)\ge f(D)|\tilde D\sim H_0)$(6.81)

这个量依赖于取样分布的尾部面积概率(tail area probability);下面是一个例子.

给定一个p值,我们定义如下的决策规则:当且仅当p值小于某个阈值,比如$\alpha=0.05$的时候我们才拒绝零假设.如果拒绝了,就说观测测试统计和预期测试统计之间的差异在$\alpha$程度上统计学显著(statistically signiﬁcant).这个方法也叫做零假设显著性检验(null hypothesis signiﬁcance testing,缩写为NHST).

这个过程保证了我们期望的第一类误差率(假阳性)最大为$\alpha$.有时候就有人将这解释为频率论假设检验很保守,因为很不容易意外拒绝零假设.但实际上正好相反:因为这个方法值考虑了对零假设的拒绝,所以不论样本规模多大,也从来不收集对零假设有利的证据.因此,P值总是倾向于夸大反对零假设的证据,容易引发误判(very “trigger happy”).

一般来说,P值和我们真正关心的量之间差别巨大,我们真正关心的是给定数据后零假设的后验概率$p(H_0|D)$.具体来说,Sellke 等(2001)一篇文章中表明即便P值小到0.05,$H_0$的后验概率还是可能高达至少30%甚至更高.所以频率论者常说有充分证据表明了一个不能用零假设解释的效应,而贝叶斯主义者就常常会有更保守的判断.比如,P值曾被用来证明超感官知觉(extra-sensory perception,缩写为ESP)是真实的(Wagenmakers et al. 2011),虽然大家明知道那就是扯.因此某些医学杂志早就禁止使用P值了((Matthews 1998)).

P值的另外一个问题是其计算依赖于停止收集数据的决策,即便这些决策对你已经观测到的数据并无影响.比如加入我抛了硬币n=12次,然后观测到了s=9次人头朝上,f=3次背面朝上,则n=s+f.这时候n是固定的,但s和f都是随机的,所以相关的抽样分布就是二项分布:

$Bin(s|n,\theta)  = {\begin{pmatrix}n\\s\end{pmatrix}} \theta^s(1-\theta)^{n-s}  $(6.82)

设零假设就是硬币没有作弊,即$\theta=0.5$,这个$\theta$是人头朝上的概率.这样使用检验统计$t(s)=s$得到的单边p值(one-sided p-value)就是:

$p_1=P(S\ge 9|H_0)= \sum^{12}_{s=9} Bin(s|12,0.5)=\sum^{12}_{s=9} {\begin{pmatrix}12\\s\end{pmatrix}}0.5^{12}=0.073$(6.83)

双边P值(two-sided p-value)就是:

$p_2= \sum^{12}_{s=9} Bin(s|12,0.5)+ \sum^{3}_{s=0} Bin(s|12,0.5)=0.073+0.073=0.146$(6.84)

这两种情况中,P之都比神奇的5%阈值要大很多,所以频率论就不会拒绝零假设了.

然后设想我告诉你我一直扔硬币,直到我观测到了$f=3$次人头朝下为止.这时候f是固定的,而n和s是随机的.所以这时候概率模型就成了负二项分布(negative binomial distribution,):

$NegBinom(s|f,\theta)={\begin{pmatrix}s+f-1\\f-1\end{pmatrix}}\theta^s(1-\theta)^f$(6.85)
上式中的f=n-s.

要注意这个分布中依赖于$\theta$的项目和等式6.82与6.85中的是一样的,所以在$\theta$上的后验在两种情况下也都是一样的.不过对同样数据的两种解释给出了不同的P值.具体来说就是在负二项分布情况下的p值是:

$p_3=P(S\ge9|H_0)=\sum^\infty _{s=9}{\begin{pmatrix}s+3-1\\3-1\end{pmatrix}}(1/2)^s(1/2)^3=0.0327$(6.86)

这P值是3%,这样好像很明显硬币被做了手脚了!当然这很荒诞了,因为数据都是一样的,明显对硬币的推测也应该一样才对.不论如何也都是随机选择的实验协议.最重要的应该是试验结果,而不是对使用哪种试验方式的人为判断.

虽然这看上去有点像数学上的弯弯绕,但实际应用中也是有很大影响的.比如由于停止规则(stopping rule)影响到P值的计算,这就意味着频率论这往往倾向于推迟终结试验,甚至即便已经有明显结论了也是如此,至少这会严重影响他们的统计分析.如果试验成本很高而且对人有害,使用频率论和P值就明显是祸害.所以毫不意外,美国食品药品管理局(FDA)在对新药的测试中,都明确支持了贝叶斯方法了,因为贝叶斯方法不会受停止规则的影响.

### 6.6.3 似然性原则

频率论方法出现很多问题的根源所在就是违背了似然性原则(likelihood principle),这个原则是说推测应该建立在观测数据的似然率上,而不是建立在没观测到的假设未来数据上.贝叶斯方法明显满足这个原则,所以也就不会有频率论所遇到的那么多问题了.

Birnbaum 1962年提出了一个支持似然性原则的有力证据,其文章表明这个原则自觉遵循了两个更简单的原则.第一个就是充分原则(sufficiency principle),说的是一个充分统计应该包含了和未知参数相关的所有信息(定义即证明).第二个是弱条件原则(weak conditionality),说的是推论应该基于已经发生的事件,而不是可能发生的时间.要推导出这个,可以考虑Berger 1985年的一个例子.加入我们要分析一种物质,可以把它发到纽约或者加利福尼亚的实验室.这两个实验室都挺好,所以就用公平硬币假设.如果人头朝上,就选加州哪个实验室.当测试这个物质的结果回来的时候,会不会考虑硬币本来也可能背面朝上所以本来也可能应该送到纽约的实验室呢?大多数人会说因为硬币背面朝上没发生所以纽约的实验室与此无关.这就是一个弱条件的例子.给定了这个原则之后,就能发现所有推论都应该基于被观测到的现象上,而这对于标准频率论过程来说是恒定的.关于似然性原则的更多细节参考Berger and Wolpert 1988.

### 6.6.4 为啥大家不都选贝叶斯?


上文已经表明,频率论统计有种种缺陷,而贝叶斯方法却没有,那有人可能就会问:"为啥大家不都选贝叶斯?"1986年有一个频率论统计学家Bradley Efron还就以此为标题写过一篇文章.他这篇文章不长,但是很值得读一读.下面是他文章的开头部分:

>标题的这个问题被提出至少两次了.第一次是拉普拉斯(Laplace)曾经问过这个问题,他曾经是一个贝叶斯主义者,完全赞同贝叶斯公式来推断问题,十九世纪的大多数科学家也纷纷认同.这其中包含高斯(Gauss),而高斯的很多统计学方面的研究都是以频率论形式阐述的.
>第二次出现这个问题是关于贝叶斯合理性的争论.以Savage和 de Finetti为首的现代统计学家,对选中贝叶斯方法给出了很多高级的有力的理论证据.这个工作的副产物是频率论者眼中的术语不一致冲突.
>尽管如此,并不是所有人都是贝叶斯主义者.在当前(1986年)统计学终于开始广泛用于科研报道中了,而实际上二十世纪的统计学主要还是非贝叶斯的.不过Lindley(1975)预测这一情况会在21世纪发生变化.


时间会检验Lindley说的是不是对的...

练习略


# MLAPP 读书笔记 - 07 线性回归(Linear regression)

> A Chinese Notes of MLAPP,MLAPP 中文笔记项目 
https://zhuanlan.zhihu.com/python-kivy

记笔记的人：[cycleuser](https://www.zhihu.com/people/cycleuser/activities)

2018年06月15日13:41:04

## 7.1 概论

线性回归是统计学和(监督)机器学习里面的基本主力.使用核函数或者其他形式基函数来扩展之后,还可以用来对非线性关系进行建模.把高斯输出换成伯努利或者多元伯努利分部,就还可以用到分类上面,这些后文都会讲到.所以这个模型很值得详细学习一下.

## 7.2 模型选择


在本书1.4.5已经看到过线性回归了,其形式为:

$p(y|x\theta)=N(y|w^Tx\sigma^2)$(7.1)

线性回归也可以通过将x替换成为输入特征的非线性函数比如$\phi(x)$来对非线性关系进行建模.也就是将形式变成了:


$p(y|x\theta)=N(y|w^T\phi (x)\sigma^2)$(7.2)


这就叫基函数扩展(basis function expansion).(要注意这时候模型依然是以w为参数,依然还是线性模型;这一点后面会有很大用处.)简单的例子就是多项式基函数,模型中函数形式为:

$\phi(x)=[1,x,x^2,...,x^d]$(7.3)

图1.18展示了改变d的效果,增加d就可以建立更复杂的函数.

对于多输入的模型,也可以使用线性回归.比如将温度作为地理位置的函数来建模.图7.1(a)所示为:$\mathrm{E}[y|x]=w_0+w_1x_1+w_2x_2$,图7.1(b)所示为:$\mathrm{E}[y|x]=w_0+w_1x_1+w_2x_2+w_3x_1^2+w_4x_2^2$.


## 7.3 最大似然估计(最小二乘法)

最大似然估计(MLE)是估计统计模型参数的常用方法了,定义如下:

$ \hat\theta \overset{\triangle}{=} \arg\max_\theta \log p(D|\theta)$(7.4)

此处参考原书图7.1

通常假设训练样本都是独立同分布的(independent and identically distributed,缩写为iid).这就意味着可以写出下面的对数似然函数(log likelihood):

$l(\theta) \overset{\triangle}{=} \sum^N_{i=1}\log p(y_i|x_i,\theta)$(7.5)

我们可以去最大化对数似然函数,或者也可以等价的最小化负数对数似然函数(the negative log likelihood,缩写为NLL):

$NLL(\theta)\overset{\triangle}{=} -\sum^N_{i=1}\log p(y_i|x_i,\theta)$(7.6)

负对数似然函数(NLL)有时候更方便,因为很多软件都有专门设计找最小值的函数,所以比最大化容易.

接下来设我们对这个线性回归模型使用最大似然估计(MLE)方法.在上面的公式中加入高斯分布的定义,就得到了下面形式的对数似然函数:

$$
\begin{aligned}
l(\theta)&=  \sum^N_{i=1}\log[(\frac{1}{2\pi\sigma^2})^{\frac{1}{2}} \exp (-\frac{1}{2\sigma^2}(y_i-w^Tx_i)^2)   ]&\text{(7.7)}\\
&= \frac{-1}{2\sigma^2}RSS(w)-\frac{N}{2}\log(2\pi\sigma^2) &\text{(7.8)}\\
\end{aligned}
$$

上式中的RSS是residual sum of squares的缩写,意思是残差平方定义为:
$RSS(w)\overset{\triangle}{=} \sum^N_{i=1}(y_i-w^Tx_i)^2$    (7.9)


此处参考原书图7.2

RSS也叫做平方误差总和(sum of squared errors),这样也可以缩写成SSE,这样就有SSE/N,表示的是均方误差MSE(mean squared erro).也可以写成残差(residual errors)向量的二阶范数(l2 norm)的平方和:



$RSS(w)=||\epsilon||^2_2=\sum^N_{i=1}\epsilon_i^2$     (7.10)


上式中的$\epsilon_i=(y_i-w^Tx_i)^2$.

这样就能发现w的最大似然估计(MLE)就是能让残差平方和(RSS)最小的w,所以这个方法也叫作小二乘法(least squares).这个方法如图7.2所示.图中红色圆点是训练数据$x_i,y_i$,蓝色的十字点是估计数据$x_i,\hat y_i$,竖直的蓝色线段标识的就是残差$\epsilon_i=y_i-\hat y_i$.目标就是要寻找能够使平方残差总和(图中蓝色线段长度)最小的图中所示红色直线的参数(斜率$w_1$和截距$w_0$).

在图7.2(b)中是线性回归样例的负对数似然函数(NLL)曲面.可见其形态类似于一个单底最小值的二次型碗,接下来就要进行以下推导.(即便使用了基函数扩展,比如多项式之类的,这也是成立的,因为虽然输入特征可以不是线性的,单负对数似然函数依然还是以w为参数的线性函数.)


### 7.3.1 最大似然估计(MLE)的推导

首先以更好区分的形式重写目标函数(负对数似然函数):

$NLL(w)=\frac{1}{2}(y-Xw)^T(y-Xw)=\frac{1}{2}w^T(X^TX)w-w^T(X^Ty)$   (7.11)

上式中
$X^TX=\sum^N_{i=1}x_ix_u^T=\sum^N_{i=1}\begin{pmatrix} x_{i,1}^2&... x_{i,1}x_{i,D}\\&& ...&\\  x_{i,D}x_{i,1} &... & x_{i,D}^2 \end{pmatrix}$   (7.12)

是矩阵平方和（sum of squares matrix）,另外的一项为：

$X^Ty=\sum^N_{i=1}x_iy_i$   (7.13)

使用等式4.10中的结论,就得到了梯度函数（gradient）,如下所示：

$g(w)=[X^TXw-X^Ty]=\sum^N_{i=1} x_i(w^Tx_i-y_i)$   (7.14)

使梯度为零,则得到了：

$X^TXw=X^Ty$   (7.15)


这就是正规方程(normal equation).这个线性方程组对应的解$\hat w$就叫做常规最小二乘解（ordinary least squares solution,缩写为 OLS solution）：

$\hat w_{OLS}=(X^TX)^{-1}X^Ty$   (7.16)重要公式



### 7.3.2 几何解释


这个方程有很优雅的几何解释.假设N>D,也就意味样本比特征数目多.X列向量（columns）定义的是在N维度内的一个D维度的子空间.设第j列为$\tilde x_j$,是在$R^N$上的一个向量.(应该不难理解,$x_i\in R^D$表示的就是数据情况中的第i个.)类似的y也是一个$R^N$中的向量.例如,如果社N=3个样本,二D=2的子空间:

$X=\begin{pmatrix}1&2 \\ 1 &-2\\1 &2 \end{pmatrix},y=\begin{pmatrix}8.8957\\0.6130\\1.7761\end{pmatrix}$   (7.17)

这两个向量如图7.3所示.

然后我们就要在这个线性子空间中找一个尽可能靠近y的向量$\hat y\in R^N$,也就是要找到:

$\arg\min_{\hat\in span(\{ \tilde x_1,...,\tilde x_D \})} ||y-\hat y||_2$   (7.18)

由于$\hat y \in span(X)$,所以就会存在某个权重向量(weight vector)w使得:

$\hat y= w_1\tilde x_1+...+w_D\tilde x_D=Xw$   (7.19)


此处参考原书图7.3


要最小化残差的范数(norm of the residual)$y-\hat y$,就需要让残差向量(residual vector)和X的每一列相正交(orthogonal),也就是对于$j=1:D$有$\tilde x ^T_j (y-\hat y) =0$.因此有:



$\tilde x_j^T(y-\hat y)=0  \implies X^T(y-Xw)=0\implies w=(X^TX)^{-1}X^Ty$ (7.20)

这样y的投影值就是:

$\hat y=X\hat w= X(X^TX)^{-1}X^Ty$(7.21)

这对应着在X的列空间(column space)中的y的正交投影(orthogonal projection).投影矩阵$P\overset{\triangle}{=} X(X^TX)^{-1}X^T$就叫做帽子矩阵(hat matrix),因为在y上面盖了个帽子成了$\hat y$.


### 7.3.3 凸性质

在讲到最小二乘法的时候,我们注意到负对数似然函数(NLL)形状像是一个碗,有单一的最小值.这样的函数用专业术语来说是凸(convex)的函数.凸函数在机器学习里面非常重要.

然后咱们对这个概念进行一下更确切定义.设一个集合S,如果对于任意的$\theta,\theta'\in S$,如果有下面的性质,则S是凸的集合:

$\lambda\theta+(1-\lambda)\theta'\in S, \forall  \lambda\in[0,1]$(7.22)

此处参考原书图7.4
此处参考原书图7.5

也就是说在$\theta$和$\theta'$之间连一条线,线上所有的点都处在这个集合之内.如图7.4(a)所示就是一个凸集合,而图7.4(b)当中的就是一个非凸集合.

一个函数的上图(epigraph,也就是一个函数上方的全部点的集合)定义了一个凸集合,则称这个函数$f(\theta)$就是凸函数.反过来说,如果定义在一个凸集合上的函数$f(\theta)$满足对任意的$\theta,\theta'\in S$,以及任意的$0\le\lambda\le1$,都有下面的性质,也说明这个函数是凸函数:

$f(\lambda \theta +(1-\lambda)\theta')\le \lambda f(\theta) +(1-\lambda)f(\theta ')$ (7.23)

图7.5(b)是一个一维样本.如果不等式严格成立,就说这个函数是严格凸函数(strictly convex).如果其反函数$-f(\theta)$是凸函数,则这个函数$f(\theta$是凹函数(concave).标量凸函数(scalar convex function)包括$\theta^2,e^\theta,\theta\log\theta (\theta>0)$.标量凹函数(scalar concave function)包括$\log(\theta),\sqrt\theta$.

直观来看,(严格)凸函数就像是个碗的形状,所以对应在碗底位置有全局的唯一最小值$\theta^*$.因此其二阶导数必须是全局为正,即$\frac{d}{d\theta}f(\theta)>0$.当且仅当一个二阶连续可微(twice-continuously differentiable)多元函数f的海森矩阵(Hessian)对于所有的$\theta$都是正定的(positive definite),这个函数才是凸函数.在机器学习语境中,这个函数f通常对应的都是负对数似然函数(NLL).

此处参考原书图7.6


负对数似然函数(NLL)是凸函数的模型是比较理想的.因为这就意味着能够找到全局最优的最大似然估计(MLE).本书后面还会看到很多这类例子.不过很多模型还并不一定就能有凹的似然函数.这时候就要推一些方法来求局部最优参数估计了.



## 7.4 健壮线性回归*


通常我们用均值为零且方差固定的正态分布$\epsilon_i\sim N(0,\sigma^2)$来对回归模型的噪音建模,$\epsilon_i=y_i-w^Tx_i$.这时候对似然函数最大化就等价于使平方残差总和(sum of squared residuals)最小,这部分之前刚才已经讲过了.不过如果在数据里面有异常值/离群点(outliers),就容易影响你和质量,如图7.6(a)所示,图底部的几个点就是异常值.这是因为平方差(squared error)以二次形式惩罚偏差,所以远离拟合曲线的点会比临近曲线的点对拟合有更大的影响.

有一种方法可以实现对异常值的健壮性,就是把对响应变量的正态分布替换成更重尾(heavy tails)的分布.这样的分布赋予异常值更高似然性,而不用改变直线去特地解释这些异常值.

拉普拉斯分布(Laplace distribution)就是一个选择,如本书2.4.3所示.如果用拉普拉斯分布来对回归的观测模型建模,就得到了下面的似然函数:

$p(y|x,w,b)=Lap(y|w^Tx,b)\propto \exp (-\frac{1}{b}|y-w^Tx|)$(7.24)

为了健壮性,将平方项替换成绝对值,即用$|y-w^Tx|$替换$(y-w^Tx)^2$.为了简单起见,这里就设b是一个固定值.然后设第i个残差为$r_i \overset{\triangle}{=} y_i-w^Tx_i$.这样负对数似然函数(NLL)就成了:

$l(w)=\sum_i|r_i(w)|$(7.25)





|似然函数|先验|名称|章节|
|---|---|---|---|
|正态分布|均匀先验|最小二乘法|7.3|
|正态分布|正态分布|岭回归|7.5|
|正态分布|拉普拉斯|套索回归(Lasso)|13.3|
|拉普拉斯|均匀先验|健壮回归|7.4|
|学生分布|均匀先验|健壮回归|练习11.12|

表 7.1 对线性回归中各种似然函数和先验的总结.似然函数指的是$p(y|x,w,\sigma^2)$的分布,先验指的是$p(w)$的分布.均匀分布的最大后验估计(MAP)对应的就是最大似然估计(MLE).


然而很不幸,等式7.25是一个非线性的目标函数,很难去优化.还好我没可以将负对数似然函数(NLL)转化成一个线性目标函数,受线性约束的限制,这需要用到分割变量(split variable)的技巧.首先定义:

$r_i \overset{\triangle}{=} r_i^+-r_i^-$(7.26)

然后将线性不等式约束带入,即$r_i^+\ge 0,r_o^-\le 0$.这样受约束的目标函数就成了:

$\min_{w,r^+,r^-}\sum_i(r^+-r_i^-)  s.t. r_i^+\ge 0,r_i^-\ge 0,w^Tx_i+r_i^++r_i^-=y_i$(7.27)

这就是一个线性规划(linear program),有D+2N未知和3N约束.(This is an example of a linear program with D + 2N unknowns and 3N constraints.)

因为这是一个凸优化问题,所以有唯一解.要解线性规划(LP),必须首先将其写成标准型:

$\min_{\theta}f^T\theta  s.t. A\theta \le b,A_{ep}\theta=b_{eq},1\le\theta\le u$(7.28)

目前在咱们的例子中,$\theta=(w,r^+,r^-),f=[0,1,1],A=[],b=[],A_{eq}=[X,I,-I],b_{eq}=y,I=[-\infty1,0,0],u=[]$.这可以通过线性规划求解器(LP solver)(参考Boyd and Vandenberghe 2004).图7.6(b)所示为具体方法的一个例子.

除了拉普拉斯似然函数下使用负对数似然函数,另一种方法是最小化胡贝尔损失函数(Huber loss function,出自 Huber 1964),定义如下:

$L_H(r,\delta)=\begin{cases} r^2/2 &\text{  if  } |r|\le \delta\\\delta|r|-\delta^2/2&\text{  if  }|r|>\delta \end{cases}$(7.29)

这个定义等价于对小于$\delta$的误差使用二次损失函数$l_2$,对大于$\delta$的误差使用一次损失函数$l_1$.如图7.6(b)所示.这个损失函数的优势就是全局可微(everywhere differentiable),这是利用了当$r\ne 0$时候$\frac{d}{dr}|r|=sign(r)$.还可以验证这个函数是$C_1$连续的,因为两部分函数的梯度都符合$r=\pm \delta$,名义上就是$\frac{d}{dr}L_H(r,\delta)|_{r=\delta}=\delta$.结果就是胡贝尔损失函数油画起来比拉普拉斯似然函数容易多了,因为可以使用标准光滑优化方法(比如拟牛顿法,quasi-Newton),而不用使用线性规划了.

图7.6(a)所示的就是胡贝尔损失函数.结果和概率方法的结果很相似.实际上胡贝尔方法确实也有一种概率角度的解释,不过就是不太自然 (Pontil et al).

此处参考原书图7.7

## 7.5 岭回归

最大似然估计中一大问题就是过拟合.在本节要讲的就是使用高斯先验的最大后验估计来改善这个问题.为了简单起见,本节用高斯似然函数,而不用健壮似然函数了.

### 7.5.1 基本思想

最大似然估计过拟合的原因就是它选的参数都是最适合对训练数据建模的;但如果训练数据有噪音,这些参数就经常会形成非常复杂的函数.举个简单的例子,对一个N=21个点的数据使用最小二乘法拟合一个14次多项式曲线.得到的函数就可能是非常七扭八歪,如图7.7(a)所示.对应的除了$w_0$之外的最小二乘系数为:

6.560, -36.934, -109.255, 543.452, 1022.561, -3046.224, -3768.013,
8524.540, 6607.897, -12640.058, -5530.188, 9479.730, 1774.639, -2821.526


可见其中有很多特别大的正数和负数.这些系数让曲线七扭八歪,完美地插入所有数据.但这就很不稳定:如果我们稍微改变一下数据,系数就会发生巨大变化.

可以让系数小一点,这样得到的就是更光滑的曲线,使用一个零均值高斯先验就可以了:


$p(w)=\prod_j N(w_j|0,\tau^2$(7.30)

其中的$1/\tau^2$控制了先验强度.对应的最大后验估计(MAP)问题就是:


$\arg\max_w\sum^N_{i=1}\log N(y_i|w_0+w^Tx_i,\sigma^2)+\sum^D_{j=1}\log(w_j|0,\tau^2)$(7.31)


此处参考原书图7.8

很容易证明上面这个问题等价于对下面这个项目求最小值:

$J(w)=\frac{1}{N}\sum^N_[i=1}(y_i-(w_0+w^Tx_i))^2+\lambda||w||^2_2$(7.32)

其中的$\lambda\overset{\triangle}{=} \sigma^2/\tau^2$,而$||w||^2_2=\sum_j w^Tw$是平方二范数(squared two-norm).这样第一项就依然还是均方误差比负对数似然函数(MSE/NLL),第二项$\lambda\ge 0$就是符合惩罚项.对应的解为:

$\hat w_{ridge}=(\lambda I_D+X^TX)^{-}X^Ty$(7.33)重要公式

这个方法就叫做岭回归(ridge regression),也叫惩罚最小二乘法(penalized least squares).通常,将用高斯先验来使参数变小的方法叫做$l_2$规范化($l_2$ regularization),或者叫做权重衰减(weight decay).要注意,偏移项$w_0$并不是规范化的,因为这只影响函数的高度,而不影响其复杂性.通过对权重烈度综合(sum of the magnitudes of the weights)进行惩罚,能确保函数尽量简单(比如w=0对应的就是一条直线,也就是最简单的函数了,对应是常数.)

图7.7所示为此方法的思想,图中表明增加$\lambda$就会导致函数曲线更加光滑.得到的系数也更小.例如使用$\lambda=10^{-3}$,就得到了下面的系数:

2.128, 0.807, 16.457, 3.704, -24.948, -10.472, -2.625, 4.360, 13.711,
10.063, 8.716, 3.966, -9.349, -9.232

在图7.8(a)中,对训练集上的均方误差(MSE)和$\log(\lambda)$的函数关系进行头图.可见随着增长$\lambda$,也就是让模型受约束程度增加,训练集上的误差也增加了.对于测试集,就呈现了U形曲线的,也就是模型先是过拟合,然后又欠拟合.通常都用交叉验证来选择$\lambda$,如图7.8(b)所示.在本书14.8,会用更加概率论的方法来对此进行讲解.

本书中会考虑到使用不同先验的效果.每一种都对应着不同形式的规范化(regularization).这个方法广泛用于防止过拟合.


### 7.5.2 数值稳定计算*

有意思的是,岭回归不仅在统计学上效果更好,也更容易进行数值拟合,因为$(\lambda I_D+X^TX)$比$X^TX$有更好条件(更容易可逆),至少对于适当的大的$\lambda$.

尽管如此,出于数值计算稳定性考虑,矩阵求逆还是尽量要避免的.(比如如果你在MATLAB里面写了$w=inv(X;*X)*X'y$,都会遇到警告.)接下来咱们讲一个拟合岭回归模型的有用技巧(另外通过扩展也可以用于计算Vanilla普通最小二乘估计(Ordinary least squares,OLS)),使数值计算健壮性提高.假设先验形式为$p(w)=N(0,\Lambda ^2)$,其中的$\Lambda$是精度矩阵(precision matrix).在岭回归的情况下,$\Lambda=(1/\tau^2)I$.为了避免惩罚$w_0$项,应该先将数据中心化,如练习7.5所讲.

首先从先验中哪来一些虚拟数据来对原始数据进行扩充:

$\tilde X= \begin{pmatrix} X/\sigma\\ \sqrt\Lambda \end{pmatrix}, \tilde y =\begin{pmatrix} y/\sigma \\ 0_{D\times 1} \end{pmatrix}$(7.34)

$$
\begin{aligned}
f(w)&=  (\tilde y- \tilde X w)^T(\tilde y-\tilde X m)                &\text{(7.35)}\\
&=  (\begin{pmatrix} y/\sigma \\ 0 \end{pmatrix} -\begin{pmatrix} X/\sigma\\ \sqrt\Lambda \end{pmatrix} w)^T  (\begin{pmatrix} y/\sigma \\ 0 \end{pmatrix} -\begin{pmatrix} X/\sigma\\ \sqrt\Lambda \end{pmatrix} w)              &\text{(7.36)}\\
&=  (\begin{pmatrix} \frac{1}{\sigma}(y-XW)\\ \sqrt\Lambda w \end{pmatrix})^T   (\begin{pmatrix} \frac{1}{\sigma}(y-XW)\\ \sqrt\Lambda w \end{pmatrix})              &\text{(7.37)}\\
&=  \frac{1}{\sigma^2}(y-Xw)^T(y-Xw)+(\sqrt\Lambda)^T(\sqrt\Lambda)              &\text{(7.38)}\\
&= \frac{1}{\sigma^2}(y-Xw)^T(y-Xw)+ w^T\Lambda w                   &\text{(7.39)}\\
\end{aligned}
$$

因此最大后验估计就是:

$\hat w_{ridge}= (\tilde X^T \tilde X )^{-1} \tilde X^T \tilde y$(7.40)

然后设:
$\tilde X=QR$(7.41)
是X的QR分解(QR decomposition),其中的Q是正交的(即$Q^TQ=QQ^T=I$),而R是上三角矩阵(upper triangular).因此有:

$(\tilde X^T\tilde X)^{-1}=(R^TQ^TQR)^{-1}=(R^TR)^{-1}=R^{-1}R^{-T}$(7.42)

因此有:

$\hat w_{ridge}= R^{-1}R^{-T}R^TQ^T\tilde y=R^{-1}Q \tilde y$(7.43)

由于R是上三角矩阵,所以求逆很容易.这就可以避免去对$\Lambda+X^TX$求逆就可以计算岭估计了.

这样,只要简单地计算未扩展矩阵X的QR分解,再利用原始的y,就可以计算最大似然估计(MLE)了.对于解最小二乘问题来说,这是首选方法.(实际上这个特别常用,在MATLAB里面只要一行代码就可以了,使用的是反斜杠运算符(backslash operator): w=X\y.)计算一个$N\times D$规模矩阵的QR分解只需要$O(ND^2)$的时间复杂度,所以在数值计算上很稳定.

如果D远大于N,即$D\gg N$,就要先进行SVD分解.具体来说就是设$X=USV^T$为X的SVD分解,其中的$V^TV=I_N,UU^T=U^TU=I_N$,S是一个$N\times N$的对角矩阵.然后设$Z=UD$是一个$N\times N$矩阵.然后可以将岭估计写成下面的形式:


$\hat w_{ridge} =V(Z^TZ+\lambda I_N)^{-1}Z^Ty$(7.44)



也就是说可以把D维度向量$x_i$替换成N维的向量$z_i$,然后跟之前一样进行惩罚拟合.接下来通过乘以一个V再把得到的N维的解转换成D维的解.几何角度来说,就旋转到一个新的坐标系统中,其中除了前面的N个参数之外其他参数都是0.这不会影响解的有效性,因为球面高斯先验(spherical Gaussian prior)具有旋转不变性(rotationally invariant).这个方法总体需要$O(DN^2)$的运算时间.


### 7.5.3 和主成分分析(PCA)的联系*

在本节要说岭回归和主成分分析(PCA,本书12.2)之间的联系,这一联系也会让我们明白为啥岭回归性能如此好.这部分的讨论基于(Hastie et al. 2009, p66).

设$X=USV^T$是X的SVD分解.通过等式7.44,可以得到:
$\hat w_{ridge} = V(S^2+\lambda I)^{-1}SU^Ty$(7.45)

这样就得到岭回归对训练集的预测:
$$
\begin{aligned}
\hat y &=   X\hat w_{ridge}=USV^TV(S^2+\lambda I)^{-1}SU^Ty             &\text{(7.46)}\\
&=  U\tilde SU^Ty=\sum^D_{j=1}u_j\tilde S_{jj}u_j^Ty   &\text{(7.47)}\\
\end{aligned}
$$

此处参考原书图7.9

其中的
$\tilde S_{jj} \overset{\triangle}{=} [S(S^2+\lambda I)^{-1}S]_{jj}=\frac{\sigma_j^2}{\sigma^2_j+\lambda }$(7.48)

$\sigma_j$是X的奇异值(singular values).因此有:

$\hat y= X\hat w_{ridge}=\sum^D_{j=1}u_j\frac{\sigma^2_j}{\sigma^2_j+\lambda}u_j^Ty$(7.49)

与之对比的最小二乘法预测为:

$\hat y = X\hat w_{ls}=(USV^T))VS^{-1}U^Ty)=UU^Ty=\sum^D_{j=1}u_ju_j^Ty$(7.50)


如果和$\lambda$相比$\sigma^2_j$很小,那么方向(direction)$u_j$就不会对预测有太大影响.从这个角度来看,可以定义一个模型自由度(degrees of freedom)的有效数字,如下所示:


$dof(\lambda)= \sum^D_{j=1}\frac{\sigma^2_j}{\sigma^2_j+\lambda}$(7.51)
当$\lambda =0,dof(\lambda)=D$,而随着$\lambda \rightarrow \infty,dof(\lambda)\rightarrow 0$.

接下来说说为啥这个性质很理想.在7.6中,我们会看到如果对w使用一个均匀先验,就有$cov[w|D]=\sigma^2(X^TX)^{-1}$.因此那些我们不确定w的的方向(direction)是由由最小特征值的矩阵的特征向量决定的,如图4.1所示.更进一步,在本书12.2.3中,我们会发现平方奇异值(squared singular values)$\sigma_j^2$等于$X^TX$的特征值.因此小的奇异值$\sigma_j$对应的就是高后验方差(high posterior variance)的方向.这些方向也是岭回归收缩最大的方向.

这个过程如图7.9所示.横向的$w_1$参数没能由数据确定(有高后验方差),而竖直方向上的$w_2$参数相当确定.因此$w_2^{map}$很接近$\hat w_2 ^{mle}$,但$w_1^{map}$严重朝向先验均值(这个例子中是0)偏移.(可以和图4.14(c)比对来看,图4.14(c)所示的是不同可靠性传感器的传感器融合.)

还有一个与之相关但不太一样的方法,叫做主成分回归(principal components regression).这个方法的思路是:首先使用主成分分析(PCA)来降低数据维度到K维度,然后利用低维度特征作为输入特征进行回归.不过,这个方法的预测精确性上并不如岭回归这样好(Hastie et al. 2001, p70).原因是在主成分回归中,只有前K个(推导出来的)维度还保留着,而剩下的D-K个维度的信息都全被忽略了.而相比之下,岭回归是对所有维度进行了软加权(soft weighting).

### 7.5.4 大规模数据的规范化效应


规范化(regularization)是避免过拟合的最常用方法.不过还有另外一种有效的方法,就是使用大规模数据,当然了,这个不一定总能实现.直观来看就是训练用的数据规模更多,进行学习的效果就能越好.所以我们期望随着数据规模N增大,测试误差就逐渐降低到某个定值.

这个如图7.10所示,图中为不同次数多项式回归和样本规模N下的均方误差(mean squared error)(误差和训练集样本规模的曲线也叫作学习曲线(learning curve)).测试集上误差的形态有两方面决定:生成过程中的内在变异性导致的对于所有模型都会出现的无法降低的部分(也叫作噪音本底);另一个依赖于生成过程(真实情况)和模型之间差异导致的部分(也叫作结构误差,structural error).

图7.10中所示,真实情况应该是一个二次多项式,而我们分别用1次/2次/25次多项式对这个数据进行拟合.得到的三种模型对应就称之为$M_1,M_2,M_{25}$.从图中可以发现,$M_2,M_{25}$的结构误差都是0,因为都能够捕获真实生成过程.不过$M_1$的结构误差就特别大,这就证明了其远高于误差本底.

对于任何足以捕获真实情况的模型(也就是说有最小结构误差),测试误差都会随着样本规模增大即$N\rightarrow \infty$而趋向噪音本底.不过对于简单模型来说通常会更快趋向于0,因为要估计的参数更少.具体来说就是对于有限规模的训练集来说,我们估计得参数和给定模型类别能进行估计的最佳参数之间总是会有一些差异.这就叫做近似误差(approxmation error),会随着训练集样本规模增大,即$N\rightarrow \infty$而趋向于0,但对于简单模型来说趋向于0的速度更快.这个如图7.10所示,另外也可以参考练习7.1.

在大数据领域,简单模型效果出乎意料地好(Halevy et al. 2009).不过还是有必要学习一些更复杂的学习方法的,因为总会有一些问题中咱们没办法获得特别多的数据.甚至即便在一些数据丰富的情境下,比如网络搜索中,只要我们想要根据用户进行个性化结果生成,对任意用户的可用数据规模也都会变小(相比问题复杂程度而言).

此处参考原书图7.10

在这样的情况下,就可能需要同时学习多种相关模型,也就是所谓的多任务学习(multi-task learning).这个过程可以从有大量数据的任务中"借用统计强度"给数据规模小的任务.相关方法在本书后文中还会讲到.

## 7.6 贝叶斯线性回归

虽然岭回归是计算点估计的有效方法,有时候还可能要对w和$\sigma^2$的全后验进行计算.为了简单起见,就假设噪音方差$\sigma^2$已知,就只要关注与计算$p(w|D,\sigma^2)$.然后在本书7.6.3考虑更通用的情况,计算$p(w,\sigma^2|D)$.假设使用整个高斯释然模型(throughout a Gaussian likelihood model).使用一个健壮似然函数进行贝叶斯推断也是可行的,不过需要更复杂技巧(参考练习24.5).

### 7.6.1 计算后验

在线性回归中,似然函数为:

$$
\begin{aligned}
p(y|X,w,\mu,\sigma^2)& =N(y|\mu+Xw,\sigma^2I_N)             &\text{(7.52)}\\
& \propto \exp(-\frac{1}{2\sigma^2}(y-\mu1_N-Xw)^T(y-\mu1_N-Xw))           &\text{(7.53)}\\
\end{aligned}
$$

其中的$\mu$是偏移项.如果输入值是中心化的,则对于每个j都有$\sum_ix_{ij}=0$,输出均值正负概率相等.所以假设一个不适当先验(improper prior)给$\mu$,形式为$p(\mu)\propto 1$,然后整合起来就得到了:


$p(y|X,w,\sigma^2)\propto \exp( -\frac{1}{2\sigma^2}||  y-\bar y1_N-Xw  ||^2_2 )$(7.54)

其中的$\bar y =\frac{1}{N} \sum^N_{i=1} y_i$ 是输出的经验均值.为了表达简洁,假设输出已经中心化了,然后将$y-\bar y1_N$写作为y.

上面这个高斯似然函数的共轭先验也还是高斯分布,可以表示做$p(w)\N(w|w_0,V_0)$.利用高斯分布的贝叶斯规则(灯饰4.125),就得到了下面的后验:


$$
\begin{aligned}
p(w|X,y,\sigma^2)& \propto N(w|w)0,V_0)N(y|Xw,\sigma^2I_N)=N(w|w_N,V_N) &\text{(7.55)}\\
W_N& = V_NV_0^{-1}w_0+\frac{1}{\sigma^2}V_NX^Ty &\text{(7.56)}\\
V_N^{-1}& = V_0^{-1}+\frac{1}{\sigma^2}X^TX  &\text{(7.57)}\\
V_N& = \sigma^2(\sigma^2V_0^{-1}+X^TX)^{-1} &\text{(7.58)}\\
\end{aligned}
$$

如果$w_0=0,V_0=\tai^2I$,且定义$\lambda=\frac{\sigma^2}{\tau^2}$那么后验均值就降低到了岭估计.这是因为高斯分布的均值和众数相等.

要对后验分布获得更深入了解(而不是只知道众数),可以考虑一个1维例子:

$y(x,w)=w_0+w_1x+\epsilon$(7.59)
其中的真实参数为$w_0=-0.3,w_1=0.5$.如图7.11所示是先验/似然函数/后验以及一些后验预测样本.具体来说最右边一列是函数$y(x,w^{(s)})$,其中的x取值范围在区间[-1,1],而$w^{(s)}\sim N(w|w_N,V_N)$是从参数后验重取样的一个样本.开始的时候从先验中取样(第一行),预测就是遍布整个空间,因为先验是均匀的.随着看到了数据点之后(第二行),后验就开始收到对应的似然函数的约束了,预测也更接近观测数据了.不过我们会发现后验还是有岭状形态,反映了多解性的存在,有不同的斜率/截距.这很好理解,因为我们不能从一次观测中推出两个参数来.在看到两个点之后(第三行),后验就更窄了,预测也有更相似的斜率截距了.在观测了20个数据点之后(最后一行)后验就成了一个以真实值为中心的$\delta$函数的形状了,真实值用白色十字表示.(这个估计会收敛到真实值是因为数据是从这个模型生成的,还因为贝叶斯估计其是连续估计器,更多细节参考本书6.4.1的讲解.)

此处参考原书图7.11


### 7.6.2 计算后验预测

作预测总是很难,尤其是预测未来.---Yogi Berra

在机器学习我们都更关注预测,而不是对参数的解析.利用等式4.126,可以很明显发现对于测试点x的后验预测分布也是一个高斯分布:

$$
\begin{aligned}
p(y|x,D,\sigma^2)& = \int N(y|x^Tw,\sigma^2)N(w|w_N,V_N)d w  &\text{(7.60)}\\
&= N(y|w^T_Nx,\sigma^2_N(x))  &\text{(7.61)} \\
\sigma^2_N(x)&= \sigma^2+x^TV_Nx  &\text{(7.62)} \\
\end{aligned}
$$

上面这个预测分布中的方差$\sigma^2_N(x)$取决于两个项:观测噪音的方差$\sigma^2$,参数方差$V_N$.后面这一项表示为观测方差,取决于测试点x和训练数据集D之间的距离关系.这如图7.12所示,其中误差范围随着远离训练样本中的点而增大,表示着不确定性的增加.这对于主动学习等领域来说很重要,在这些领域中我们要建模的对象是我们了解程度远不如已知数据的点.对比之下,这个插值估计就有固定的误差范围,因为:

$p(y|x,D,\sigma^2)\approx \int N(y|x^Tw,\sigma^2)\delta_{\hat w}(w)d w=p(y|x,\hat w,\sigma^2 )$(7.63)

如图7.12(a)所示.


### 7.6.3 $\sigma^2$未知的情况下用贝叶斯推断*


在这一部分利用本书4.6.3的结论,解决在线性回归模型中计算$p(w,\sigma^2,D)$的问题.这就能推出本书7.6.1当中的结论,当时是假设$\sigma^2$是已知的.如果使用无信息先验,就会发现这和频率论统计学有一些有趣的联系.


#### 7.6.3.1 共轭先验


一如既往,先写出似然函数:
$p(y|X,w,\sigma^2)=N(y|Xw,\sigma^2I_N)$(7.64)

类似本书4.6.3,很明显自然共轭先验形式如下所示:
$$
\begin{aligned}
& p(w,\sigma^2)= NIG(w,\sigma^2|w_0,V_0,a_0,b_0 &\text{(7.65)}\\
& \overset{\triangle}{=} N(w|w_0,\sigma^2V_0)IG(\sigma^2|a_0,b_0) &\text{(7.66)}\\
& = \frac{b_0^{a_0}}{(2\pi)^{D/2}|V_0|^{\frac 12} \Gamma (a_0)} (\sigma^2)^{-(a_0+(D/2)+1)} &\text{(7.67)}\\
& \times \exp[-\frac{(w-w_0)^TV_0^{-1}(w-w_0)+2b_0}{2\sigma^2}] &\text{(7.68)}\\
\end{aligned}
$$

此处参考原书图7.12

有了先验和似然函数,就可以得到后验如下所示:

$$
\begin{aligned}
p(w,\sigma^2|D)& =  NIG(w,\sigma^2|w_N,V_N,a_N,b_N)  &\text{(7.69)}\\
w_N& = V_N(V_0^{-1}w_0+X^Ty)   &\text{(7.70)}\\
V_N& =  (V_0^{-1} +X^TX)^{-1} &\text{(7.71)}\\
a_N& = a_0 +n/2   &\text{(7.72)}\\
b_N& = b_0+\frac{1}{2}(w_0^TV_0^{-1}w_0+y^Ty-w_N^TV^{-1}_Nw_N)   &\text{(7.73)}\\
\end{aligned}
$$

$w_N$和$V_N$就和$\sigma^2$已知的情况类似了.$a_N$的表达时也很直观很好理解,就是用来对计数进行更新的.$b_N$的表达式可以按照下面方式理解:先验平方和$b_0$加上经验平方和$y^Ty$,另外加一个w的先验误差项.

$$
\begin{aligned}
p(\sigma^2|D)&= IG(a_N,b_N) &\text{(7.74)}\\
p(w|D)&= T(w_N,\frac{b_N}{a_N}V_N,2a_N) &\text{(7.75)}\\
\end{aligned}
$$


接下来给一个利用7.6.3.3当中等式的应用样例.

类似本书4.6.3.6,这个后验预测分布也是一个学生T分布.
具体来说给定了m次新测试特征$\tilde X$,就有:

$p(\tilde y|\tilde X,D) =T(\tilde y|\tilde Xw_N,\frac{b_N}{a_N}(I_m+\tilde XV_N\tilde X^T) ,2a_N )$(7.76)

预测方差有两个部分:首先是由于测量噪音导致的$(b_N/a_N)I_m$,另一个是由于对w不确定性的$(b_N/a_N)\tilde X V_N \tilde X^T$.后面这一项取决于测试输入和训练集的距离.

通常都设置$a_0=b_0=0$,对应的就是对$\sigma^2$的无信息先验,然后设置$w_0=0,V_0=g(X^TX)^{-1}$,对应的任意正值g.这也叫做Zellner’s g-prior(Zellner 1986).这里的g扮演的角色类似岭回归里面的$1/\lambda$.不过,区别是先验协方差正比于$(X^TX)^{-1}$而不是岭回归里面的I.这就保证了后验和输入范围无关(Minka 2000b).这也可以参考7.10.

接下来看个例子,如果我们使用一个无信息先验,给定N次测量的后验预测分布就是$V^{-1}_N=X^TX$.单位信息先验(unit information prior)定义为单样本包含尽量多信息的先验(Kass and Wasserman 1995).要对线性回归建立单位信息先验,需要使用$V^{-1}_0=\frac{1}{N}X^TX$就等价于g=N的g先验.


#### 7.6.3.2 无信息先验

$$
\begin{aligned}
p(w,\sigma^2|D)&= NIG(w,\sigma^2|w_N,V_N,a_N,b_N)  &\text{(7.77)}\\
w_N&=\hat w _{mle}=(X^TX)^{-1}X^Ty  &\text{(7.78)}\\
V_N&= (X^TX)^{-1} &\text{(7.79)}\\
a_N&= \frac{N-D}{2} &\text{(7.80)}\\
b_N&= \frac{2^2}{2} &\text{(7.81)}\\
s^2&= (y-X\hat w_{mle})^T(y-X\hat w_{mle}) &\text{(7.82)}\\
\end{aligned}
$$


|---|---|---|---|---|
|$w_j$|$\mathrm{E}[w_j|D ]$|$\sqrt{var [w_j|D]}$|95\%CI|sig|

|$w_j$|期望|标准差|95\%置信区间|显著性|
|---|---|---|---|---|
|w0|10.998|3.06027|[4.652,17.345]|\*|
|w1|-0.004|0.00156|[-0.008,-0.001]|\*|
|w2|-0.054|0.02190|[-0.099,.0.008]|\*|
|w3|0.068|0.09947|[-0.138,0.274]||
|w4|-1.294|0.56381|[-2.463,-0.124]|\*|
|w5|0.232|0.10438|[0.015,0.448]|\*|
|w6|-0.357|1.56646|[-3.605,2.892]||
|w7|-0.237|1.00601|[-2.324,1.849]||
|w8|0.181|0.23672|[-0.310,0.672]||
|w9|-1.285|0.86485|[-3.079,0.508]||
|w10|-0.433|0.73487|[-1.957,1.091]||



表7.2 对卡特彼勒数据(caterpillar data)使用无信息先验的线性回归模型的后验均值,标准偏差,置信区间.由本书配套PMTK3的linregBayesCaterpillar生成.

权重的边缘分布为:
$p(w|D)=T(w|\hat w,\frac{s^2}{N-D}C,N-D)$(7.83)
上式中的$C=(X^TX)^{-1}$,$\hat w$是最大似然估计(MLE).这些等式的含义后面会讲.

#### 7.6.3.3 贝叶斯和频率论相一致的样例*

(半共轭)的无信息先验很有意思,因为得到的后验等价于从频率论统计学推出来的结果(参考本书4.6.3.9).比如从等式7.83可以得到:

$p(w_j|D)=T(w_j|\hat w_j,\frac{C_{jj}s^2}{N-D},N-D)$(7.84)

这就等价于对最大似然估计(MLE)的抽样分布,其形式如下所示(Rice 1995, p542), (Casella and Berger 2002, p554):

$\frac{w_j-\hat w_j}{s_j}\sim t_{N-D}$(7.85)

其中的:

$s_j=\sqrt{\frac{s^2C_{jj}}{N-D}}$(7.86)

是估计参数的标准差.(本书6.2有讲到取样分布.)结果就是对参数的频率论的置信区间和贝叶斯边缘置信区间在这个样本中是一样的.

还拿卡特彼勒数据集为例(Marin and Robert 2007).(这个数据集的细节含义并不重要.)可以使用等式7.84来计算回归系数的后验均值/标准差/95%置信区间.结果如表7.2所示.很明显这些95%置信区间等价于使用标准频率论方法计算得到的95%置信区间(这部分代码参考本书配套PMTK3的linregBayesCaterpillar).
还可以使用边缘厚颜来计算回归参数是否显著(significantly)远离0.一个不太正规(根本不用到决策规则)的方法就是检查其95%置信区间是否排除了0.从表7.2可以得知通过这个可以衡量得到系数0,1,2,4,5都是显著的,所以加了个小星星.很容易验证这些结果和标准频率论软件得到的p值为5%的结果一样.

对于某些读者而言,可能贝叶斯方法和频率论得到结果的对应关系很让人惊讶,本书6.6当中还提到过频率论方法中的各种问题.另外还要注意到当N<D的时候,最大似然估计(MLE)根本不存在,所以标准频率论方法这时候就不能用了.不过贝叶斯推断的方法还是可以用的,虽然需要使用适当的先验.(参考(Maruyama and George 2008) 有讲到对g先验扩展以用于D>N的情况.)


### 7.6.4 线性回归的经验贝叶斯方法(证据程序)

目前为止都是假设先验为已知的.本节要说的经验贝叶斯过程是用来挑选超参数的.也就是说要挑选能够将边缘似然函数最大化的$\eta=(\alpha,\lambda)$,其中$\lambda=1/\sigma^2$是观测噪音的精度,而$\alpha$是先验精度,先验是$p(w)=N(w|0,\alpha^{-1}I)$.这也叫做证据程序(evidence procedure)(MacKay 1995b). 算法上的细节参考本书13.7.4.


证据程序可以作为交叉验证的一个替代方法.比如在图7.13(b)中所示的不同值$\alpha$对应的对数边缘似然函数,以及通过优化器找到的最大值.可见在这个例子中,得到的和5叠交叉验证中的结果(如图7.12(a)中所示)一样.(在两种方法的样例中都使用了固定的$\lambda= 1/\sigma^2$,以保证可对比性.)


证据程序相比交叉验证的主要的实践优势,在本书13.7当中才更明显,到时候回对每个特征使用不同的$\alpha_j$来将先验泛化扩展.这可以用于进行特征选择,使用一种叫做自动相关性判别(automatic relevancy determination,缩写为ARD)的方法来实现.作为对比,用交叉验证是没办法调节不同的D个超参数的.

对比不同类别模型的时候,证据程序也很有用,因为提供了对证据(evidence)的一个很好的估计:

$$
\begin{aligned}
p(D|m)&= \int \int p(D|w,m)p(w|m,\eta)p(\eta|m)dw d\eta &\text{(7.87)}\\
&\approx \max_\eta \int p(D|w,m)p(w|m,\eta)p(\eta|m)dw &\text{(7.88)}\\
\end{aligned}
$$


很重要的一点是在$\eta$上进行积分,而不是任意设置,具体原因如本书5.3.2.5所示.实际上这也是我们在图5.7和5.8当中的多项回归模型中估计边缘似然函数所用的方法.本书21.5.2讲了更贝叶斯风格的方法,其中是要对$\eta$的不确定性建模,而不是计算点估计.


练习略


# MLAPP 读书笔记 - 08 逻辑回归(Logistic regression)

> A Chinese Notes of MLAPP,MLAPP 中文笔记项目 
https://zhuanlan.zhihu.com/python-kivy

记笔记的人：[cycleuser](https://www.zhihu.com/people/cycleuser/activities)

2018年6月20日15:05:14

## 8.1 概论

构建概率分类器有一种方法是建立形式为$p(y,x)$的联合模型,然后以x为条件,推$p(y|x)$.这叫生成方法(generative approach).另外一种办法是直接以$p(y|x)$的形式去拟合一个模型.这就叫做启发式方法(discriminative approach),本章就要讲这个方法.具体来说就是要假设有一些参数为线性的启发模型.我们会发现这样的模型拟合起来特别简单.在8.6,我们会对生成方法和启发方法进行对比,在本书后面的章节中,还会讲到非线性的启发模型和非参数化的启发模型.

## 8.2 模型选择

正如在本书1.4.6讲过的,逻辑回归对应的是下面这种二值化分类模型:
$p(y|x,w)=Ber(y|sigm(w^Tx))$(8.1)

图1.19(b)所示的就是一个一维例子.逻辑回归可以很容易扩展用于高维度输入特征向量.比如图8.1所示的就是对二维输入和不同的权重向量w的逻辑回归$p(y=1|x,w)=sigm(w^Tx)$.如果设置概率0.5的位置为阈值,就能得到一个决策边界,其范数(垂线)为w.

## 8.3 模型拟合

本节讲对逻辑回归模型进行参数估计的算法.

此处参考原书图8.1

### 8.3.1 最大似然估计(MLE)

逻辑回归的负对数似然函数为:
$$
\begin{aligned}
NLL(w)&= -\sum^N_{i=1}\log [\mu_i^{I(y_i=1)}\times (1-\mu_i)^{I(y_i=0)}]  &\text{(8.2)}\\
&=  -\sum^N_{i=1}\log [y_i\log \mu_i+(1-y_i)\log(1-\mu_i)]   &\text{(8.3)}\\
\end{aligned}
$$

这也叫交叉熵误差函数(cross-entropy error function)参考本书2.8.2.

这个公式还有另外一个写法,如下所示.设$\tilde y_i \in \{-1,+1\}$,而不是$y_i\in\{0,1\}$.另外还有$p(y=-1)=\frac{1}{ 1+\exp (-w^Tx)}$和$p(y=1)=\frac{1}{ 1+\exp (+w^Tx)}$.这样有:

$NLL(w)=\sum^N_{i=1}\log(1+\exp(-\tilde y_i w^Tx_i))$(8.4)

和线性回归不一样的是,在逻辑回归里面,我们不再能以闭合形式写出最大似然估计(MLE).所以需要使用一个优化算法来计算出来.为了这个目的,就要推到梯度(gradient)和海森矩阵(Hessian).

此处参考原书图8.2

如练习8.3所示,很明显梯度和海森矩阵分别如下所示:
$$
\begin{aligned}
g &=\frac{d}{dw}f(w)=\sum_i*\mu_i-y_i)x_i=X^T(\mu-y)   &\text{(8.5)}\\
H &= \frac{d}{dw}g(w)^T=\sum_i(\nabla_w\mu_i)x_i^T=\sum_i\mu_i(1-\mu_i)x_xx_i^T  &\text{(8.6)}\\
&= X^TSX  &\text{(8.7)}\\
\end{aligned}
$$

其中的$S\overset{\triangle}{=}diag(\mu_i(1-\mu_i))$.通过练习8.3也可以证明海森矩阵H是正定的(positive definite).因此负对数似然函数NLL就是凸函数(convex)有唯一的全局最小值.接下来就说一下找到这个最小值的方法.

### 8.3.2 梯度下降(gradient descent)

无约束优化问题的最简单算法,可能就是梯度下降(gradient descent)了,也叫做最陡下降(Steepest descent).写作下面的形式:

$\theta_{k+1}=\theta_k -\eta_kg_k$(8.8)

其中的$\eta_k$是步长规模(step size)或者也叫学习率(learning rate).梯度下降法的主要问题就是:如何设置步长.这个问题还挺麻烦的.如果使用一个固定的学习率,但又太小了,那收敛就会很慢,但如果要弄太大了呢,又可能最终不能收敛.这个过程如图8.2所示,其中对下面的(凸函数)进行了投图:

$f(\theta)=0.5(\theta_1^2-\theta_2)+0.5(\theta_1)^2$(8.9)

任意设置从(0,0)开始.在图8.2(a)中,使用了固定步长为$\eta =0.1 $;可见沿着低谷部位移动很慢.在图8.2(b)中,使用的是固定步长$\eta =0.6 $;很明显这样一来算法很快就跑偏了,根本就不能收敛了.


此处参考原书图8.3

所以就得像个靠谱的办法来选择步长,这样才能保证无论起点在哪里最终都能收敛到局部最优值.(这个性质叫做全局收敛性(global convergence),可千万别跟收敛到全局最优值弄混淆哈.)通过泰勒定理(Taylor's theorem),就得到了:

$f(\theta+\eta d)\approx f(\theta)+\eta g^Td$(8.10)

其中的d是下降方向.所以如果$\eta$足够小了,则$f(\theta+\eta d)< f(\theta)$,因为梯度会是负值的.不过我们并不希望步长太小,否则就要运算很久才能到达最小值了.所以要选一个能够最小化下面这个项的步长$\eta$:

$\phi(\eta)=f(\theta_k +\eta d_k)$(8.11)

这就叫线性最小化(line minimization)或者线性搜索(line search).有很多种方法来借这个一维优化问题,具体细节可以参考(Nocedal and Wright 2006).

图8.3(a)展示了上面那个简单问题中的线性搜索.不过我们会发现线性搜索得到的梯度下降路径会有一种扭折行为(zig-zag behavior).可以看到其中一次特定线性搜索要满足$\eta_k =\arg \min_{\eta>0}\phi (\eta)$.优化的一个必要条件就是导数为零,即$\phi'(\eta)=0$.通过链式规则(chain rule),$\phi'(\eta)=d^Tg$,其中$g=f'(\theta+\eta d)$是最后一步的梯度.所以要么就有$g=0$,意思就是已经找到了一个固定点(stationary point);要么就是$g\perp d $,意味着这一步所在点的位置上局部梯度和搜索方向相互垂直.因此连续起来方向就是正交的,如图8.3(b)所示,这就解释了搜索路径的扭折行为.

降低这种扭折效应的一种简单的启发式方法就是增加一个动量项(momentum term)$\theta_k-\theta_{k-1}$:

$\theta_{k+1}=\theta_k-\eta_kg_k+\mu_k(\theta_k-\theta_{k-1})$(8.12)

上式中的$0\le \mu_k \le 1$控制了动量项的重要程度.在优化领域中,这个方法叫做重球法(heavy ball method ,参考 Bertsekas 1999).

另外一种最小化扭折行为的方法是使用共轭梯度(conjugate gradients)(参考Nocedal and Wright 2006第五章,或者Golub and van Loan 1996,10.2).这个方法是选择形式为$f(\theta)=\theta^TA\theta$的二次形式(quadratic objectives),这是在解线性方程组的时候出现的.不过非线性的共轭梯度就不太受欢迎了.

### 8.3.3 牛顿法

#### 算法8.1 最小化一个严格凸函数的牛顿法

1. 初始化一个$\theta_0$;
2. 对于k=1,2,...等,一直到收敛为止,重复下面步骤:
3.      估算$g_k=\nabla f(\theta_k)$
4.      估算$H_k=\nabla^2 f(\theta_k)$
5.      对$d_k$求解$H_kd_k=-g_k$
6.      使用线性搜索来找到沿着$d_k$方向的步长$\eta_k$
7.      $\theta_{K+1}=\theta_k+\eta_kd_k$


如果把空间曲率(curvature)比如海森矩阵(Hessian)考虑进去,可以推导出更快速的优化方法.这样方法就成了二阶优化方法了(second order optimization metods).如果不考虑曲率的那个就叫做牛顿法(Newton’s algorithm).这是一个迭代算法(iterative algorithm),其中包含了下面形式的更新步骤:
$\theta_{k+1}=\theta_k-\eta_kH_k^{-1}g_k$(8.13)

完整的伪代码如本书算法2所示.

这个算法可以按照下面步骤推导.设构建一个二阶泰勒展开序列来在$\theta_k$附近估计$f(\theta)$:

$f_{quad}(\theta)=f_k+g^T_k(\theta-\theta_k)+\frac{1}{2}(\theta-\theta_k)^TH_k(\theta-\theta_k)$(8.14)

重写成下面的形式

$f_{quad}(\theta)=\theta^TA\theta+b^T\theta+c$(8.15)

其中:

$A=\frac{1}{2}H_k,b=g_k-H_k\theta_k,c=f_k-g^T_k\theta_k+\frac{1}{23}\theta^T_kH_k\theta_k$(8.16)

$f_{quad}$最小值为止在:

$\theta=-\frac{1}{2}A^{-1}b=\theta_k-H_k^{-1}g_k$(8.17)

因此牛顿步长$d_k=-H_k^{-1}g_k$就可以用来加到$\theta_k$上来最小化在$\theta_k$附近对$f$的二阶近似.如图8.4(a)所示.

此处参考原书图8.4

在最简单的形式下,牛顿法需要海森矩阵$H_k$为正定矩阵,这保证了函数是严格凸函数.否则,目标函数非凸函数,那么海森矩阵$H_k$就可能不正定了,所以$d_k=-H_k^{-1}g_k$就可能不是一个下降方向了(如图8.4(b)所示).这种情况下,简单的办法就是逆转最陡下降方向,$d_k=-g_k$.列文伯格-马夸特算法(Levenberg Marquardt algorithm)是一种在牛顿步长和最陡下降步长之间这种的自适应方法.这种方法广泛用于解非线性最小二乘问题.一种替代方法就是:不去直接计算$d_k=-H_k^{-1}g_k$,可以使用共轭梯度来解关于$d_k$的线性方程组$H_kd_k=-g_k$.如果$H_k$不是正定矩阵,只要探测到了负曲率,就可以简单地截断共轭梯度迭代,这样就叫做截断牛顿法(truncated Newton).

### 8.3.4 迭代重加权最小二乘法(Iteratively reweighted least squares,缩写为IRLS)


接下来试试将牛顿法用到二值化逻辑回归中求最大似然估计(MLE)上面.在这个模型中第$k+1$次迭代中牛顿法更新如下所示(设$\eta_k=1$,因此海森矩阵(Hessian)是确定的):

$$
\begin{aligned}
w_{k+1}&=  w_k-H^{-1}g_k &\text{(8.18)}\\
&= w_k+(X^TS_kX)^{-1}X^T(y-\mu_k)   &\text{(8.19)}\\
&= (X^TS_kX)^{-1}[(X^TS_kX)w_k+X^T(y-\mu_k)]  &\text{(8.20)}\\
&= (X^TS_kX)^{-1}X^T[S_kXw_k+y-\mu_k]  &\text{(8.21)}\\
&= (X^TS_kX)^{-1}X^TS_kz_k  &\text{(8.22)}\\
\end{aligned}
$$

然后就可以定义工作响应函数(working response)如下所示:
$z_k\overset{\triangle}{=} Xw_k+S_k^{-1}(y-\mu_k)$(8.23)

等式8.22就是一个加权最小二乘问题(weighted least squares problem),是要对下面的项最小化:


$\sum^N_{i=1}S_{ki}(z_{ki}-w^Tx_i)^2$(8.24)

由于$S_k$是一个对角矩阵,所以可以把目标函数写成成分的形式(对每个$i=1:N$):


$z_{ki}=w_k^Tx_i+\frac{y_i-\mu_{ki}}{\mu_{ki}(1-\mu_{ki})}$(8.25)

这个算法就叫做迭代重加权最小二乘法(Iteratively reweighted least squares,缩写为IRLS),因为每次迭代都解一次加权最小二乘法,其中的权重矩阵$S_k$在每次迭代都变化.伪代码参考本书配套算法10.



#### 算法8.2 迭代重加权最小二乘法(IRLS)

1. $w=0_D$;
2. $w_0=\log(\bar y/ (1-\bar y))$
3. 重复下面步骤:
4.      $\eta_i=w_0+w^Tx_i$
5.      $\mu_i=sigm(\eta_i)$
6.      $s_i=\mu_i(1-\mu_i)$
7.      $z_i=\eta_i+\frac{y_i-\mu_i}{s_i}$
8.      $S=diag(s_{1:N})$
9.      $w=(X^TSX)^{-1}X^TSz$
10.  直到收敛


### 8.3.5 拟牛顿法

二阶优化算法的源头都是牛顿法,在本书8.3.3中讲到过.不过很不幸的是计算出来海森矩阵H的运算开销成本太高了.拟牛顿法(Quasi-Newton methods)就应运而生了,以迭代方式使用从每一步的梯度向量中学到的信息来构建对海森矩阵的估计.最常用的方法就是BFGS方法(这四个字母是发明这个算法的四个人的名字的首字母Broyden, Fletcher, Goldfarb, Shanno),这个方法是使用下面所示定义的$B_k\approx H_k$来对海森矩阵进行估计:
$$
\begin{aligned}
B_{k+1}& =B_k+\frac{y_ky_k^T}{y_k^Ts_k}-\frac{(B_ks_k)(B_ks_k)^T}{s_k^TB_ks_k} &\text{(8.26)}\\
s_k& = \theta_k-\theta_{k-1}  &\text{(8.27)}\\
y_k& = g_k-g_{k-1}  &\text{(8.28)}\\
\end{aligned}
$$

这是对矩阵的二阶更新(rank-two update),这确保了矩阵保持正定(在每个步长的特定限制下).通常使用一个对角线估计来启动算法,即设$B_0=I$.所以BFGS方法可以看做是对海森矩阵使用对角线加上低阶估计的方法.

另外BFGS方法也可以对海森矩阵的逆矩阵进行近似,通过迭代更新 $C_l\approx = H_k^{-1}$,如下所示:

$C_{k+1}=(I-\frac{s_ks_k^T}{y_k^Ts_k})C_k(I- \frac{y_ks_k^T}{y_k^Ts_k})+\frac{s_ks_k^T}{y_k^Ts_k}$(8.29)

存储海森矩阵(Hessian)需要消耗$O(D^2)$的存储空间,所有对于很大规模的问题,可以使用限制内存BFGS算法(limited memory BFGS),缩写为L-BFGS,其中的$H_k$或者$H_k^{-1}$都是用对角矩阵加上低阶矩阵来近似的.具体来说就是积(product)$H_k^{-1}g_k$可以通过一系列的$s_k$和$y_k$的内积来得到,只使用m个最近的$s_k,y_k$对,忽略掉更早的信息.这样存储上就只需要$O(mD)$规模的空间了.通常设置m大约在20左右,就足够有很好的性能表现了.更多相关信息参考(Nocedal and Wright 2006, p177).L-BFGS在机器学习领域中的无约束光滑优化问题中通常都是首选方法.

### 8.3.6 $l_2$规范化(regularization)


相比之下我们更倾向于选岭回归而不是线性回归,类似得到了,对于逻辑回归我们更应该选最大后验估计(MAP)而不是计算最大似然估计(MLE).实际上即便数据规模很大了,在分类背景下规范化还是很重要的.假设数据是线性稀疏的.这时候最大似然估计(MLE)就可以通过$||m||\rightarrow \infty$来得到,对应的就是一个无穷陡峭的S形函数(sigmoid function)$I(w^Tx>w_0)$,这也叫一个线性阈值单元(linear threshold unit).这将训练数据集赋予了最大规模概率质量.不过这样一来求解就很脆弱而且不好泛化.

所以就得和岭回归里面一样使用$l_2$规范化(regularization).这样一来新的目标函数.梯度函数.海森矩阵就如下所示:

$$
\begin{aligned}
f'(w)&=NLL(w)+\lambda w^Tw           &\text{(8.30)}\\
g'(w)&= g(w)+\lambda w          &\text{(8.31)}\\
H'(w)&= H(w)+\lambda I          &\text{(8.32)}\\
\end{aligned}
$$

调整过之后的等式就更适合用于各种基于梯度的优化器了.

### 8.3.7 多类逻辑回归

接着就要讲多类逻辑回归(multinomial logistic regression)了,也叫作最大熵分类器(maximum entropy classifier).这种方法用到的模型形式为:

$p(y=c|x,W)=\frac{\exp(w_c^Tx)}{\sum^C_{c'=1}\exp(w_{c'}^Tx)}$(8.33)

还有一个轻微变体,叫做条件逻辑模型(conditional logit model),是在对每个数据情况下一系列不同的类集合上进行了规范化;这个可以用于对用户在不同组合的项目集合之间进行的选择进行建模.

然后引入记号.设$\mu_{ic}=p(y_i=c|x_iW)=S(\eta_i)c$,其中的$\eta_iW^Tx_i$是一个$C\times 1$ 向量.然后设$y_{ic}=I(y_i=c)$是对$y_i$的一种编码方式(one-of-C encoding);这样使得$y_i$成为二进制位向量(bit vector),当且仅当$y_i=c$的时候第c个位值为1.接下来是参考(Krishnapuram et al. 2005),设$w_C=0$,这样能保证可辨识性(identifiability),然后定义$w=vec(W(:,1:C-1))$是一个$D\times (C-1)$维度的列向量(column vector).

这样就可以写出如下面形式的对数似然函数(log-likelihood):

$$
\begin{aligned}
l(W)&= \log\prod^N_{i=1}\prod^C_{c=1}\mu_{ic}^{y_{ic}}=\sum^N_{i=1}\sum^C_{c=1}y_{ic}\log \mu_{ic}  &\text{(8.34)}\\
&= \sum^N_{i=1}[(\sum^C_{c=1}y_{ic}w_c^Tx_i)-\log(\sum^C_{c'=1} \exp (w_{c'}^Tx_i) )]  &\text{(8.35)}\\
\end{aligned}
$$

加上负号就是负对数似然函数NLL了:
$f(w)=-l(w)$

然后就可以针对NLL计算器梯度和海森矩阵了.由于w是分块结构的(block-structured),记号会比较麻烦,但思路还是很简单的.可以定义一个$A\otimes B$表示在矩阵A和B之间的克罗内克积(kronecker product).如果A是一个$m\times n$矩阵,B是一个$p\times q$矩阵,那么$A\otimes B$就是一个$mp\times nq$矩阵:

$A\otimes B= \begin{bmatrix} a_{11}B &...& a_{1n}B\\...&...&...\\a_{m1}B&...&a_{mn}B \end{bmatrix}$(8.37)

回到咱们刚刚的例子,很明显(练习8.4)梯度为:
$g(W)=\nabla f(w)=\sum^N_{i=1}(\mu_i-y_i)\otimes x_i$(8.38)

其中的$y_i=(I(y_i=1),...,I(y_i=C-1))$,$\mu_i(W)=[p(y_i=1|x_i,W),...,p(y_i=C-1|x_i,W)]$这两个都是长度为$C-1$的列向量(column vectors).例如如果有特征维度D=3,类别数目C=3,这就成了:

$g(W)=\sum_i\begin{pmatrix}(\mu_{i1}-y_{i1})x_{i1} \\(\mu_{i1}-y_{i1})x_{i2}\\(\mu_{i1}-y_{i1})x_{i3}\\(\mu_{i2}-y_{i2})x_{i1}\\(\mu_{i2}-y_{i2})x_{i2}\\(\mu_{i2}-y_{i2})x_{i3}\end{pmatrix}$(8.39)


也就是说对于每个类c,第c列中权重的导数(the derivative for the weights)为:
$\nabla_{w_c}f(W)=\sum_i(\mu_i{i}-y_{ic})x_i$(8.40)

这就和二值化逻辑回归的情况下形式一样了,名义上就是误差项乘以$x_i$.(其实这是指数族分布的一个通用特征,在本书9.3.2会讲到.)

(参考练习8.4)很容易发现海森矩阵是一个下面所示形式的$D(C-1)\times D(C-1)$分块矩阵:

$H(WW) = \nabla^2 f(w)=\sum^N_{i=1}(diag(\mu_i)-\mu_i\mu_i^T)\otimes (x_ix_i^T) $(8.41)


$$
\begin{aligned}
H(W)&=\sum_i \begin{pmatrix} \mu_{i1}-\mu_{i1}^2 & -\mu_{i1}\mu_{i2}\\ -\mu_{i1}\mu_{i2}& \mu_{i2}-\mu_{i2}^2\end {pmatrix} \otimes \begin{pmatrix} x_{i1}x_{i1}&x_{i1}x_{i2}&x_{i1}x_{i3}\\x_{i2}x_{i1}&x_{i2}x_{i2}&x_{i2}x_{i3}\\x_{i3}x_{i1}&x_{i3}x_{i2}&x_{i3}x_{i3}  \end{pmatrix}               &\text{(8.42)}\\
&=  \sum_i\begin{pmatrix} (\mu_{i1}-\mu_{i1}^2)X_i&-\mu_{i1}\mu_{i2}X_i\\-\mu_{i1}\mu_{i2}X_i&(\mu_{i2}-\mu_{i2}^2)X_i  \end{pmatrix}             &\text{(8.43)}\\
\end{aligned}
$$

其中的$X_i=x_ix_i^T$.也就是分块矩阵中块$c,c'$部分为:

$H_{c,c'}(W)=\sum_i\mu_{ic}(\delta_{c,c'}-\mu_{i,c'})x_ix_i^T$(8.44)

这也是一个正定矩阵,所以有唯一最大似然估计(MLE).

接下来考虑最小化下面这个式子:
$f'(wW\overset{\triangle}{=} -\log [(D|w)-\log p(W)$(8.45)

其中的$p(W)=\prod_cN(w_C|0,V_0)$.这样一来就得到了下面所示的新的目标函数/梯度函数/海森矩阵:
$$
\begin{aligned}
f'(w)&= f(w)+\frac{1}{2}\sum_cw_cV_0^{-1}w_c &\text{(8.46)}\\
g'(w)&= g(W)+V_0^{-1}(\sum_cw_c) &\text{(8.47)}\\
H'(w)&= H(W)+I_C\otimes V_0^{-1} &\text{(8.48)}\\
\end{aligned}
$$

这样就可以传递给任意的基于梯度的优化器来找到最大后验估计(MAP)了.不过要注意这时候的海森矩阵规模是$O ((CD)\times (CD))$,比二值化情况下要多C倍的行和列,所以这时候更适合使用限制内存的L-BFGS方法,而不适合用牛顿法.具体MATLAB代码参考本书配套PMTK3的logregFit.

## 8.4 贝叶斯逻辑回归

对逻辑回归模型,很自然的需求就是计算在参数上的完整后验分布$p(w|D)$.只要我们相对预测指定一个置信区间,这就很有用了.(另外在解决情景匪徒问题(contextual bandit problems)时候也很有用,参考本书5.7.3.1.)
然而很不幸,不像线性回归的时候了,这时候没办法实现这个目的,因为对于逻辑回归来说没有合适的共轭先验.本章这里讲的是一个简单近似;还有一些其他方法,比如马尔可夫链蒙特卡罗(Markov Chain Monte Carlo,缩写为MCMC,本书24.3.3.1),变分推导(variational inference,本书21.8.1.1),
期望传播(expectation propagation,Kuss and Rasmussen 2005)等等.为了记号简单,这里还用二值逻辑回归为例.

### 8.4.1 拉普拉斯近似(Laplace approximation)

本节将对一个后验分布进行高斯近似.假如$\theta\in R^D$.设:
$p(\theta|D)=\frac{1}{Z}e^{-E(\theta)}$(8.49)

其中的$E(\theta)$叫能量函数(energy function),等于未归一化对数后验(unnormalized
log posterior)的负对数,即$E(\theta)=-\log p(\theta,D)$,$Z=p(D)$是归一化常数.然后进行关于众数$\theta^*$(对应最低能量状态)的泰勒级数展开,就得到了:

$E(\theta) \approx E(\theta^*)+(\theta-\theta^*)^Tg+\frac{1}{2}(\theta-\theta^*)^TH(\theta-\theta^*)$(8.50)

其中的g是梯度,H是在众数位置能量函数的海森矩阵:
$g\overset{\triangle}{=} \nabla E(\theta)|_{\theta^*},H\overset{\triangle}{=} \frac{\partial^2E(\theta)}{\partial\theta\partial\theta^T}|_{\theta^*}$(8.51)

由于$\theta^*$是众数,梯度项为零.因此:
$$
\begin{aligned}
\hat p(\theta|D)& \approx \frac{1}{Z}e^{-E(\theta^*)} \exp[-\frac{1}{2}(\theta-\theta^*)^T H(\theta-\theta^*)] &\text{(8.52)}\\
& = N(\theta|\theta^*,H^{-1})&\text{(8.53)}\\
Z=p(D)& \approx \int \hat p(\theta|D)d\theta = e^{-E(\theta^*)}(2\pi)^{D/2}|H|^{-\frac{1}{2}} &\text{(8.54)}\\
\end{aligned}
$$

最后这一行是参考了多元高斯分布的归一化常数.

等式8.54就是对边缘似然函数的拉普拉斯近似.所以等式8.52有时候也叫做对后验的拉普拉斯近似.不过在统计学领域,拉普拉斯近似更多指的是一种复杂方法(具体细节参考Rue等,2009).高斯近似通常就足够近似了,因为后验分布随着样本规模增长就越来越高斯化,这个类似中心极限定理.(在物理学领域有一个类似的技术叫做鞍点近似(saddle point approximation).)

### 8.4.2 贝叶斯信息量(Bayesian information criterio,缩写为BIC)的推导

可以使用高斯近似来写出对数似然函数,去掉不相关的常数之后如下所示:
$\log p(D)\approx \log(p(D|\theta^*)+\log p(\theta^*)-\frac{1}{2}\log|H|$(8.55)

加在$\log(p(D|\theta^*)$后面的惩罚项(penalization terms)也叫作奥卡姆因子(Occam factor),是对模型复杂程度的量度.如果使用均匀先验,即$p(\theta)\propto 1$,就可以去掉第二项,然后把$\theta^*$替换成最大似然估计(MLE)$\hat\theta$.

接下来看看对上式中第三项的估计.已知$H=\sum^N_{i=1}H_i$,其中的$H_i=\nabla\nabla \log p(D_i|\theta)$.然后用一个固定的矩阵$\hat H$来近似每个$H_i$.这样就得到了:

$\log|H|=\log|N\hat H| =\log (N^d|\hat H|)=D\log N+\log |\hat H|$(8.56)

其中$D=dim(\theta)$,并且假设H是满秩矩阵(full rank matrix).就可以去掉$\log |\hat H|$这一项了,因为这个独立于N,这样就可以被似然函数盖过去了.将所有条件结合起来,就得到了贝叶斯信息量分数(BIC score,参考本书5.3.2.4):
$\log p(D)\approx p(D|\hat \theta)-\frac{D}{2}\log N$(8.57)


### 8.4.3 逻辑回归的高斯近似

接下来对逻辑回归应用高斯近似.使用一个高斯先验,形式为$p(w)=N(w|0,V_0)$,正如在最大后验估计(MAP)里面一样.近似后验为:
$p(w|D)\approx N(w|\hat w, H^{-1})$(8.58)


上式中$\hat w = \arg\min_w \mathrm{E}(w),\mathrm{E}(w) =-(\log p(D|w)+\log p(w)), H=\nabla^2 \mathrm{E}(w)|_{\hat w}$


以图8.5(a)中所示的线性稀疏二位数据为例.有很多个不同参数设置的线都能很好地区分开训练数据;在图中画了四条.图8.5(b)所示的是似然函数曲面,从中可以看到似然函数是无界的,随着向右上角的参数空间移动,似然函数沿着一个嵴线移动,$w_2/w_1=2.34$(通过对角线推测到的).这是因为将$||w||$推向无穷大可以是似然函数最大化.因为大的回归权重会让S形函数非常陡峭,就成了一个阶梯函数了.因此当数据线性稀疏的时候最大似然估计(MLE)不能很好定义.

为了规范表达这个问题,假设使用一个以原点为中心的模糊球形先验(vague spherical prior),$N(w|0,100I)$.将这个球形先验乘以似然函数曲面就得到了一个严重偏斜的后验,如图8.5(c)所示.(这是因为似然函数截断了参数空间中与实验数据不符合的区域.)最大后验估计(MAP)如图中蓝色点所示.这就不像是最大似然估计(MLE)那样跑到无穷远了.

对这个后验的高斯近似如图8.5(d)所示.其中可以看到是一个对称分布,因此也不算是一个很好的估计.不过好歹众数还是正确的(通过构造得到的),而且至少表现了沿着西南东北方向比垂直这个方向上有更大不确定性的这个事实(这对应着稀疏线方向的不确定性).虽然这个高斯近似很粗糙,也肯定比用最大后验估计(MAP)得到的$\delta$函数近似要好很多了.



### 8.4.4 近似后验预测

给定了后验,就可以计算置信区间,进行假设检验等等.就跟之前在7.6.3.3里面对线性回归案例所做的一样.不过在机器学习里面,更多兴趣还是在预测上面.后验预测分布的形式为:
$p(y|x,D)=\int p(y|x,w)p(w|D)dw$(8.59)

此处参考原书图8.5

很不幸这个积分可难算了.

最简单的近似就是插值估计(plug-in approximation),在二值化分类的情况下,形式为:
$p(y=1|x,D)\approx p(y=1|x,\mathrm{E}[w])$(8.60)

其中的$\mathrm{E}[w]$是后验均值.在这个语境下,$\mathrm{E}[w]$也叫作贝叶斯点(Bayes point).当然了,这种插值估计肯定是低估了不确定性了.所以接下来会说更好的近似方法.

此处参考原书图8.6

#### 8.4.4.1 蒙特卡罗方法近似

更好的方法就是蒙特卡罗方法(Monte Carlo approximation),定义如下:
$p(y=1|x,D)\approx \frac{1}{S}\sum^S_{s=1} sigm((w^s)^Tx)$(8.61)

其中的$w^s\sim p(w|D)$是在后验中的取样.(这个方法很容易扩展到多类情况.)如果使用蒙特卡罗方法估计后验,就可以服用这些样本来进行预测.如果对后验使用高斯估计,就要用标准方法从高斯分布中取得独立样本.

此处查看原书图8.7

图8.6(b)展示了在我们的二维样例中从后验预测分布取的样本.图8.6(c)展示的是这些样本的均值.通过对多个预测取平均值,就可以发现决策边界的不确定性随着远离训练数据而散发开.所以虽然决策边界是线性的,后验预测密度还是非线性的.要注意后验均值的决策边界大概和每个类的距离都是一样远;这是对大便捷原则的贝叶斯模拟,在本书14.5.2.2会进一步讲到.

图8.7(a)所示的是一维下第一个例子.红色的点表示的是训练数据中后验预测分布评估出来的均值.竖着的蓝色线段表示的是对该后验预测的95%置信区间;蓝色的小星星是中位数位置.可见贝叶斯方法可以基于SAT分数来对一个学生能通过考试的概率的不确定性进行建模,而不是仅仅给出一个点估计.

### 8.4.4.2 Probit近似(适度输出)*


如果有一个对后验的高斯近似,$p(w|D) \approx N(w|m_N,V_N)$,就可以计算后验预测分布的确定性近似(deterministic approximation),至少在二值化情况下是可以的.步骤如下所示:


$$
\begin{aligned}
p(y=1|x,D)&\approx \int sigm(w^Tx)p(w|D)dw=\int sigma(a)N(a|\mu_a,\sigma_a^2)da  &\text{(8.62)}\\
a&\overset{\triangle}{=} w^Tx  &\text{(8.63)}\\
\mu_a &\overset{\triangle}{=} \mathrm{E}[a]=m_N^Tx &\text{(8.64)}\\
\sigma^2_a&\overset{\triangle}{=} var[a]=\int p(a|D)[a^2-\mathrm{E}[a^2]]da &\text{(8.65)}\\
&= \int p(w|D)[(w^Tx)^2-(m_N^Tx)^2]dw =x^TV_Nx &\text{(8.66)}\\
\end{aligned}
$$


然后就能发现需要去评估一个对应高斯分布的S形函数(sigmoid function)的期望.可以利用S形函数类似概率函数(probit function)的性质来进行近似,通过标准正态分布的累计密度函数(cdf):
$\Phi(a)\overset{\triangle}{=}\int^a_{-\infty} N(x|0,1)dx$(8.67)

图8.7(b)所示的就是s形函数和概率函数.图中的坐标轴做了缩放,使得$sigm(a)$在原点位置附近有和$\Phi(\lambda a)$有类似的范围,其中$\lambda^2 =\pi /8$.

利用概率函数(probit function)的优势就是可以用一个高斯分布以解析形式卷积(convolve)出来:
$\int \Phi (\lambda a)N(a|\mu,\sigma^2)da =\Phi (\frac{a}{(\lambda^{-2}+\sigma^2)^{\frac{1}{2}}})$(8.68)

然后再等号两边都使用 $sigm(a)\approx \Phi (\lambda a)$ 来插值近似,就得到了:

$$
\begin{aligned}
\int sigm(a)N(a|\mu,\sigma^2)da& \approx sigm(k(\sigma^2)\mu)            &\text{(8.69)}\\
k(\sigma^2)& \overset{\triangle}{=} (1+\pi\sigma^2/8)^{-\frac{1}{2}}           &\text{(8.70)}\\
\end{aligned}
$$

将上面的近似用到逻辑回归模型中,就得到了下面的表达式(最初引用自(Spiegelhalter and Lauritzen 1990)):
$p(y=1|x,D)\approx sigm(k(\sigma^2_a)\mu_a)$(8.71)

图8.6(d)所示表面这个近似能得到和蒙特卡洛近似相似的结果.

使用等式8.71这种近似,也叫作调节输出(moderated output),因为这比起插值估计不那么极端.要理解这一点,要注意到$0\le k(\sigma^2)\le 1$,因此就有:
$sigm(k(\sigma^2)\mu)\le sigma(\mu)=p(y=1|x,\hat w)$(8.72)

上式中的不等号当$\mu\ne 0$的时候严格成立.如果$\mu >0$,就有$p(y=1|x,\hat w)>0.5$,但调节的预测(moderated prediction)总是在0.5附近,所以不太可信(less confident).不过,决策边界存在于$p(y=1|x,D)=sigm(k(\sigma^2)\mu)=0.5$的位置,也就意味着$\mu =\hat w^Tx=0$.因此调节预测的决策边界和差值近似是一样的.所以两种方法的误分类率是一样的,但对数似然函数是不一样的.(要注意在多类情况下,后验协方差给出的结果和插值方法是不一样的,参考本书练习3.10.3以及(Rasmussen
and Williams 2006)).

### 8.4.5 残差分析(异常值检测)*

检验数据中的异常值(outlier)有时候很有用.这个过程就叫残差分析(residual analysis)或者案例分析(case analysis).在回归情况下,这个可以通过计算残差来得到:$r_i=y_i-\hat y_i$,其中的$\hat y_i =\hat w^T x_i$.如果模型假设正确无误,这些值应该遵循一个正态分布$N(0,\sigma^2)$.可以投图(qq-plot)评定,其中两个坐标轴的值分别是高斯分布的N个理论值(theoretical quantiles)和$r_i$的经验值(empirical quantiles).偏离这条直线的点就是潜在的异常值.

基于残差的简单方法不适用于二进制数据,因为依靠测试统计的渐进正态(asymptotic normality).不过用贝叶斯方法,就能定义异常值了,可以定义为$p(y_i |\hat y_i)$小的点,一般使用$\hat y_i =sigm (\hat w^T x)$.要注意这里的$\hat w$是从全部数据估计出来的.在预测$y_i$时更好的方法是从对w的估计排除掉$(x_i,y_i)$.也就是定义异常值为在交叉验证后验预测分布下有低概率的点,定义形式为:

$p(y_i|x_i,x_{-i},y_{-i})=\int p(y_i|x_i,w)\prod _{i'\ne i} p(y_{i'}|x_{i'},w)p(w)dw$(8.73)

这就可以通过抽样方法来有效近似(Gelfand 1996).更多关于逻辑回归模型中残差分析的相关内容可以参考(Johnson and Albert 1999, Sec 3.4).

## 8.5 在线学习(Online learning)和随机优化(stochastic optimization)


传统机器学习都是线下的,也就意味着是有一批量的数据,然后优化一个下面形式的等式:

$f(\theta)=\frac{1}{N}\sum^N_{i=1}f(\theta,z_i)$(8.74)

其中如果有$z_i=(x_i,y_i)$是监督学习情况(supervised case),或者只有$x_i$就对应着无监督学习的情况,而$f(\theta,z_i)$这个函数是某种损失函数.比如可以使用下面这样的损失函数:

$f(\theta,z_i)=L(y_i,h(x_i,\theta))$(8.75)

其中的$h(x_i,\theta)$是预测函数,而$L(y,\hat y)$是某种其他的损失函数,比如可以使平方误差或者胡博损失函数(Huber loss).在频率论统计学方法中,平均损失函数也叫作风险(参考本书6.3),所以对应地就将这个方法整体叫做经验风险最小化(empirical risk minimization,缩写为ERM),参考本书6.5.

可是如果有一系列的流数据(streaming data)不停出现,就需要进行在线学习(online learning),也就是要随着每次有新数据来到而更新估计,而不是等到尽头,因为可能永无止境.另外有时候虽然数据是成批的一整个数据,也可能会因为太大没办法全部放进内存等原因也需要使用在线学习.接下来就要讲这类校本化的学习方法.

### 8.5.1 在线学习和遗憾最小化(regret minimization)

假如在每一步中,客观世界都提供了一个样本$z_k$,而学习者必须使用一个参数估计$\theta_k$对此进行响应.在理论机器学习社区中,在线学习关注的目标是遗憾值(regret),定义为相对于使用单个固定参数值时候能得到的最好结果所得到的平均损失:

$regret_k\overset{\triangle}{=} \frac{1}{k} \sum^k_{t=1} f(\theta_t,z_t)-\min_{\theta^*\in \Theta}\frac{1}{k} \sum^k_{t=1}f(\theta_*,z_t)$(8.77)

比如我们要调查股票市场.设$\theta_j$是我们在股票j上面投资的规模,而$z_j$表示这个股票带来的回报.这样损失函数就是$f(\theta,z)=-\theta^Tz$.遗憾值(regret)就是我们通过每次交易而得到的效果,而不只是依据什么神秘预言来选择买那个股票然后购买和持有的策略.

在线学习的简单算法是在线梯度下降法(online gradient descent (Zinkevich 2003)),步骤如下:在每次第k步,使用下列表达式更新参数:
$\theta_{k+1}=\roj_{\Theta}(\theta_k-\eta_kg_k)$(8.78)

其中的$proj_v(v)=\arg\min_{w\in V}||w-v||_2$是向量v在空间V上的投影,$g_k=\nabla f(\theta_k ,z_k)$是梯度项,而$\eta_k$是补偿规模.(只有当参数必须要约束在某个$R^D$的子集内的时候才需要使用投影这个步骤.更多细节参考本书13.4.3.)接下来要看看这个让遗憾最小化的方法和更传统的关注对象之间的关系,比如最大似然估计(MLE).

当然遗憾最小化也由很多其他方法,这就超出这本书的覆盖范围了,更多细节可以参考Cesa-Bianchi and Lugosi (2006).

### 8.5.2 随机优化和风险最小化

接下来我们要尝试的不是让过去步骤的遗憾最小化,而是希望未来损失最小化,这在很多(频率论)统计学习理论中更长久.也就是要最小化:

$f(\theta=\mathrm{E}[f(\theta,z)]$(8.79)

其中这个期望是对未来数据上取的.优化这种某些变量是随机变量的函数的过程就叫做随机优化(Stochastic optimization).
假如要从一个分不中得到一系列有限的抽样样本.一个方法就是优化8.79里面的期望值,在每一步应用等式8.78进行更新.这就叫做随机梯度下降法(stochastic gradient descent,缩写为SGD,出自Nemirovski and Yudin 1978).通常我们都想要一个简单的参数估计,可以用下面的进行平均:

$\bar\theta_k=\frac{1}{k}\sum^k_{t=1}\theta_t$(8.80)

这就叫Polyak-Ruppert 平均,可以递归使用,如下所示:

$\bar\theta_k=\bar\theta_{k-1}-\frac{1}{k}(\nbar\theta_{k-1}-\theta_k)$(8.81)
更多细节参考(Spall 2003; Kushner and Yin 2003).

#### 8.5.2.1 设定步长规模

接下来要讨论的是要保证随机梯度下降(SGD)收敛所需要的学习速率(learning rate)的充分条件(sufficient conditions).这也叫做Robbins-Monro条件:

$\sum^\infty_{k=1}\eta_k=\infty,\sum^\infty_{k=1}\eta^2_k=\infty$(8.82)

$\eta_k$在时间上的取值集合也叫作学习速率列表(learning rate schedule).可以用很多公式,比如$\eta_k=1/k$,或者可以用下面这个(Bottou 1998; Bach and Moulines 2011):
$\eta_k=(\tau_0+k)^{-k}$(8.83)

上面的$\tau_0 \ge 0$减慢了算法的早期迭代,而$k\in (0.5,1]$控制了旧值被遗忘的速率.

随机优化的一个主要缺陷就是需要去调整这些个参数.一个简单的启发式办法(Bottou 2007)如下所示:存储数据的一个初始子集,然后对这个自己适用一系列不同的$\eta$值;然后选择能使得目标对象降低最快的,再将其用于其他的全部数据上.要注意这可能会导致不收敛,不过当算法的性能提升达到某个设定好的位置(hold-out set plateaus)的时候可以终止(这也叫早期停止,early stopping)

#### 8.5.2.2 分参数步长规模(Per-parameter step sizes)


随机梯度下降法(SGD)的一个问题就是对于不同的参数都用同样的补偿规模.接下来要简单介绍一种新方法,自适应梯度下降法(adaptive gradient),缩写为adagrad,出自(Duchi et al. 2010),这个方法的思路类似使用对角海森矩阵近似(diagonal Hessian approximation).(类似方法也可以参考Schaul et al. 2012).具体来说就是如果$\theta_i(k)$是第k次的参数i,而$g_i(k)$是对应的梯度,就可以用下面的方式进行更新:

$\theta_i(k+1)=\theta_i(k)-\eta\frac{g_i(k)}{\tau_o+\sqrt{s_i(k)}}$(8.84)

其中对角步长规模向量(diagonal step size vector)是梯度向量的平方(gradient vector squared),加上整个时间上的所有补偿.这也可以使用下面的形式来递归更新:

$s_i(k)=s_i(k-1)+g_i(k)^2$(8.85)

这个结果就是一个分参数步长规模,可以适应损失函数的曲率(curvature).这个方法最开始推导出来是为了遗憾最小化的情形,不过还可以有很多其他用途.

#### 8.5.2.3 随机梯度下降(SGD)和批量学习(batch learning)的对比

如果没有一个无限的数据流,可以去模拟一个,只要随机从训练集中取样数据点就可以了.本质上是将等式8.74作为对经验分布的期望来优化。

#### 算法8.3 随机梯度下降法

1. 初始化$\theta,\eta$;
2. 重复下面步骤直至收敛:
3.      随机交流数据(permute data)
4.      for $i=1:N$ 重复下面操作:
5.          $g=\nabla f(\theta,z_i)$
6.          $\theta \leftarrow proj_\Theta (\theta-\eta g)$
7.          更新$\eta$


理论上应该有替代取样,不过实际上通常都是无替代随机交流数据和样本效果更好,然后后面都重复这样操作.每次对全部数据集进行一次抽样就叫做一代(epoch).伪代码参考本书算法8.

在线下学习的情况下,更好的方法是以B份数据来进行小批量(mini-batch)梯度计算.如果B=1,这就是标准的随机梯度下降发,如果B=N,这就成了标准的最陡下降(Steepest descent).一般都设置$B\sim 100$.

虽然随机梯度下降法(SGD)是很简单的一阶方法(first-order method),但用于一些问题的时候效果出奇地好,尤其是数据规模很大的情况(Bottou 2007).直观理解起来,原因可能是只要看过几个样本之后就能对梯度进行很好的估计了.而使用很大规模的数据来仔细计算精准的梯度就很可能是浪费时间了,因为算法反正也要在下一步重新计算梯度.为了充分利用计算时间,最好是使用一个有噪音的估计,然后沿着参数空间快速移动.一个极端的例子,比如要对每个样本都重复一份来复制整个训练样本集.这样批量方法就要花费两倍时间,而在线学习方法就几乎不会被影响,因为梯度方向其实没有变化(双倍数据规模知识改变了梯度烈度(magnitude),但并不相关,因为梯度反正也要被步长规模所缩放).

除了能加速之外,随机梯度下降法(SGD)还不太容易在浅局部最小值部位卡住,因为通常增加了一定规模的噪音.因此这种方法在机器学习社区中很流行于拟合有非凸函数对象的模型,比如神经网络(neural networks,本书16.5)和深层信念网络(deep belief networks本书28.1)等等.

### 8.5.3 最小均方算法(LMS algorithm)



举个随机梯度下降法(SGD)的例子,假设要考虑去计算在线学习中线性回归的最大似然估计(MLE).在等式7.14中已经推导出了批量梯度(batch gradient).在第k次迭代的在线梯度为:

$g_k =x_i(\theta^T_kx_i-y_i)$(8.86)

此处查看原书图8.8

其中的$i=i(k)$是第k次迭代时候使用的训练样本.如果数据集是流式的,就用$i(k)=k$;为了表达简单,以后就这么用了.等式8.86很好理解:特征向量$x_k$乘以预测$\hat y_k =\theta^T_k x_k$和真实的响应变量$y_k$的差距作为权重.;因此梯度函数就像可以当做是一个误差信号了.

在计算了梯度之后,可以沿着梯度进行下一步长,如下所示:
$\theta_{k+1}=\theta_k-\eta_k(\hat y_k-y_k)x_k$(8.87)

(这里就没必要进行投影的步骤了,因为这是一个非约束的优化问题,unconstrained optimization problem.)这个算法也叫作最小均方算法(least mean squares,缩写为LMS),也被称作$\delta$规则(delta rule),或者也叫做Widrow-Hoff 规则(Widrow-Hoff rule).

图8.8所示就是对图7.2当中的数据应用这个算法的结果.启动点为$\theta=(-0.5,2)$,经过大约26次迭代而收敛(这里的收敛指的是$||\theta_k-\theta_{k-1}||^2_2$小于阈值$10^{-2}$).

要注意最小均方算法(LMS)可能需要很多次遍历整个数据才能找到最优解.对比之下,使用递归最小均方算法,基于卡尔曼过滤器(Kalman filter)使用二阶信息(second-order information),只要单次遍历数据就能找到最优解了(参考本书18.2.3).也可以参考练习7.7.

### 8.5.4 感知器算法(perceptron algorithm)


接下来考虑如何对在线情况下的二值化逻辑回归模型(binary logistic regression model)进行拟合.批量梯度(batch gradient)如等式8.5所示.在线情况下呢,加权重的更新的形式简单如下:
$\theta_k=\theta_{k-1}-\eta_kg_i =\theta_{k-1} -\eta_k(\mu_i-y_i)x_i$(8.88)

其中$\mu_i=p(y_i=1|x_i,\theta_k)=\mathrm{E}[y_i|x_i,\theta_k]$.可见这和最小均方算法(LMS)形式一模一样.实际上这个性质对于多有的通用线性模型都成立(参考本书9.3).

然后对这个算法进行近似.设:
$\hat y_i =\arg\max_{y\in\{0,1\}} p(y|x_i,\theta)$(8.89)

代表了最大概率类标签.然后替代$\mu_i =p(y=1|x_i,\theta)=sigm(\theta^Tx_i)$中的剃度表达式为$\hat y_i$.这样就得到了近似的梯度:

$g_i\approx (\hat y_i -y_i)x_i$(8.90)

如果我们假设$y\in \{-1,+1\}$,而不是$y\in \{0,1\}$,那么在代数计算上就能更简单了.这时候我们的预测就成了:
$\hat y_i =sign(\theta^Tx_i)$(8.91)

然后如果$\hat y_i y_i =-1$,就分类错误了,而如果$\hat y_i y_i =+1$则表示猜对了分类标签.

在每一步,都要通过加上梯度来更新权重向量.关键的观察项目在于,如果预测正确,那么$\hat y_i=y_i$,所以(近似)梯度就是零了,也就不用去更改权重向量了.可是如果$x_i$是误分类的(misclassified),就要按照下面的步骤更新权重向量了:如果$\hat y_i =1$而$y_i = -1$,那么负梯度就是$-(\hat y_i-y_i)x_i=-2x_i$;如果反过来$\hat y_i =-1$而$y_i = 1$,那么负梯度就是$-(\hat y_i-y_i)x_i= 2x_i$.上面这个因数2可以吸收进学习速率(learning rate)$\eta$里面,之写成更新的形式,在误分类的情况下为:

$\theta_k =\theat_{k-1}+\eta_k y_i x_i$(8.92)


由于只有权重的符号是重要的,而大小并不重要,所以就可以设$\eta_k=1$.伪代码参考本书的算法11.
上面这个算法也就叫做感知器算法(perceptron algorithm),出自(Rosenblatt 1958),在给的数据是线性稀疏(linearly separable)的情况下就会收敛,即存在参数$\theta$使得在训练集上的预测$sign(\theta^Tx)$会达到零误差(0 error).不过如果暑假不是线性稀疏的,这个算法就不收敛了,甚至可能虽然收敛也要花费很长时间才行.训练逻辑回归模型有很多更好的方法,比如使用适当的随机梯度下降(SGD)而不使用梯度近似,或者迭代重加权最小二乘法(IRLS,参考本书8.3.4).不过感知器算法还是有很重要历史地位的:这可以算是有史以来被推导出的第一个机器学习算法(Frank Rosenblatt 1957),甚至还被用模拟硬件进行了实现.另外,这个算法也可以用于计算边缘分布$p(y_i|x, \theta)$比计算最大后验分布输出(MAP output)$\arg\max _y p(y|x,\theta)$在运算上更昂贵的模型拟合;这还引出了一些结构输出(structured-output)分类问题.具体细节参考本书19.7.

#### 算法8.4 感知器算法

1. 输入:线性稀疏数据集$x_i \in R^D,y_i \in \{ -1.+1\}, for i =1:N$
2. 初始化$\theta_0$;
3. $k\leftarrow 0$
4. 重复下面步骤直至收敛:
5.      $k\leftarrow k+1$
6.      $i \leftarrow k mod N$
7.      如果$\hat y_i\ne y_i$:    
8.          $\theta_{k+1}\leftarrow \theta_k+y_ix_i$
9.      否则:
10.         无操作



### 8.5.5 贝叶斯视角

在线学习的另外一个方法就是从贝叶斯视角实现的.这个概念特别简单:就是递归应用贝叶斯规则:
$p(\theta|D_{1:k})\propto p(D_k|\theta)p(\theta|d_{1:k-1})$(8.93)

这有个很明显的优势,因为返回的是一个后验,而不是一个点估计.这也允许超参数(hyper-parameters)的在线自适应(online adaptation),这是非常重要的,因为在线学习没办法使用交叉验证.最后的一个不那么明显的优点就是速度可以比随机梯度下降法(SGD)更快.具体原因在于,通过对每个参数加上其均值的后验方差建模,可以有效对每个参数赋予不同的学习速率(de Freitas et al. 2000),这是对空间曲率(curvature)建模的一种简单方法.这些房差通过概率论的常见规则就可以实现自适应(adapted).对比之下,使用二阶(second-order)优化方法来解决在线学习的问题可能就要麻烦多了(更多细节参考Schraudolph et al.2007; Sunehag et al. 2009; Bordes et al. 2009, 2010).

本书18.2.3是一个简单的样例,展示了如何使用卡尔曼过滤器(Kalman filter)来在线拟合一个线性回归模型.和最小均方算法(LMS)不同,这个方法遍历数据一次就可以收敛到最优解(离线).Ting et al.2010 讲了一种扩展方法,以在线的形式来学习一个健壮的非线性回归模型(robust non-linear regression model).对于通用线性模型(GLM)的情况,可以使用一个假设密度过滤器(assumed density filter,参考本书18.5.3),其中使用一个对角协方差的高斯分布来对后验近似;方差项目就可以用作分参数步长规模(per-parameter step-size).更多细节参考本书18.5.3.2.另外一种方法是使用粒子过滤器(particle filtering,本书23.5),这个方法被(Andrieu et al. 2000)用于核化的(kernelized)线性/逻辑回归模型的序列学习(sequentially learning).

## 8.6 生成分类器和判别分类器(Generative vs discriminative classifiers)

在本书4.2.2,已经降到了类标签的后验分布使用高斯判别分析(Gaussian discriminative analysis,缩写为GDA)之后形式和逻辑回归一模一样,都是$p(y=1|x)=sigm(w^Tx)$.因此这个决策边界在两种情况下都是x的线性函数.不过要注意很多生成模型可能会给出一个逻辑回归后验,比如,每个类条件密度都是泊松分布(Poisson)$p(x|y=c)=Poi(x|\lambda_c)$.所以使用GDA所做的假设要比使用逻辑回归的假设更强.

这些模型更进一步的区别就是训练方式.当你和一个判别模型的时候,一般是最大化条件对数似然函数$\sum^N_{i=1}\log p(y_i|x_i,\theta)$,而当拟合一个生成模型的时候,通常要最大化联合对数似然函数$\sum^N_{i=1}\log p(y_i,x_i|\theta)$.很明显,这就能导致不同结果(参考练习4.20).

当使用GDA做出的高斯假设正确无误的时候,生成模型需要的训练样本数据集要比逻辑回归更少,就能达到确定水平的性能,可是如果高斯假设不正确,逻辑回归效果就更好了(Ng and Jordan 2002).这是因为判别模型不需要对特征分布进行建模.这也如图8.10所示.可见其中类条件密度还是相当复杂的;具体来说就是$p(x|y=1)$是一个多项分布,就可能很难估计.不过类后验$p(y=c|x)$是一个简单的s形函数,中间部位就是阈值0.55.这就说明一般来说判别模型可能更精准,因为他们的工作某种程度上来说更简单.不过精确度并不是我们挑选方法时候的唯一重要因素.接下来就要说一下两种方法的优点和不足.

### 8.6.1 不同方法的各自优劣

* 容易拟合?我们已经看到了,拟合生成分类器通常都很简单.比如本书3.5.1.1和4.2.4,分别对朴素贝叶斯模型和线性判别分析模型(LDA)进行了拟合,只需要简单的计数和取平均.相比之下,逻辑回归就需要解一个凸优化问题了(具体细节比如本书8.3.4),这就要慢多了.
* 分开拟合各类?在生成分类器中,我们队每个类条件密度分开估计其参数,所以不需要再增加更多类的时候重新训练模型.对比之下在判别模型中,所有参数都参与互动,所以添加新类的时候必须要重新训练.(如果我们训练一个生成模型来最大化一个判别对象也是这样的情况,参考Salojarvi et al. 2005.)
* 处理缺失数据更容易?有时候一些输入(x的成分)可能并没有观察到.也就是缺失了.在生成分类器里面,有一种简单方法来应对这种情况,稍后本书8.6.2就会讲到.不过在判别分类器里面,原则上这种问题就无解了,因为模型假设x是永远可用的要能用来做条件的(当然其实也有一些启发式方法来应对,参考Marlin 2008).
* 能处理无标签训练数据?半监督学习(semi-supervised learning)是很有意思的,其中使用了一些未标签数据来解决一个监督任务.这对于生成模型来说很容易(参考(Lasserre et al. 2006; Liang et al. 2007)),但对于判别模型就难多了.
* 输入输出是否对称?对于生成模型,可以反着用,然后通过给定的输出来推测可能的输入,只要计算$p(x|y)$就可以了.这对于判别模型来说就是不可能了.因为生成模型定义了一个在x和y上的联合分布,因此输入输出就是对称的.
* 能否特征预处理?判别方法的一个大优势就是允许我们事先以任何方式来对数据进行预处理,比如可以把x替换成$\phi(x)$,可以是某种基函数扩展,比如图8.9所示.不过要是相对这种预处理数据定义生成模型就可能很难了,因为新的特征就会以复杂方式相互关联.
* 能否有校正良好的概率?有点生成模型,比如朴素贝叶斯,有很强的独立假设,而这些假设很可能是无效的.这就可能导致非常极端的后验类概率,比如很靠近0或者1.判别模型比如逻辑回归等等,就通常在概率估计上有更好的校正.

上面就是对于两种模型的比较对比.这两种模型最好都掌握一些,放进你的工具箱.表格8.1所示是本书讲的分类和回归技术的总结.

此处参考原书图8.9
此处参考原书图8.10

|模型名称|分类/回归|生成/判别|参数化/非参数化|章节|
|---|---|---|---|---|
|判别分析 Discriminant analysis|分类|生成|参数化|4.2.2,4.2.4|
|朴素贝叶斯分类器Naive Bayes classifier|分类|生成|参数化|3.5,3.5.1.2|
|树增广朴素贝叶斯分类器Tree-augmented Naive Bayes classifier|分类|生成|参数|10.2.1|
|线性回归 Linear regression|回归|判别|参数化|1.4.5,7.3,7.6|
|逻辑回归 Logistic regression|分类|判别|参数化|1.4.6,8.3.4,8.4.3,21.8.1.1|
|稀疏线性/逻辑回归 Sparse linear/ logistic regression|结合|判别|参数化|13|
|专家混合 Mixture of experts|结合|判别|参数化|11.2.4|
|多层感知器/神经网络 Multilayer perceptron (MLP)/ Neural network|结合|判别|参数化|16|
|条件随机域 Conditional random field (CRF)|分类|判别|参数化|19.6|
|K最近邻分类器 K nearest neighbor classifier|分类|生成|非参数化|1.4.2,14.7.3|
|无穷混合判别分析 (Infinite) Mixture Discriminant analysis|分类|生成|非参数化|14.7.3|
|分类和回归树 Classification and regression trees (CART)|结合|判别|非参数化|16.2|
|增强模型 Boosted model|结合|判别|非参数化|16.4|
|稀疏核化线性/逻辑回归 Sparse kernelized lin/logreg (SKLR)|结合|判别|非参数化|14.3.2|
|相关向量机 Relevance vector machine (RVM)|结合|判别|非参数化|14.3.2|
|支持向量机 Support vector machine (SVM)|结合|判别|非参数化|14.5|
|高斯过程 Gaussian processes (GP)|结合|判别|非参数化|15|
|平滑样条 Smoothing splines|回归|判别|非参数化|15.4.6|
表 8.1 本书所讲到的分类/回归模型的列表.此表格也可以从[这个链接](http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/html/tu
tSupervised.html)查看对应的PMTK代码.任何的生成概率模型(比如隐形马尔科夫链HMM,玻尔兹曼机器Boltzmann machines,贝叶斯网络 Bayesian networks等等)都可以转化成用作类条件密度(class
conditional density)的分类器.


### 8.6.2 处理缺失数据

有时候输入值(x的成分)可能没观测到;这可能是创安器故障导致的,也可能是记录时候没弄完整等等.这就叫做数据缺失问题 (missing data problem,Little. and Rubin 1987).对于生成模型来说,能在原则上有办法处理这种缺失数据是最大的优势了.

规范化表达一下,使用一个二值化响应变量$r_i\in \{0,1\}$,用来判断$x_i$是否被观测到.联合模型形式就是$p(x_i,r_i|\theta,\phi)=p(r_i|x_i,\phi)p(x_i|\theta)$,其中的$\phi$是控制该项目是否被检测到的参数.如果假设$p(r_i|x_i,\phi)=p(r_i|\phi)$,就说数据是随机缺失的(missing completely at random,缩写为MCAR).如果这这两个假设都不成立,就说数据是非随机缺失(not missing completely at random,缩写为NMCAR).这种情况下,就必须对数据缺失机制进行建模了,因为确实的模式中包含了关于缺失数据和对应参数的信息.这在协作过滤(most collaborative filtering)问题中最常见.更多内容参考(Marlin 2008).接下来先假设数据是随机丢失的.

处理缺失数据的时候,最好要区分出来数据缺失发生在测试的时候(而训练数据是完整的)还是发生在训练的时候,训练时候有缺失就更麻烦一些.接下来会分别讨论两种情况.要注意在测试的时候分类标签总是缺失的,这就是测试的定义决定的;如果在训练的时候分类标签有时候也缺失,这样问题就是半监督学习(semi-supervised learning)了.

#### 8.6.2.1 测试时候的数据丢失

在生成分类其中,随机缺失数据的特征可以通过边缘化而去掉(marginalizing them out).例如,如果缺失$x_1$的值,可以计算:

$$
\begin{aligned}
p(y=c|x_{2:D},\theta)&\propto p(y=c |\theta)p(x_{2:D}|y=c,\theta)  &\text{(8.94)}\\
&= p(y=c|\theta)\sum_{x_1}p(x_1,x_{2:D}|y=c,\theta)      &\text{(8.95)}\\
\end{aligned}
$$

如果使用朴素贝叶斯加设,这个边缘化(maginalization)过程可以如下进行:
$\sum_{x_1}p(x_1,x_{2:D}|y=c,\theta)=[\sum_{x_1}p(x_1|\theta_{1c})]\prod^D_{j=2}p(x_j|\theta_{jc})=\prod^D_{j=2}p(x_j|\theta_{jc})$(8.96)

其中利用了$\sum_{x_1} p(x_1|y=c,\theta)=1$.因此在一个朴素贝叶斯分类器里面,只要在测试的时候忽略掉确实特征就可以了.类似的在判别分析里面,不论估计参数的时候使用了什么样的规范化方法(regularization method),都可以解析地将确实变量边缘化来去掉(参考本书4.3):

$p(x_{2:D}|y=c,\theta)=N(x_{2:D}|\mu_{c,2:D},\Sigma_{c,2:d,2:D})$(8.97)

#### 8.6.2.2 训练时候的数据丢失

训练时候数据丢失就不那么好处理了.尤其是这时候计算最大似然估计(MLE)或者最大后验分布(MAP)就都不再是简单的优化问题了,具体原因在本书11.3.2中会讲到.不过也不要紧,因为很快就会学到很多更复杂的算法(比如本书11.4要讲的期望最大化算法(EM))来对这种情况下的最大似然估计(MLE)和最大后验分布(MAP)进行近似.


### 8.6.3 费舍尔线性判别分析(FLDA)*

判别分析(Discriminant analysis)是用来分类的一种生成方法(generative approach),需要对特征拟合一个多元正态分布(MVN).这在高维度的情况下可能就很困难.所以有一种办法就是降低特征$x\in R^D$的维度,然后对得到的低维度特征$z\in R^L$来拟合多元正态分布(MVN).最简单的方法就是使用线性投影矩阵$z=Wx$,这里的W就是一个$L\times D$的矩阵.可以使用主成分分析(PCA)来找到矩阵W(参考本书12.2);得到的结果和正则化线性判别分析(RDA,参考本书4.2.6)类似,因为奇异值分解(SVD)和主成分分析(PCA)是本质上等价的.不过主成分分析(PCA)是无监督技术,不需要考虑类标签.所以得到的低维度特征就并不见得一定是对于分类来说的最优选择,如图8.11所示.度还有一种方法,就是找使用高斯类条件密度模型来尽可能降低维度数据分类最优的矩阵W.这里使用高斯分布是合理的,因为我们计算的是一系列特征的线性组合,虽然这些特征可能不见的是高斯分布的.这种方法就叫做费舍尔线性判别分析(Fisher’s linear discriminant analysis,缩写为FLDA).

此处参考原书图8.11

费舍尔线性判别分析(FLDA)是对判别方法和生成方法的一种混合.这个方法的缺点就是限制在使用的$L\le C-1$小于类标签数目减一的维度,而不论D的维度是多少,具体原因后面会解释.这样在二分类情况下,就意味着要找一个单独向量w来对数据进行投影.下面就推到一些二分类情况优化w的过程.然后再泛化到多分类的情况下,最终对这个方法给一个概率论的解释.

#### 8.6.3.1 一维最优投影的推导

接下来要对二分类情况下的最优方向w进行推导,这部分参考了(Bishop 2006b, Sec 4.1.4).定义类条件均值(class-conditional means)为:

$\mu_1=\frac{1}{N_1}\sum_{i:y_i =1} x_i,\mu_2=\frac{1}{N_2}\sum_{i:y_i =2} x_i $(8.98)

设$m_k=w^T\mu_k$为每个均值在线w上的投影.另外设$z_i=w^Tx_i$为数据在线上的投影.这样投影点的方差就正比于(proportional to):
$s_k^2 = \sum_{i:y_i =k} (z_i-m_k)^2$(8.99)

咱们的目标就是找出能让均值距离$m_2-m_1$最大的w,同时也要保证投影的簇(cluster)是紧密的(tight):

$J(w)=\frac{(m_2-M_1)^2}{}$(8.100)

将等好友吧改写成关于w的形式如下所示:

$J(w)=\frac{w^TS_Bw}{w^TS_Ww}$(8.101)

其中的$S_B$为类间散布矩阵(between-class scatter matrix):

$S_B=(\mu_2-\mu_1)(\mu_2-\mu_1)^T$(8.102)

$S_W$为类内散布矩阵(within-class scatter matrix):
$S_W = \sum_{i:y_i=1} w^T(x_i-\mu_1)(x_i-\mu_1)^T +  \sum_{i:y_i=2} w^T(x_i-\mu_2)(x_i-\mu_2)^T  $(8.103)

然后两边分别乘以$w^T$和$w$:

$w^TS_Bw=w^T(\mu_2-\mu_1)(\mu_2-\mu_1)^T w=(m_2-m_1)(m_2-m_1)^T$(8.104)

$$
\begin{aligned}
w^TS_Ww &=\sum_{i:y_i=1} w^T(x_i-\mu_1)(x_i-\mu_1)^T w+  \sum_{i:y_i=2} w^T(x_i-\mu_2)(x_i-\mu_2)^T w &\text{(8.105)}\\
&= \sum_{i:y_i=1}(z_i-m_1)^2+\sum_{i:y_i=2}(z_i-m_2)^2   &\text{(8.106)}\\
\end{aligned}
$$

等式8.101就是两个标量的比;可以关于我求导数然后就等于零了.很明显(参考练习12.6)$J(w)$最大化的时候为:

$S_Bw=\lambdaS_Ww$(8.107)

其中的:
$\lambda =\frac{w^TS_Bw}{w^TS_Ww}$(8.108)

等式107也叫广义特征值问题(generalized eigenvalue problem).如果$S_W$可逆,就可以转换成一个规范特征值问题:
$S_W^{-1}S_Bw =\lambda w$(8.109)

不过在二分类情况下,就有一个更简单的解了.由于

$S_Bw = (\mu_2-\mu_1)(\mu_2-\mu_1)^T w =(\mu_2-\mu_1)(m_2-m_1)$(8.110)

所以通过等式8.109就有
$$
\begin{aligned}
\lambda w& = S_W^{-1}(\mu_2-\mu_1)(m_2-m_1)  &\text{(8.111)}\\
w & \propto  S_W^{-1}(\mu_2-\mu_1) &\text{(8.112)}\\
\end{aligned}
$$

由于我们只关心方向,缩放因数就无所谓了,所以可以直接写成:

$w = S_W^{-1}(\mu_2-\mu_1) $(8.113)

这就是二分类情况下的最优解了.如果$$S_W\propto I$,就意味着汇总协方差矩阵(pooled covariance matrix)是各向同性的(isotropic),这样w就正比于联合类均值(joins class means)的向量.如图8.11所示,这是一个直觉上很合理的投影方向.

#### 8.6.3.2 扩展到高维度和多分类情况


把上面的思路扩展到多分类情况,以及高维度子控件,只需要找到一个投影矩阵W,从D到L进行映射,最大化
$J(W)=\frac{W\Sigma_BW^T}{W\Sigma_WW^T}$(8.114)

其中
$$
\begin{aligned}
\Sigma_B & \overset{\triangle}{=} \sum_c \frac{N_c}{N}(\mu_c-\mu)(\mu_c-\mu)^T  &\text{(8.115)}\\
\Sigma_W & \overset{\triangle}{=} \sum_c \frac{N_c}{N}\Sigma_c  &\text{(8.116)}\\
\Sigma_c & \overset{\triangle}{=} \frac{1}{N_c}\sum_{i:y_i=c} (x_i-\mu_c) (x_i-\mu_c)^T  &\text{(8.117)}\\
\end{aligned}
$$

解就是:
$W=\Sigma_W^{-\frac{1}{2}} U$(8.118)

其中的U是$\Sigma_W^{-\frac{1}{2}} \Sigma_B\Sigma_W^{-\frac{1}{2}}$的L主特征向量(L leading eigenvectors),假设$\Sigma_W$是非奇异的.(如果是奇异的,可以先对全部数据进行主成分分析(PCA).)




此处参考原书图8.12

图8.12所示为将这个方法应用到$D=10$维度的运输局,其中有$C=11$个不同的原因声音(vowel sounds).图中可见很明显FLDA得到的分类比PCA效果好.

要注意FLDA是限制在最多$L\le C-1$维度的线性子空间的,不管D有多大,这是因为类间协方差矩阵$\Sigma_B$的秩(rank)就是$C-1$.(这里的-1是因为$\mu$项是$\mu_c$的线性函数.)这限制了FLDA的使用.

#### 8.6.3.3 FLDA的概率论解释*

对FLDA方法的概率论解释参考了(Kumar and Andreo 1998; Zhou et al. 2009).他们提出了一个模型,叫做异方差线性判别分析(heteroscedastic LDA,缩写为HLDA),过程如下所示.设W是一个$D\times D$的可逆矩阵,设$z_i=Wx$是对数据的转换.然后对转换后的数据的每一类都拟合完整协方差高斯分布(full covariance Gaussians),但仅限于前面L个成分为分类拟合(class-specific);剩下的$H=D-L$个成分在类间共享,因此也就不做区分(not be discriminative).也就是使用:

$$
\begin{aligned}
p(z_i|\theta,y_i=c) &= N(z_i|\mu_c,\Sigma_c) &\text{(8.119)}\\
\mu_c & \overset{\triangle}{=} (m_c;m_0) &\text{(8.120)}\\
\Sigma_c & \overset{\triangle}{=} \begin{pmatrix}  S_c & 0\\ 0 & S_0 \end{pmatrix} &\text{(8.121)}\\
\end{aligned}
$$


其中的$m_0$是共享的H维度均值,而$S_0$是共享的$H\times H$协方差.原始数据(未变换过)的概率密度函数(pdf)为:

$$
\begin{aligned}
p(x_i|y_i=c,W,\theta)&= |W|N(Wx_i|\mu_c,\Sigma_c) &\text{(8.122)}\\
&=|W|N(W_L x_i|m_c,S_c) N(W_H x_i|m_0,S_0)    &\text{(8.123)}\\
\end{aligned}
$$

其中$w=\begin{pmatrix} W_L\\ W_H\end{pmatrix}$.对于固定的W,很不容易推导出$\theta$的最大似然估计(MLE).然后可以使用梯度方法优化W.

在$\Sigma_c$为对角阵的特殊情况下,有一个W的闭合形式的解(Gales 1999).当所有$\Sigma_c$都一样的情况下,就会到了经典的线性判别分析(classical LDA, Zhou et al. 2009).

总的来看,如果雷协方差在可判别子空间内不相等(比如$\Sigma_c$独立于c是个错误假设),那么HLDA就会优于LDA.用合成数据(synthetic dat)就很容易演示出这种情况,另外更有挑战性的一些任务比如语音识别等等当中也是如此(Kumar and Andreo 1998).另外我们还可以通过让每个类都有自己的投影矩阵来进一步扩展这个模型,这样就成了多重线性判别分析(multiple LDA,Gales 2002).

练习略































